{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a786c77c",
      "metadata": {
        "id": "a786c77c"
      },
      "source": [
        "# LangChain: Memory\n",
        "\n",
        "## Outline\n",
        "* ConversationBufferMemory\n",
        "* ConversationBufferWindowMemory\n",
        "* ConversationTokenBufferMemory\n",
        "* ConversationSummaryMemory"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1297dcd5",
      "metadata": {
        "id": "1297dcd5"
      },
      "source": [
        "## ConversationBufferMemory"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU \"langchain[openai]\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bw6nUeLPZbVi",
        "outputId": "2f836972-1a29-4fbc-fe1b-dc2571d5b2e7"
      },
      "id": "bw6nUeLPZbVi",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1f518f5",
      "metadata": {
        "height": 147,
        "tags": [],
        "id": "a1f518f5"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "if userdata.get(\"OPENAI_API_KEY\"):\n",
        "  os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "\n",
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "llm_model = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\", temperature=0)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2301270b-7a69-40f8-9934-f840499b6ae9",
      "metadata": {
        "id": "2301270b-7a69-40f8-9934-f840499b6ae9"
      },
      "source": [
        "Note: LLM's do not always produce the same results. When executing the code in your notebook, you may get slightly different answers that those in the video."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20ad6fe2",
      "metadata": {
        "height": 96,
        "tags": [],
        "id": "20ad6fe2"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import LLMChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain_core.messages import SystemMessage\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        "    MessagesPlaceholder,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate(\n",
        "    [\n",
        "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "        HumanMessagePromptTemplate.from_template(\"{text}\"),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "SDed2LkdobK0"
      },
      "id": "SDed2LkdobK0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88bdf13d",
      "metadata": {
        "height": 147,
        "tags": [],
        "id": "88bdf13d"
      },
      "outputs": [],
      "source": [
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "conversation = LLMChain(\n",
        "    llm=llm_model,\n",
        "    memory = memory,\n",
        "    prompt=prompt,\n",
        "    verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db24677d",
      "metadata": {
        "height": 45,
        "tags": [],
        "id": "db24677d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "577f527f-6bdc-4eb3-87a7-f0fc33ec4a0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mHuman: Hi, my name is Steve\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': 'Hi Steve! How can I assist you today?',\n",
              " 'chat_history': [HumanMessage(content='Hi, my name is Steve', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='Hi Steve! How can I assist you today?', additional_kwargs={}, response_metadata={})]}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "conversation.invoke({\"text\": \"Hi, my name is Steve\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc3ef937",
      "metadata": {
        "height": 30,
        "tags": [],
        "id": "cc3ef937",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a459d94f-2a7d-48d0-e354-6208760446e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mHuman: Hi, my name is Steve\n",
            "AI: Hi Steve! How can I assist you today?\n",
            "Human: What is 1+1?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': '1 + 1 equals 2.',\n",
              " 'chat_history': [HumanMessage(content='Hi, my name is Steve', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='Hi Steve! How can I assist you today?', additional_kwargs={}, response_metadata={}),\n",
              "  HumanMessage(content='What is 1+1?', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='1 + 1 equals 2.', additional_kwargs={}, response_metadata={})]}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "conversation.invoke(input=\"What is 1+1?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acf3339a",
      "metadata": {
        "height": 45,
        "tags": [],
        "id": "acf3339a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35192367-afcc-4fd0-fa14-253d12221176"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mHuman: Hi, my name is Steve\n",
            "AI: Hi Steve! How can I assist you today?\n",
            "Human: What is 1+1?\n",
            "AI: 1 + 1 equals 2.\n",
            "Human: What is my name?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': 'Your name is Steve.',\n",
              " 'chat_history': [HumanMessage(content='Hi, my name is Steve', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='Hi Steve! How can I assist you today?', additional_kwargs={}, response_metadata={}),\n",
              "  HumanMessage(content='What is 1+1?', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='1 + 1 equals 2.', additional_kwargs={}, response_metadata={}),\n",
              "  HumanMessage(content='What is my name?', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='Your name is Steve.', additional_kwargs={}, response_metadata={})]}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "conversation.invoke(input=\"What is my name?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2529400d",
      "metadata": {
        "height": 30,
        "tags": [],
        "id": "2529400d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4f548a5-9355-4977-cd9a-3d242e57665e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[HumanMessage(content='Hi, my name is Steve', additional_kwargs={}, response_metadata={}), AIMessage(content='Hi Steve! How can I assist you today?', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is 1+1?', additional_kwargs={}, response_metadata={}), AIMessage(content='1 + 1 equals 2.', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is my name?', additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is Steve.', additional_kwargs={}, response_metadata={})]\n"
          ]
        }
      ],
      "source": [
        "print(memory.buffer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5018cb0a",
      "metadata": {
        "height": 30,
        "tags": [],
        "id": "5018cb0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30895bfb-7f00-4cec-cd3b-e68950a134c5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'chat_history': [HumanMessage(content='Hi, my name is Steve', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='Hi Steve! How can I assist you today?', additional_kwargs={}, response_metadata={}),\n",
              "  HumanMessage(content='What is 1+1?', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='1 + 1 equals 2.', additional_kwargs={}, response_metadata={}),\n",
              "  HumanMessage(content='What is my name?', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='Your name is Steve.', additional_kwargs={}, response_metadata={})]}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "memory.load_memory_variables({})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VejuFb2rcVx3",
        "outputId": "bc180308-c752-4795-f902-1c3de523f800"
      },
      "id": "VejuFb2rcVx3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LLMChain(memory=ConversationBufferMemory(chat_memory=InMemoryChatMessageHistory(messages=[HumanMessage(content='Hi, my name is Steve', additional_kwargs={}, response_metadata={}), AIMessage(content='Hi Steve! How can I assist you today?', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is 1+1?', additional_kwargs={}, response_metadata={}), AIMessage(content='1 + 1 equals 2.', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is my name?', additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is Steve.', additional_kwargs={}, response_metadata={})]), return_messages=True, memory_key='chat_history'), verbose=True, prompt=ChatPromptTemplate(input_variables=['chat_history', 'text'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x7ff883ad3a60>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], input_types={}, partial_variables={}, template='{text}'), additional_kwargs={})]), llm=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7ff7a275b230>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7ff7a2602210>, root_client=<openai.OpenAI object at 0x7ff7a650fe60>, root_async_client=<openai.AsyncOpenAI object at 0x7ff7a3852810>, model_name='gpt-4o-mini', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True), output_parser=StrOutputParser(), llm_kwargs={})"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14219b70",
      "metadata": {
        "height": 30,
        "tags": [],
        "id": "14219b70"
      },
      "outputs": [],
      "source": [
        "memory2 = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a36e9905",
      "metadata": {
        "height": 47,
        "tags": [],
        "id": "a36e9905"
      },
      "outputs": [],
      "source": [
        "memory2.save_context({\"input\": \"Hi\"},\n",
        "                    {\"output\": \"What's up\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61631b1f",
      "metadata": {
        "height": 30,
        "tags": [],
        "id": "61631b1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cd1d5b2-8e19-4be8-aa00-a292585a952f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[HumanMessage(content='Hi', additional_kwargs={}, response_metadata={}), AIMessage(content=\"What's up\", additional_kwargs={}, response_metadata={})]\n"
          ]
        }
      ],
      "source": [
        "print(memory2.buffer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2fdf9ec",
      "metadata": {
        "height": 30,
        "tags": [],
        "id": "a2fdf9ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0981398-48f6-4b8f-8fb7-f93ad169e6cf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'chat_history': [HumanMessage(content='Hi', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content=\"What's up\", additional_kwargs={}, response_metadata={})]}"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "memory2.load_memory_variables({})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ca79256",
      "metadata": {
        "height": 62,
        "tags": [],
        "id": "7ca79256"
      },
      "outputs": [],
      "source": [
        "memory2.save_context({\"input\": \"在 python 中, 什麼資料結構等於 JAVA 的 map\"},\n",
        "                    {\"output\": \"我保證一定是 list\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "890a4497",
      "metadata": {
        "height": 30,
        "tags": [],
        "id": "890a4497",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c81b2721-05d1-43e4-e155-bcf792127695"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'chat_history': [HumanMessage(content='Hi', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content=\"What's up\", additional_kwargs={}, response_metadata={}),\n",
              "  HumanMessage(content='在 python 中, 什麼資料結構等於 JAVA 的 map', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='我保證一定是 list', additional_kwargs={}, response_metadata={})]}"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "memory2.load_memory_variables({})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_model = init_chat_model(\"gpt-3.5-turbo\", model_provider=\"openai\", temperature=0.8)\n",
        "\n",
        "conversation = LLMChain(\n",
        "    llm=llm_model,\n",
        "    memory=memory2,\n",
        "    prompt=prompt,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "tcYp8M6Rcy43"
      },
      "id": "tcYp8M6Rcy43",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation({\"text\": \"不管對錯, 剛剛你說Java 的map等於python 的什麼?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NT1q0nnKc98X",
        "outputId": "220cbddd-ce1a-414e-e6c8-4f6b4dafa054"
      },
      "id": "NT1q0nnKc98X",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mHuman: Hi\n",
            "AI: What's up\n",
            "Human: 在 python 中, 什麼資料結構等於 JAVA 的 map\n",
            "AI: 我保證一定是 list\n",
            "Human: 不管對錯, 剛剛你說Java 的map等於python 的什麼?\n",
            "AI: 對不起，我犯了一個錯誤。在Python中，與Java中的Map對應的資料結構是字典（Dictionary）。字典是一種無序的鍵值對集合，可以通過鍵來查找對應的值。希望這次回答能幫助到您。\n",
            "Human: 不管對錯, 剛剛你說Java 的map等於python 的什麼?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': '對不起，我之前的回答有誤。在 Python 中，與 Java 中的 Map 對應的資料結構是字典（Dictionary）。字典是一種無序的鍵值對集合，可以通過鍵來查找對應的值。希望這次的回答對您有幫助。感謝您的指正。',\n",
              " 'chat_history': [HumanMessage(content='Hi', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content=\"What's up\", additional_kwargs={}, response_metadata={}),\n",
              "  HumanMessage(content='在 python 中, 什麼資料結構等於 JAVA 的 map', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='我保證一定是 list', additional_kwargs={}, response_metadata={}),\n",
              "  HumanMessage(content='不管對錯, 剛剛你說Java 的map等於python 的什麼?', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='對不起，我犯了一個錯誤。在Python中，與Java中的Map對應的資料結構是字典（Dictionary）。字典是一種無序的鍵值對集合，可以通過鍵來查找對應的值。希望這次回答能幫助到您。', additional_kwargs={}, response_metadata={}),\n",
              "  HumanMessage(content='不管對錯, 剛剛你說Java 的map等於python 的什麼?', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='對不起，我之前的回答有誤。在 Python 中，與 Java 中的 Map 對應的資料結構是字典（Dictionary）。字典是一種無序的鍵值對集合，可以通過鍵來查找對應的值。希望這次的回答對您有幫助。感謝您的指正。', additional_kwargs={}, response_metadata={})]}"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf98e9ff",
      "metadata": {
        "tags": [],
        "id": "cf98e9ff"
      },
      "source": [
        "## ConversationBufferWindowMemory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66eeccc3",
      "metadata": {
        "height": 45,
        "tags": [],
        "id": "66eeccc3"
      },
      "outputs": [],
      "source": [
        "from langchain.memory import ConversationBufferWindowMemory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ea6233e",
      "metadata": {
        "height": 45,
        "tags": [],
        "id": "3ea6233e"
      },
      "outputs": [],
      "source": [
        "memory = ConversationBufferWindowMemory(k=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc4553fb",
      "metadata": {
        "height": 113,
        "tags": [],
        "id": "dc4553fb"
      },
      "outputs": [],
      "source": [
        "memory.save_context({\"input\": \"Hi\"},\n",
        "                    {\"output\": \"What's up\"})\n",
        "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
        "                    {\"output\": \"Cool\"})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a788403",
      "metadata": {
        "height": 30,
        "tags": [],
        "id": "6a788403",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c2c9ccc-86b5-499b-dae1-ed6a2d6ce32a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'history': \"Human: Hi\\nAI: What's up\\nHuman: Not much, just hanging\\nAI: Cool\"}"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "memory.load_memory_variables({})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4087bc87",
      "metadata": {
        "height": 147,
        "tags": [],
        "id": "4087bc87"
      },
      "outputs": [],
      "source": [
        "llm_model = init_chat_model(\"gpt-5-nano\", model_provider=\"openai\")\n",
        "memory = ConversationBufferWindowMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "conversation = LLMChain(\n",
        "    llm=llm_model,\n",
        "    memory = memory,\n",
        "    prompt=prompt,\n",
        "    verbose=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4faaa952",
      "metadata": {
        "height": 45,
        "tags": [],
        "id": "4faaa952",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "167a4949-19fd-4cde-ce44-63af4b0829ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mHuman: Hi, my name is Steve\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': 'Nice to meet you, Steve! How can I help today?\\n\\nI can assist with:\\n- Explaining concepts or answering questions\\n- Brainstorming ideas or plans\\n- Writing: emails, essays, reports, resumes\\n- Coding help or debugging\\n- Study help and problem solving\\n- Planning tasks or projects\\n\\nTell me what you’d like to do, or share a goal and I’ll tailor my response.',\n",
              " 'chat_history': []}"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "conversation.invoke({\"text\": \"Hi, my name is Steve\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb20ddaa",
      "metadata": {
        "height": 30,
        "tags": [],
        "id": "bb20ddaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "fb962241-7ea8-4853-88b2-da4f61e1c589"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"1 + 1 equals 2! It's a simple addition problem, but it's the foundation of so many mathematical concepts. Do you enjoy math, or is there another subject you prefer?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "conversation.predict(input=\"What is 1+1?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "489b2194",
      "metadata": {
        "height": 45,
        "tags": [],
        "id": "489b2194"
      },
      "outputs": [],
      "source": [
        "conversation.predict(input=\"What is my name?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2931b92",
      "metadata": {
        "id": "d2931b92"
      },
      "source": [
        "## ConversationTokenBufferMemory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f6d063c",
      "metadata": {
        "height": 30,
        "tags": [],
        "id": "9f6d063c"
      },
      "outputs": [],
      "source": [
        "#!pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb9020ed",
      "metadata": {
        "height": 79,
        "tags": [],
        "id": "fb9020ed"
      },
      "outputs": [],
      "source": [
        "from langchain.memory import ConversationTokenBufferMemory\n",
        "from langchain.llms import OpenAI\n",
        "llm = ChatOpenAI(temperature=0.0, model=llm_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43582ee6",
      "metadata": {
        "height": 147,
        "tags": [],
        "id": "43582ee6"
      },
      "outputs": [],
      "source": [
        "memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=50)\n",
        "memory.save_context({\"input\": \"AI is what?!\"},\n",
        "                    {\"output\": \"Amazing!\"})\n",
        "memory.save_context({\"input\": \"Backpropagation is what?\"},\n",
        "                    {\"output\": \"Beautiful!\"})\n",
        "memory.save_context({\"input\": \"Chatbots are what?\"},\n",
        "                    {\"output\": \"Charming!\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "284288e1",
      "metadata": {
        "height": 30,
        "tags": [],
        "id": "284288e1"
      },
      "outputs": [],
      "source": [
        "memory.load_memory_variables({})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ff55d5d",
      "metadata": {
        "id": "5ff55d5d"
      },
      "source": [
        "## ConversationSummaryMemory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72dcf8b1",
      "metadata": {
        "height": 45,
        "tags": [],
        "id": "72dcf8b1"
      },
      "outputs": [],
      "source": [
        "from langchain.memory import ConversationSummaryBufferMemory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a5b238f",
      "metadata": {
        "height": 283,
        "tags": [],
        "id": "4a5b238f"
      },
      "outputs": [],
      "source": [
        "# create a long string\n",
        "schedule = \"There is a meeting at 8am with your product team. \\\n",
        "You will need your powerpoint presentation prepared. \\\n",
        "9am-12pm have time to work on your LangChain \\\n",
        "project which will go quickly because Langchain is such a powerful tool. \\\n",
        "At Noon, lunch at the italian resturant with a customer who is driving \\\n",
        "from over an hour away to meet you to understand the latest in AI. \\\n",
        "Be sure to bring your laptop to show the latest LLM demo.\"\n",
        "\n",
        "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)\n",
        "memory.save_context({\"input\": \"Hello\"}, {\"output\": \"What's up\"})\n",
        "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
        "                    {\"output\": \"Cool\"})\n",
        "memory.save_context({\"input\": \"What is on the schedule today?\"},\n",
        "                    {\"output\": f\"{schedule}\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e4ecabe",
      "metadata": {
        "height": 30,
        "tags": [],
        "id": "2e4ecabe"
      },
      "outputs": [],
      "source": [
        "memory.load_memory_variables({})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6728edba",
      "metadata": {
        "height": 98,
        "tags": [],
        "id": "6728edba"
      },
      "outputs": [],
      "source": [
        "conversation = ConversationChain(\n",
        "    llm=llm,\n",
        "    memory = memory,\n",
        "    verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a221b1d",
      "metadata": {
        "height": 45,
        "tags": [],
        "id": "9a221b1d"
      },
      "outputs": [],
      "source": [
        "conversation.predict(input=\"What would be a good demo to show?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb582617",
      "metadata": {
        "height": 30,
        "tags": [],
        "id": "bb582617"
      },
      "outputs": [],
      "source": [
        "memory.load_memory_variables({})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ba827aa",
      "metadata": {
        "height": 30,
        "id": "4ba827aa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c07922b",
      "metadata": {
        "height": 30,
        "id": "2c07922b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4505e6f-626e-46a9-a6c2-fe89c1963241"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mHuman: Python 中的 list 跟一般程式語言 list 的不同？\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "reasoning = {\n",
        "    \"effort\": \"medium\",  # 'low', 'medium', or 'high'\n",
        "    \"summary\": \"auto\",  # 'detailed', 'auto', or None\n",
        "}\n",
        "\n",
        "llm_model = init_chat_model(\"gpt-5-nano\", model_provider=\"openai\", reasoning=reasoning, stream_usage=True)\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "conversation = LLMChain(\n",
        "    llm=llm_model,\n",
        "    memory=memory,\n",
        "    prompt=prompt,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "\n",
        "result = conversation.invoke({\"text\": \"Python 中的 list 跟一般程式語言 list 的不同？\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52696c8c",
      "metadata": {
        "height": 30,
        "id": "52696c8c"
      },
      "outputs": [],
      "source": [
        "reasoning = {\n",
        "    \"effort\": \"medium\",  # 'low', 'medium', or 'high'\n",
        "    \"summary\": \"auto\",  # 'detailed', 'auto', or None\n",
        "}\n",
        "\n",
        "llm_model = init_chat_model(\"gpt-5-nano\", model_provider=\"openai\", reasoning=reasoning, stream_usage=True)\n",
        "result = llm_model.invoke(\"Python 中的 list 跟一般程式語言 list 的不同？\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result.content[0][\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0yvn8iYyoNs",
        "outputId": "d0fe923d-3bfd-424a-f0ce-92b47c2081fe"
      },
      "id": "w0yvn8iYyoNs",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "簡單說，Python 的 list 與「一般語言裡的 List」常常指的是不同的東西或不同的實作。下面把重點整理，幫你區分清楚。\n",
            "\n",
            "- Python list 是什麼\n",
            "  - 是 Python 內建的動態陣列（dynamic array），用來存放任意型別的元素（可以混放不同型別）。\n",
            "  - 它是可變的（mutable），你可以 append、insert、pop、slice 等。\n",
            "  - 底層存放的是對象引用（指向 PyObject 的指針），每個元素實際上是一個「引用」到某個 Python 對象。\n",
            "  - 支援負數索引、切片、清單方法（append、extend、insert、remove、pop、sort、reverse、copy 等），以及 list comprehension 等語法特性。\n",
            "  - 切片返回的是新的一個列表（是拷貝而非視圖）。\n",
            "  - 記憶體模型：底層是一段連續的記憶體，儲存的是指針；新增容量時會成長，典型是摻合式增長（o(1) 平均時間的 append）。\n",
            "\n",
            "- 與「一般語言中的 List」的常見差異\n",
            "  - 類型限制\n",
            "    - Python list 零型別限制，元素可以是任意型別，且同一個 list 內也可以混放。\n",
            "    - 許多語言的 List（例如 Java 的 List<T>、C++ 的 std::vector<T>）是泛型化的，通常會固定元素的型別（編譯時型別檢查，運行時才會有型別擦除或轉型成本）。\n",
            "  - 實作底層\n",
            "    - Python 的 list 本質上是動態陣列（類似於其他語言的 ArrayList / std::vector 的概念），不是「雙向鏈結串列」等其他結構。\n",
            "    - 在很多語言裡，List 可能是介面或抽象型別，實作可以是陣列型 (ArrayList / Vector) 或鏈結型 (LinkedList) 等，性能特性會不同。\n",
            "  - 可變性與不可變性\n",
            "    - Python list 是默認可變的。\n",
            "    - 某些語言的 List 介面可能有不可變版本（immutable list）或在某些情境下限制修改。\n",
            "  - 典型用途與效能特性\n",
            "    - Python list 對於隨機存取（O(1)）和在末端加入元素（append，平均 O(1)）表現良好，對於中間定位的插入/刪除會是 O(n)。\n",
            "    - 與 C++ 的 vector/Java 的 ArrayList 類似，在中間插入或刪除成本也通常是 O(n)（因為要移動後面的元素）。\n",
            "    - 如果你需要在頭尾快速 pop/append，某些語言提供的 deque（雙端隊列）或 Python 的 collections.deque 提供更優的 O(1) 操作。\n",
            "  - 記憶體與效能負荷\n",
            "    - Python list 儲存的是對象引用，實際的 Python 對象仍然獨立存在。為大量數值資料時，單純的 Python list 會比原生數值陣列有較高的記憶體開銷。\n",
            "    - 若需要高密度的數值運算，常會用 numpy 等專門的數值型別陣列，而非標準的 Python list。\n",
            "  - 切片與拷貝\n",
            "    - Python 的切片會產生新清單（拷貝元素的引用），不是「視圖」，這點與某些語言的子集合視圖處理不同。\n",
            "  - 語法與工具\n",
            "    - Python 有 list comprehension、生成器、豐富的內建方法，讓操作清單更直覺。\n",
            "    - 你也可以用 typing.List[T] 做型別標註（靜態型別檢查工具如 mypy 會檢查，但運行時仍是動態型別）。\n",
            "\n",
            "- 實用摘要\n",
            "  - 如果你需要一個通用、易用的可變序列，Python list 是最常用的選擇。\n",
            "  - 若你需要要麼只存數字且追求內存效率，考慮使用 numpy 陣列。\n",
            " 不了解的情況下，Python 的 list 跟一般語言裡的 List 最接近的比較是「動態陣列 / 容器（如 ArrayList / std::vector）」的概念，而不是單純的鏈結清單。\n",
            "  \n",
            "如果你有在比較特定語言的 List（例如與 Java 的 List、C++ 的 std::vector、或 C 里的自訂串列）之間的差異，告訴我是哪幾個語言，我可以做更針對性的對比與性能建議。你現在想比較的是哪幾種語言的 List？\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in result.additional_kwargs[\"reasoning\"][\"summary\"]:\n",
        "  print(i[\"text\"])\n",
        "  print(\"========\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfgGwiXyzeTa",
        "outputId": "e1a1ddba-830b-45e4-be53-100eb89736d2"
      },
      "id": "sfgGwiXyzeTa",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Reviewing list performance**\n",
            "\n",
            "I'm evaluating how insertion and deletion work in lists. Inserting or deleting in the middle is O(n) because it requires shifting elements. In programming languages like C++ or Java, the \"List\" interface has implementations such as ArrayList (dynamic array) and LinkedList. In Python, lists behave like Java's ArrayList, providing O(1) random access but O(n) for middle operations. Python lacks a built-in linked list but offers collections.deque, which allows O(1) appending or popping from both ends. Overall, mutability varies between Python's mutable lists and other languages that might have immutable lists.\n",
            "========\n",
            "**Examining Python lists**\n",
            "\n",
            "I'm pondering several aspects of Python lists. They manage memory using reference counting and garbage collection, meaning they're not overly prone to fragmentation. When slicing a list, Python creates a new list with copies of the elements, unlike some languages that provide views. For copying a list, I need to use list.copy() or slicing to avoid aliasing. Performance-wise, Python lists can be slower for numeric operations without NumPy. I've noticed some useful constructs like list comprehensions and generator expressions, as well as immutable tuples and the array module for numeric arrays.\n",
            "========\n",
            "**Exploring Python's array module**\n",
            "\n",
            "In Python, the \"array\" module allows for storage of homogeneous numeric types in a compact C array, although it isn't commonly used. The memory representation consists of a contiguous array of pointers to PyObject, not the objects themselves, and resizing follows a doubling strategy. Python lists have unique methods like sort and reverse, along with built-in functions such as sorted(). They automatically expand, so the user doesn't need to worry about capacity. Complexity notations show various efficiencies for operations, including O(1) for appending and O(n) for inserts or removals. Additionally, I have to remember slicing with a step parameter and differentiate between \"null\" and \"None.\"\n",
            "========\n",
            "**Clarifying Python's list implementation**\n",
            "\n",
            "I want to provide a clear answer about Python lists, which are implemented as dynamic arrays of PyObject pointers. In many programming languages, a \"list\" is often a linked list or an abstract interface. However, in Python, a list is more similar to C++'s std::vector or Java's ArrayList, rather than a linked list. For a fair comparison, both Python lists and C++ vectors allow for random access at O(1) complexity, but insertion or removal in the middle has a complexity of O(n).\n",
            "========\n",
            "**Comparing Python lists and other structures**\n",
            "\n",
            "In Python, a list is implemented as a dynamic array of PyObject pointers, which retains heterogeneous types. While lists allow O(1) amortized appends, they're not linked lists—insertions at the head would be O(1) for linked lists. For efficient appends and pops at both ends, I recommend using collections.deque.\n",
            "\n",
            "Here are some key points:\n",
            "1. Type system: heterogeneous and dynamically typed.\n",
            "2. Mutability: lists are mutable.\n",
            "3. Memory model: contiguous array of references.\n",
            "4. Performance: append is O(1), insert/pop in the middle is O(n).\n",
            "5. Slicing: creates a new list.\n",
            "6. Methods: includes built-in functions and comprehensions.\n",
            "7. Comparison: similar to Java's ArrayList and C++'s vector.\n",
            "8. Memory overhead: each item references an object, more than typical arrays.\n",
            "9. Type hints: can annotate but without runtime enforcement.\n",
            "10. Support for nested lists.\n",
            "\n",
            "Here’s a quick code snippet:\n",
            "```python\n",
            "a = [1, 'two', 3.0]  \n",
            "a.append(4)  \n",
            "b = a.copy()  \n",
            "del a[1]  \n",
            "```\n",
            "Do you want to compare lists across specific programming languages?\n",
            "========\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48690d13",
      "metadata": {
        "height": 30,
        "id": "48690d13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e881b31-b2d1-4e5a-c035-a69029201fba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'chat_history': [HumanMessage(content='Python 中的 list 跟一般程式語言 list 的不同？', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='簡單說，Python 的 list 是一種內建的「動態陣列」型別，具有以下特點：有序、可變、可以放不同型別的元素、支援很多方便的方法與語法（切片、推導式等），且元素實際上是物件的引用。\\n\\n跟其他常見語言中的 list / 類似結構比較時的重點差異：\\n\\n- 與 C/C++ 的陣列\\n  - Python list 是動態的，可以自動擴充長度；C/C++ 的基本陣列通常大小固定，若要動態需另行分配與管理。\\n  - Python list 可以放不同型別的元素（混合型別），而 C/C++ 陣列通常是同一型別的元素，型別在編譯時就確定。\\n  - Python list 的每個元素實際是指向物件的指標，會有較大記憶體開銷；C/C++ 的陣列直接存放元素本身，空間更紧湊且更接近底層存取。\\n\\n- 與 linked list（如某些語言的 List/LinkedList 實作）\\n  - Python list 不是「鏈結串列」，而是動態陣列（底層是連續區塊的指標陣列）。Insert/Remove 在中間需要移動元素，成本通常是 O(n)。\\n  - 某些語言的 List 介面有多種實作（如 ArrayList、LinkedList），在效能特性上就會差異很大；Python 的 list 只有一種實作但提供了很多方便用法。\\n\\n- 與 Java 的 List<T> / ArrayList\\n  - Java 的 List 通常是介面，實作有 ArrayList、LinkedList 等，型別通常是泛型（如 List<Integer>）。\\n  - Python list 沒有泛型限定，任意元素都可以混放；沒有明確的介面與實作分離，只有一個內建型別 list。\\n  - 底層實作都可能是動態陣列，但 Python 提供的切片、推導式等語法在語法層面與 Java 的集合框架不同。\\n\\n- 與 JavaScript 的 Array\\n  - 兩者都屬動態陣列、可以混放型別元素，且都支援很多便捷操作。但語法、方法名稱、區塊語法與迭代特性不同。\\n\\nPython list 的一些重要特性（簡要重點）：\\n- 有序且可變，允許重複元素。\\n- 可以存放不同型別的元素，如 [1, \"two\", 3.0, [4, 5]]。\\n- 常用方法與運算：append、extend、insert、remove、pop、clear、index、count、sort、reverse、copy；切片 list[a:b] 是會回傳新的一個 list。\\n- 設計為引用型語言中的「引用」集合：list 中存放的是對其他物件的引用，實際元素是透過引用連結的。\\n- 負向索引、切片、淺複製與深拷貝的語義要留意。assignment 會把變數綁到同一個 list；list.copy() 與 copy 模組可以做淺/深複製。\\n- 性能特性：append 在平均情況下是 O(1)（攤銷成本），在中間插入或移除元素通常是 O(n)，切片與深拷貝等成本也要注意。\\n\\n使用上的建議與常見替代：\\n- 若要高效地存放大量同型別的數值，且需要更緊湊的內存使用，可考慮 array 模組（array.array）或 NumPy 陣列。\\n- 若需要大量在兩端插入/移除，或需要雙端佇列特性，collections.deque 會比 list 更快。\\n- 需要不可變的序列時，可以用 tuple。\\n- 若要避免混放型別造成的風險，雖然 Python 允許混放，但最好保持同一用途的元素型別一致。\\n\\n簡單範例：\\n\\n- 建立與基本操作\\n  - my_list = [1, \"two\", 3.0]\\n  - my_list.append(4)        # [1, \"two\", 3.0, 4]\\n  - sub = my_list[1:3]        # [\"two\", 3.0]，新的 list\\n  - copy1 = my_list.copy()    # 淺複製\\n  - my_list[0] = 100\\n  - remove 的用法等\\n\\n如果你有在比較的「另一語言的 list」具體語言（例如 Java、C++、JavaScript 等），也可以告訴我，我可以針對那個語言給出更精確的對比與實作差異。', additional_kwargs={}, response_metadata={})]}"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85bba1f8",
      "metadata": {
        "height": 30,
        "id": "85bba1f8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f953ad8d",
      "metadata": {
        "height": 30,
        "id": "f953ad8d"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "llm_model = init_chat_model(\"gpt-5-nano\", model_provider=\"openai\", stream_usage=True)\n",
        "\n",
        "\n",
        "class GetWeather(BaseModel):\n",
        "    \"\"\"Get the current weather in a given location\"\"\"\n",
        "\n",
        "    location: str = Field(..., description=\"The city and state, e.g. San Francisco, CA\")\n",
        "\n",
        "\n",
        "llm_with_tools = llm.bind_tools([GetWeather])\n",
        "\n",
        "ai_msg = llm_with_tools.invoke(\n",
        "    \"what is the weather like in New York\",\n",
        ")\n",
        "ai_msg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9bb2617",
      "metadata": {
        "height": 30,
        "id": "b9bb2617"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be1989bf",
      "metadata": {
        "height": 30,
        "id": "be1989bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d0ada2c-caeb-4b61-c88a-927fdaf43e9c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'name': 'GetWeather',\n",
              "  'args': {'location': 'New York, NY'},\n",
              "  'id': 'call_N1W5bB1bPhDcayAIhsTlTPcT',\n",
              "  'type': 'tool_call'}]"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ],
      "source": [
        "ai_msg.tool_calls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1f8dca6",
      "metadata": {
        "height": 30,
        "id": "b1f8dca6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc7cb86f-b02c-41ec-e1c5-96973875884d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 找到位置: Taipei -> Taipei, Taiwan\n",
            "\n",
            "🌤️  天氣資訊:\n",
            "地點: Taipei, Taiwan\n",
            "溫度: 31.2°C\n",
            "體感溫度: 32.7°C\n",
            "天氣狀況: 晴朗\n",
            "濕度: 54%\n",
            "風速: 18.8 km/h\n",
            "風向: 東\n",
            "\n",
            "\n",
            "✨ 最終回答:\n",
            "台北現在的天氣是晴朗，溫度為31.2°C，體感溫度32.7°C，濕度54%，風速18.8 km/h，風向為東。\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import HumanMessage, ToolMessage\n",
        "from pydantic import BaseModel, Field\n",
        "import requests\n",
        "\n",
        "# 初始化 LLM (設定 verbose=True)\n",
        "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0, verbose=True)\n",
        "\n",
        "\n",
        "# 定義天氣工具\n",
        "class GetWeather(BaseModel):\n",
        "    \"\"\"Get the current weather in a given location\"\"\"\n",
        "\n",
        "    location: str = Field(..., description=\"The city and state, e.g. San Francisco, CA\")\n",
        "\n",
        "\n",
        "def get_coordinates(location: str) -> dict:\n",
        "    \"\"\"使用 Open-Meteo 的 Geocoding API 獲取城市的經緯度\"\"\"\n",
        "    geocoding_url = \"https://geocoding-api.open-meteo.com/v1/search\"\n",
        "\n",
        "    # 嘗試多種語言和格式\n",
        "    search_terms = [location]\n",
        "\n",
        "    # 如果是台北，添加更多搜尋選項\n",
        "    if \"台北\" in location or \"taipei\" in location.lower():\n",
        "        search_terms = [\"Taipei\", \"台北市\", \"Taipei City\", location]\n",
        "\n",
        "    for search_term in search_terms:\n",
        "        params = {\n",
        "            \"name\": search_term,\n",
        "            \"count\": 1,\n",
        "            \"language\": \"en\",  # 改用英文搜尋較穩定\n",
        "            \"format\": \"json\"\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            response = requests.get(geocoding_url, params=params)\n",
        "            response.raise_for_status()\n",
        "            data = response.json()\n",
        "\n",
        "            if \"results\" in data and len(data[\"results\"]) > 0:\n",
        "                result = data[\"results\"][0]\n",
        "                print(f\"✅ 找到位置: {search_term} -> {result['name']}, {result.get('country', '')}\")\n",
        "                return {\n",
        "                    \"latitude\": result[\"latitude\"],\n",
        "                    \"longitude\": result[\"longitude\"],\n",
        "                    \"name\": result[\"name\"],\n",
        "                    \"country\": result.get(\"country\", \"\"),\n",
        "                    \"admin1\": result.get(\"admin1\", \"\")\n",
        "                }\n",
        "        except Exception as e:\n",
        "            print(f\"搜尋 '{search_term}' 失敗: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "def get_current_weather(location: str) -> str:\n",
        "    \"\"\"使用 Open-Meteo API 獲取實際天氣數據\"\"\"\n",
        "    # 步驟 1: 獲取城市的經緯度\n",
        "    coords = get_coordinates(location)\n",
        "\n",
        "    if not coords:\n",
        "        return f\"找不到 '{location}' 的位置資訊，請嘗試使用英文地名，例如 'Taipei'\"\n",
        "\n",
        "    # 步驟 2: 使用經緯度獲取天氣\n",
        "    weather_url = \"https://api.open-meteo.com/v1/forecast\"\n",
        "\n",
        "    params = {\n",
        "        \"latitude\": coords[\"latitude\"],\n",
        "        \"longitude\": coords[\"longitude\"],\n",
        "        \"current\": [\n",
        "            \"temperature_2m\",\n",
        "            \"relative_humidity_2m\",\n",
        "            \"apparent_temperature\",\n",
        "            \"weather_code\",\n",
        "            \"wind_speed_10m\",\n",
        "            \"wind_direction_10m\"\n",
        "        ],\n",
        "        \"timezone\": \"auto\"\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.get(weather_url, params=params)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "\n",
        "        current = data[\"current\"]\n",
        "\n",
        "        # 天氣代碼對應描述\n",
        "        weather_codes = {\n",
        "            0: \"晴朗\", 1: \"大致晴朗\", 2: \"局部多雲\", 3: \"多雲\",\n",
        "            45: \"有霧\", 48: \"霧淞\", 51: \"小雨\", 53: \"中雨\", 55: \"大雨\",\n",
        "            61: \"小雨\", 63: \"中雨\", 65: \"大雨\", 71: \"小雪\", 73: \"中雪\",\n",
        "            75: \"大雪\", 80: \"陣雨\", 81: \"中度陣雨\", 82: \"強烈陣雨\",\n",
        "            95: \"雷暴\"\n",
        "        }\n",
        "\n",
        "        weather_description = weather_codes.get(current[\"weather_code\"], \"未知天氣\")\n",
        "\n",
        "        # 風向轉換\n",
        "        directions = [\"北\", \"東北\", \"東\", \"東南\", \"南\", \"西南\", \"西\", \"西北\"]\n",
        "        direction_index = int((current[\"wind_direction_10m\"] + 22.5) / 45) % 8\n",
        "        wind_dir_text = directions[direction_index]\n",
        "\n",
        "        # 格式化結果\n",
        "        location_name = coords[\"name\"]\n",
        "        if coords[\"country\"]:\n",
        "            location_name += f\", {coords['country']}\"\n",
        "\n",
        "        weather_info = f\"\"\"\n",
        "地點: {location_name}\n",
        "溫度: {current['temperature_2m']}°C\n",
        "體感溫度: {current['apparent_temperature']}°C\n",
        "天氣狀況: {weather_description}\n",
        "濕度: {current['relative_humidity_2m']}%\n",
        "風速: {current['wind_speed_10m']} km/h\n",
        "風向: {wind_dir_text}\n",
        "        \"\"\".strip()\n",
        "\n",
        "        return weather_info\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"獲取天氣資訊時發生錯誤: {str(e)}\"\n",
        "\n",
        "\n",
        "# 綁定工具到 LLM\n",
        "llm_with_tools = llm.bind_tools([GetWeather])\n",
        "\n",
        "# 台北天氣查詢\n",
        "user_question = \"台北現在天氣如何？\"\n",
        "\n",
        "# 第一步：LLM 決定要調用什麼工具\n",
        "ai_msg = llm_with_tools.invoke([HumanMessage(content=user_question)])\n",
        "\n",
        "# 第二步：執行工具\n",
        "if ai_msg.tool_calls:\n",
        "    messages = [HumanMessage(content=user_question), ai_msg]\n",
        "\n",
        "    for tool_call in ai_msg.tool_calls:\n",
        "        if tool_call[\"name\"] == \"GetWeather\":\n",
        "            # 執行天氣 API 調用\n",
        "            weather_result = get_current_weather(tool_call[\"args\"][\"location\"])\n",
        "            print(f\"\\n🌤️  天氣資訊:\\n{weather_result}\\n\")\n",
        "\n",
        "            # 將結果加入訊息鏈\n",
        "            messages.append(\n",
        "                ToolMessage(\n",
        "                    content=weather_result,\n",
        "                    tool_call_id=tool_call[\"id\"]\n",
        "                )\n",
        "            )\n",
        "\n",
        "    # 第三步：LLM 生成最終回答\n",
        "    final_response = llm_with_tools.invoke(messages)\n",
        "    print(f\"\\n✨ 最終回答:\\n{final_response.content}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9120949",
      "metadata": {
        "height": 30,
        "id": "e9120949",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d66f82fe-df61-49aa-e4b1-13104dc87f5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❓ 使用者問題: 台北現在天氣如何？\n",
            "\n",
            "\n",
            "============================================================\n",
            "第 1 輪\n",
            "============================================================\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[llm:ChatOpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"Human: 台北現在天氣如何？\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[llm:ChatOpenAI] [1.77s] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"tool_calls\",\n",
            "          \"logprobs\": null\n",
            "        },\n",
            "        \"type\": \"ChatGeneration\",\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessage\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"\",\n",
            "            \"additional_kwargs\": {\n",
            "              \"tool_calls\": [\n",
            "                {\n",
            "                  \"id\": \"call_WrwoZdUCm43oZPjERjqv43x2\",\n",
            "                  \"function\": {\n",
            "                    \"arguments\": \"{\\\"location\\\":\\\"台北\\\"}\",\n",
            "                    \"name\": \"ConvertLocationName\"\n",
            "                  },\n",
            "                  \"type\": \"function\"\n",
            "                }\n",
            "              ],\n",
            "              \"refusal\": null\n",
            "            },\n",
            "            \"response_metadata\": {\n",
            "              \"token_usage\": {\n",
            "                \"completion_tokens\": 16,\n",
            "                \"prompt_tokens\": 114,\n",
            "                \"total_tokens\": 130,\n",
            "                \"completion_tokens_details\": {\n",
            "                  \"accepted_prediction_tokens\": 0,\n",
            "                  \"audio_tokens\": 0,\n",
            "                  \"reasoning_tokens\": 0,\n",
            "                  \"rejected_prediction_tokens\": 0\n",
            "                },\n",
            "                \"prompt_tokens_details\": {\n",
            "                  \"audio_tokens\": 0,\n",
            "                  \"cached_tokens\": 0\n",
            "                }\n",
            "              },\n",
            "              \"model_name\": \"gpt-4o-2024-08-06\",\n",
            "              \"system_fingerprint\": \"fp_eb3c3cb84d\",\n",
            "              \"id\": \"chatcmpl-CQqtkS9IaMl5wRffeD65RxVdlLald\",\n",
            "              \"service_tier\": \"default\",\n",
            "              \"finish_reason\": \"tool_calls\",\n",
            "              \"logprobs\": null\n",
            "            },\n",
            "            \"type\": \"ai\",\n",
            "            \"id\": \"run--2bdfacd6-5564-48e1-b2bf-f13ef36060c9-0\",\n",
            "            \"tool_calls\": [\n",
            "              {\n",
            "                \"name\": \"ConvertLocationName\",\n",
            "                \"args\": {\n",
            "                  \"location\": \"台北\"\n",
            "                },\n",
            "                \"id\": \"call_WrwoZdUCm43oZPjERjqv43x2\",\n",
            "                \"type\": \"tool_call\"\n",
            "              }\n",
            "            ],\n",
            "            \"usage_metadata\": {\n",
            "              \"input_tokens\": 114,\n",
            "              \"output_tokens\": 16,\n",
            "              \"total_tokens\": 130,\n",
            "              \"input_token_details\": {\n",
            "                \"audio\": 0,\n",
            "                \"cache_read\": 0\n",
            "              },\n",
            "              \"output_token_details\": {\n",
            "                \"audio\": 0,\n",
            "                \"reasoning\": 0\n",
            "              }\n",
            "            },\n",
            "            \"invalid_tool_calls\": []\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": {\n",
            "    \"token_usage\": {\n",
            "      \"completion_tokens\": 16,\n",
            "      \"prompt_tokens\": 114,\n",
            "      \"total_tokens\": 130,\n",
            "      \"completion_tokens_details\": {\n",
            "        \"accepted_prediction_tokens\": 0,\n",
            "        \"audio_tokens\": 0,\n",
            "        \"reasoning_tokens\": 0,\n",
            "        \"rejected_prediction_tokens\": 0\n",
            "      },\n",
            "      \"prompt_tokens_details\": {\n",
            "        \"audio_tokens\": 0,\n",
            "        \"cached_tokens\": 0\n",
            "      }\n",
            "    },\n",
            "    \"model_name\": \"gpt-4o-2024-08-06\",\n",
            "    \"system_fingerprint\": \"fp_eb3c3cb84d\",\n",
            "    \"id\": \"chatcmpl-CQqtkS9IaMl5wRffeD65RxVdlLald\",\n",
            "    \"service_tier\": \"default\"\n",
            "  },\n",
            "  \"run\": null,\n",
            "  \"type\": \"LLMResult\"\n",
            "}\n",
            "\n",
            "🔧 調用工具: ConvertLocationName\n",
            "📝 參數: {'location': '台北'}\n",
            "🔄 地名轉換: 台北 -> Taipei\n",
            "\n",
            "📤 工具輸出:\n",
            "中文地名「台北」對應的英文名稱是「Taipei」\n",
            "\n",
            "============================================================\n",
            "第 2 輪\n",
            "============================================================\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[llm:ChatOpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"Human: 台北現在天氣如何？\\nAI: \\nTool: 中文地名「台北」對應的英文名稱是「Taipei」\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[llm:ChatOpenAI] [1.67s] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"tool_calls\",\n",
            "          \"logprobs\": null\n",
            "        },\n",
            "        \"type\": \"ChatGeneration\",\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessage\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"\",\n",
            "            \"additional_kwargs\": {\n",
            "              \"tool_calls\": [\n",
            "                {\n",
            "                  \"id\": \"call_uIvrcX6qpt95aAKJz8JpM828\",\n",
            "                  \"function\": {\n",
            "                    \"arguments\": \"{\\\"location\\\":\\\"Taipei\\\"}\",\n",
            "                    \"name\": \"GetWeather\"\n",
            "                  },\n",
            "                  \"type\": \"function\"\n",
            "                }\n",
            "              ],\n",
            "              \"refusal\": null\n",
            "            },\n",
            "            \"response_metadata\": {\n",
            "              \"token_usage\": {\n",
            "                \"completion_tokens\": 15,\n",
            "                \"prompt_tokens\": 156,\n",
            "                \"total_tokens\": 171,\n",
            "                \"completion_tokens_details\": {\n",
            "                  \"accepted_prediction_tokens\": 0,\n",
            "                  \"audio_tokens\": 0,\n",
            "                  \"reasoning_tokens\": 0,\n",
            "                  \"rejected_prediction_tokens\": 0\n",
            "                },\n",
            "                \"prompt_tokens_details\": {\n",
            "                  \"audio_tokens\": 0,\n",
            "                  \"cached_tokens\": 0\n",
            "                }\n",
            "              },\n",
            "              \"model_name\": \"gpt-4o-2024-08-06\",\n",
            "              \"system_fingerprint\": \"fp_eb3c3cb84d\",\n",
            "              \"id\": \"chatcmpl-CQqtlCvoQ3yveW8JuSXFokGLiPiEd\",\n",
            "              \"service_tier\": \"default\",\n",
            "              \"finish_reason\": \"tool_calls\",\n",
            "              \"logprobs\": null\n",
            "            },\n",
            "            \"type\": \"ai\",\n",
            "            \"id\": \"run--8705f5f0-98c7-415b-a7cc-5ac0bf3bfc55-0\",\n",
            "            \"tool_calls\": [\n",
            "              {\n",
            "                \"name\": \"GetWeather\",\n",
            "                \"args\": {\n",
            "                  \"location\": \"Taipei\"\n",
            "                },\n",
            "                \"id\": \"call_uIvrcX6qpt95aAKJz8JpM828\",\n",
            "                \"type\": \"tool_call\"\n",
            "              }\n",
            "            ],\n",
            "            \"usage_metadata\": {\n",
            "              \"input_tokens\": 156,\n",
            "              \"output_tokens\": 15,\n",
            "              \"total_tokens\": 171,\n",
            "              \"input_token_details\": {\n",
            "                \"audio\": 0,\n",
            "                \"cache_read\": 0\n",
            "              },\n",
            "              \"output_token_details\": {\n",
            "                \"audio\": 0,\n",
            "                \"reasoning\": 0\n",
            "              }\n",
            "            },\n",
            "            \"invalid_tool_calls\": []\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": {\n",
            "    \"token_usage\": {\n",
            "      \"completion_tokens\": 15,\n",
            "      \"prompt_tokens\": 156,\n",
            "      \"total_tokens\": 171,\n",
            "      \"completion_tokens_details\": {\n",
            "        \"accepted_prediction_tokens\": 0,\n",
            "        \"audio_tokens\": 0,\n",
            "        \"reasoning_tokens\": 0,\n",
            "        \"rejected_prediction_tokens\": 0\n",
            "      },\n",
            "      \"prompt_tokens_details\": {\n",
            "        \"audio_tokens\": 0,\n",
            "        \"cached_tokens\": 0\n",
            "      }\n",
            "    },\n",
            "    \"model_name\": \"gpt-4o-2024-08-06\",\n",
            "    \"system_fingerprint\": \"fp_eb3c3cb84d\",\n",
            "    \"id\": \"chatcmpl-CQqtlCvoQ3yveW8JuSXFokGLiPiEd\",\n",
            "    \"service_tier\": \"default\"\n",
            "  },\n",
            "  \"run\": null,\n",
            "  \"type\": \"LLMResult\"\n",
            "}\n",
            "\n",
            "🔧 調用工具: GetWeather\n",
            "📝 參數: {'location': 'Taipei'}\n",
            "✅ 找到位置: Taipei, Taiwan\n",
            "\n",
            "📤 工具輸出:\n",
            "地點: Taipei, Taiwan\n",
            "溫度: 31.2°C\n",
            "體感溫度: 32.7°C\n",
            "天氣狀況: 晴朗\n",
            "濕度: 54%\n",
            "風速: 18.8 km/h\n",
            "風向: 東\n",
            "\n",
            "============================================================\n",
            "第 3 輪\n",
            "============================================================\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[llm:ChatOpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"Human: 台北現在天氣如何？\\nAI: \\nTool: 中文地名「台北」對應的英文名稱是「Taipei」\\nAI: \\nTool: 地點: Taipei, Taiwan\\n溫度: 31.2°C\\n體感溫度: 32.7°C\\n天氣狀況: 晴朗\\n濕度: 54%\\n風速: 18.8 km/h\\n風向: 東\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[llm:ChatOpenAI] [2.19s] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"台北現在的天氣是晴朗，溫度為31.2°C，體感溫度32.7°C，濕度54%，風速18.8 km/h，風向為東。\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"stop\",\n",
            "          \"logprobs\": null\n",
            "        },\n",
            "        \"type\": \"ChatGeneration\",\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessage\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"台北現在的天氣是晴朗，溫度為31.2°C，體感溫度32.7°C，濕度54%，風速18.8 km/h，風向為東。\",\n",
            "            \"additional_kwargs\": {\n",
            "              \"refusal\": null\n",
            "            },\n",
            "            \"response_metadata\": {\n",
            "              \"token_usage\": {\n",
            "                \"completion_tokens\": 48,\n",
            "                \"prompt_tokens\": 239,\n",
            "                \"total_tokens\": 287,\n",
            "                \"completion_tokens_details\": {\n",
            "                  \"accepted_prediction_tokens\": 0,\n",
            "                  \"audio_tokens\": 0,\n",
            "                  \"reasoning_tokens\": 0,\n",
            "                  \"rejected_prediction_tokens\": 0\n",
            "                },\n",
            "                \"prompt_tokens_details\": {\n",
            "                  \"audio_tokens\": 0,\n",
            "                  \"cached_tokens\": 0\n",
            "                }\n",
            "              },\n",
            "              \"model_name\": \"gpt-4o-2024-08-06\",\n",
            "              \"system_fingerprint\": \"fp_eb3c3cb84d\",\n",
            "              \"id\": \"chatcmpl-CQqtpqDGuiNrQw7ssQFGoYTKrGSA9\",\n",
            "              \"service_tier\": \"default\",\n",
            "              \"finish_reason\": \"stop\",\n",
            "              \"logprobs\": null\n",
            "            },\n",
            "            \"type\": \"ai\",\n",
            "            \"id\": \"run--667c3964-1fa6-46ee-adee-88033ae602af-0\",\n",
            "            \"usage_metadata\": {\n",
            "              \"input_tokens\": 239,\n",
            "              \"output_tokens\": 48,\n",
            "              \"total_tokens\": 287,\n",
            "              \"input_token_details\": {\n",
            "                \"audio\": 0,\n",
            "                \"cache_read\": 0\n",
            "              },\n",
            "              \"output_token_details\": {\n",
            "                \"audio\": 0,\n",
            "                \"reasoning\": 0\n",
            "              }\n",
            "            },\n",
            "            \"tool_calls\": [],\n",
            "            \"invalid_tool_calls\": []\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": {\n",
            "    \"token_usage\": {\n",
            "      \"completion_tokens\": 48,\n",
            "      \"prompt_tokens\": 239,\n",
            "      \"total_tokens\": 287,\n",
            "      \"completion_tokens_details\": {\n",
            "        \"accepted_prediction_tokens\": 0,\n",
            "        \"audio_tokens\": 0,\n",
            "        \"reasoning_tokens\": 0,\n",
            "        \"rejected_prediction_tokens\": 0\n",
            "      },\n",
            "      \"prompt_tokens_details\": {\n",
            "        \"audio_tokens\": 0,\n",
            "        \"cached_tokens\": 0\n",
            "      }\n",
            "    },\n",
            "    \"model_name\": \"gpt-4o-2024-08-06\",\n",
            "    \"system_fingerprint\": \"fp_eb3c3cb84d\",\n",
            "    \"id\": \"chatcmpl-CQqtpqDGuiNrQw7ssQFGoYTKrGSA9\",\n",
            "    \"service_tier\": \"default\"\n",
            "  },\n",
            "  \"run\": null,\n",
            "  \"type\": \"LLMResult\"\n",
            "}\n",
            "\n",
            "✨ 最終回答:\n",
            "台北現在的天氣是晴朗，溫度為31.2°C，體感溫度32.7°C，濕度54%，風速18.8 km/h，風向為東。\n",
            "\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import HumanMessage, ToolMessage\n",
        "from pydantic import BaseModel, Field\n",
        "import requests\n",
        "from langchain.globals import set_verbose, set_debug\n",
        "\n",
        "# 開啟全域 verbose 和 debug 模式\n",
        "set_verbose(True)\n",
        "set_debug(True)\n",
        "\n",
        "# 初始化 LLM\n",
        "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
        "\n",
        "\n",
        "# 工具 1: 地名轉換工具\n",
        "class ConvertLocationName(BaseModel):\n",
        "    \"\"\"Convert Chinese location names to English standard names for weather API\"\"\"\n",
        "\n",
        "    location: str = Field(..., description=\"中文地名，例如：台北、高雄、台中\")\n",
        "\n",
        "\n",
        "# 工具 2: 天氣查詢工具\n",
        "class GetWeather(BaseModel):\n",
        "    \"\"\"Get the current weather in a given location (use English location name)\"\"\"\n",
        "\n",
        "    location: str = Field(..., description=\"English location name, e.g. Taipei, Kaohsiung\")\n",
        "\n",
        "\n",
        "def convert_location_name(location: str) -> str:\n",
        "    \"\"\"\n",
        "    將台灣的中文地名轉換為英文標準名稱\n",
        "    \"\"\"\n",
        "    # 台灣地名對照表\n",
        "    taiwan_locations = {\n",
        "        # 直轄市\n",
        "        \"台北\": \"Taipei\",\n",
        "        \"臺北\": \"Taipei\",\n",
        "        \"台北市\": \"Taipei\",\n",
        "        \"新北\": \"New Taipei City\",\n",
        "        \"新北市\": \"New Taipei City\",\n",
        "        \"桃園\": \"Taoyuan\",\n",
        "        \"桃園市\": \"Taoyuan\",\n",
        "        \"台中\": \"Taichung\",\n",
        "        \"臺中\": \"Taichung\",\n",
        "        \"台中市\": \"Taichung\",\n",
        "        \"台南\": \"Tainan\",\n",
        "        \"臺南\": \"Tainan\",\n",
        "        \"台南市\": \"Tainan\",\n",
        "        \"高雄\": \"Kaohsiung\",\n",
        "        \"高雄市\": \"Kaohsiung\",\n",
        "\n",
        "        # 縣市\n",
        "        \"基隆\": \"Keelung\",\n",
        "        \"基隆市\": \"Keelung\",\n",
        "        \"新竹\": \"Hsinchu\",\n",
        "        \"新竹市\": \"Hsinchu\",\n",
        "        \"新竹縣\": \"Hsinchu County\",\n",
        "        \"苗栗\": \"Miaoli\",\n",
        "        \"苗栗縣\": \"Miaoli\",\n",
        "        \"彰化\": \"Changhua\",\n",
        "        \"彰化縣\": \"Changhua\",\n",
        "        \"南投\": \"Nantou\",\n",
        "        \"南投縣\": \"Nantou\",\n",
        "        \"雲林\": \"Yunlin\",\n",
        "        \"雲林縣\": \"Yunlin\",\n",
        "        \"嘉義\": \"Chiayi\",\n",
        "        \"嘉義市\": \"Chiayi City\",\n",
        "        \"嘉義縣\": \"Chiayi County\",\n",
        "        \"屏東\": \"Pingtung\",\n",
        "        \"屏東縣\": \"Pingtung\",\n",
        "        \"宜蘭\": \"Yilan\",\n",
        "        \"宜蘭縣\": \"Yilan\",\n",
        "        \"花蓮\": \"Hualien\",\n",
        "        \"花蓮縣\": \"Hualien\",\n",
        "        \"台東\": \"Taitung\",\n",
        "        \"臺東\": \"Taitung\",\n",
        "        \"台東縣\": \"Taitung\",\n",
        "        \"澎湖\": \"Penghu\",\n",
        "        \"澎湖縣\": \"Penghu\",\n",
        "        \"金門\": \"Kinmen\",\n",
        "        \"金門縣\": \"Kinmen\",\n",
        "        \"連江\": \"Lienchiang\",\n",
        "        \"連江縣\": \"Lienchiang\",\n",
        "        \"馬祖\": \"Matsu\",\n",
        "    }\n",
        "\n",
        "    # 移除空白並查找對應\n",
        "    location_clean = location.strip()\n",
        "\n",
        "    if location_clean in taiwan_locations:\n",
        "        english_name = taiwan_locations[location_clean]\n",
        "        result = f\"中文地名「{location}」對應的英文名稱是「{english_name}」\"\n",
        "        print(f\"🔄 地名轉換: {location} -> {english_name}\")\n",
        "        return result\n",
        "    else:\n",
        "        # 如果找不到，返回原始名稱並提示\n",
        "        result = f\"無法找到「{location}」的標準英文名稱，建議使用：{location}\"\n",
        "        print(f\"⚠️  未找到對應: {location}\")\n",
        "        return result\n",
        "\n",
        "\n",
        "def get_coordinates(location: str) -> dict:\n",
        "    \"\"\"使用 Open-Meteo 的 Geocoding API 獲取城市的經緯度\"\"\"\n",
        "    geocoding_url = \"https://geocoding-api.open-meteo.com/v1/search\"\n",
        "\n",
        "    params = {\n",
        "        \"name\": location,\n",
        "        \"count\": 1,\n",
        "        \"language\": \"en\",\n",
        "        \"format\": \"json\"\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.get(geocoding_url, params=params)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "\n",
        "        if \"results\" in data and len(data[\"results\"]) > 0:\n",
        "            result = data[\"results\"][0]\n",
        "            print(f\"✅ 找到位置: {result['name']}, {result.get('country', '')}\")\n",
        "            return {\n",
        "                \"latitude\": result[\"latitude\"],\n",
        "                \"longitude\": result[\"longitude\"],\n",
        "                \"name\": result[\"name\"],\n",
        "                \"country\": result.get(\"country\", \"\"),\n",
        "                \"admin1\": result.get(\"admin1\", \"\")\n",
        "            }\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"地理編碼錯誤: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def get_current_weather(location: str) -> str:\n",
        "    \"\"\"使用 Open-Meteo API 獲取實際天氣數據\"\"\"\n",
        "    # 獲取城市的經緯度\n",
        "    coords = get_coordinates(location)\n",
        "\n",
        "    if not coords:\n",
        "        return f\"找不到 '{location}' 的位置資訊\"\n",
        "\n",
        "    # 使用經緯度獲取天氣\n",
        "    weather_url = \"https://api.open-meteo.com/v1/forecast\"\n",
        "\n",
        "    params = {\n",
        "        \"latitude\": coords[\"latitude\"],\n",
        "        \"longitude\": coords[\"longitude\"],\n",
        "        \"current\": [\n",
        "            \"temperature_2m\",\n",
        "            \"relative_humidity_2m\",\n",
        "            \"apparent_temperature\",\n",
        "            \"weather_code\",\n",
        "            \"wind_speed_10m\",\n",
        "            \"wind_direction_10m\"\n",
        "        ],\n",
        "        \"timezone\": \"auto\"\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.get(weather_url, params=params)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "\n",
        "        current = data[\"current\"]\n",
        "\n",
        "        # 天氣代碼對應描述\n",
        "        weather_codes = {\n",
        "            0: \"晴朗\", 1: \"大致晴朗\", 2: \"局部多雲\", 3: \"多雲\",\n",
        "            45: \"有霧\", 48: \"霧淞\", 51: \"小雨\", 53: \"中雨\", 55: \"大雨\",\n",
        "            61: \"小雨\", 63: \"中雨\", 65: \"大雨\", 71: \"小雪\", 73: \"中雪\",\n",
        "            75: \"大雪\", 80: \"陣雨\", 81: \"中度陣雨\", 82: \"強烈陣雨\",\n",
        "            95: \"雷暴\"\n",
        "        }\n",
        "\n",
        "        weather_description = weather_codes.get(current[\"weather_code\"], \"未知天氣\")\n",
        "\n",
        "        # 風向轉換\n",
        "        directions = [\"北\", \"東北\", \"東\", \"東南\", \"南\", \"西南\", \"西\", \"西北\"]\n",
        "        direction_index = int((current[\"wind_direction_10m\"] + 22.5) / 45) % 8\n",
        "        wind_dir_text = directions[direction_index]\n",
        "\n",
        "        # 格式化結果\n",
        "        location_name = coords[\"name\"]\n",
        "        if coords[\"country\"]:\n",
        "            location_name += f\", {coords['country']}\"\n",
        "\n",
        "        weather_info = f\"\"\"\n",
        "地點: {location_name}\n",
        "溫度: {current['temperature_2m']}°C\n",
        "體感溫度: {current['apparent_temperature']}°C\n",
        "天氣狀況: {weather_description}\n",
        "濕度: {current['relative_humidity_2m']}%\n",
        "風速: {current['wind_speed_10m']} km/h\n",
        "風向: {wind_dir_text}\n",
        "        \"\"\".strip()\n",
        "\n",
        "        return weather_info\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"獲取天氣資訊時發生錯誤: {str(e)}\"\n",
        "\n",
        "\n",
        "# 綁定兩個工具到 LLM\n",
        "llm_with_tools = llm.bind_tools([ConvertLocationName, GetWeather])\n",
        "\n",
        "# 台北天氣查詢\n",
        "user_question = \"台北現在天氣如何？\"\n",
        "\n",
        "print(f\"❓ 使用者問題: {user_question}\\n\")\n",
        "\n",
        "# 開始多輪對話\n",
        "messages = [HumanMessage(content=user_question)]\n",
        "\n",
        "# 最多執行 5 輪工具調用\n",
        "max_iterations = 5\n",
        "for i in range(max_iterations):\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"第 {i+1} 輪\")\n",
        "    print('='*60)\n",
        "\n",
        "    # LLM 決定下一步\n",
        "    ai_msg = llm_with_tools.invoke(messages)\n",
        "    messages.append(ai_msg)\n",
        "\n",
        "    # 如果沒有工具調用，表示已經完成\n",
        "    if not ai_msg.tool_calls:\n",
        "        print(f\"\\n✨ 最終回答:\\n{ai_msg.content}\")\n",
        "        break\n",
        "\n",
        "    # 執行所有工具調用\n",
        "    for tool_call in ai_msg.tool_calls:\n",
        "        tool_name = tool_call[\"name\"]\n",
        "        tool_args = tool_call[\"args\"]\n",
        "\n",
        "        print(f\"\\n🔧 調用工具: {tool_name}\")\n",
        "        print(f\"📝 參數: {tool_args}\")\n",
        "\n",
        "        # 根據工具名稱執行對應函數\n",
        "        if tool_name == \"ConvertLocationName\":\n",
        "            result = convert_location_name(tool_args[\"location\"])\n",
        "        elif tool_name == \"GetWeather\":\n",
        "            result = get_current_weather(tool_args[\"location\"])\n",
        "        else:\n",
        "            result = f\"未知工具: {tool_name}\"\n",
        "\n",
        "        print(f\"\\n📤 工具輸出:\\n{result}\")\n",
        "\n",
        "        # 將工具結果加入訊息鏈\n",
        "        messages.append(\n",
        "            ToolMessage(\n",
        "                content=result,\n",
        "                tool_call_id=tool_call[\"id\"]\n",
        "            )\n",
        "        )\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55849fb5",
      "metadata": {
        "height": 30,
        "id": "55849fb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f0f7c12-e026-47d4-f2f6-4eb99383d579"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❓ 使用者問題: 台北現在天氣如何？\n",
            "\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `convert_location_name` with `{'location': '台北'}`\n",
            "\n",
            "\n",
            "\u001b[0m🔄 地名轉換: 台北 -> Taipei\n",
            "\u001b[36;1m\u001b[1;3m中文地名「台北」對應的英文名稱是「Taipei」\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `get_weather` with `{'location': 'Taipei'}`\n",
            "\n",
            "\n",
            "\u001b[0m✅ 找到位置: Taipei, Taiwan\n",
            "\u001b[33;1m\u001b[1;3m地點: Taipei, Taiwan\n",
            "溫度: 31.2°C\n",
            "體感溫度: 32.7°C\n",
            "天氣狀況: 晴朗\n",
            "濕度: 54%\n",
            "風速: 18.8 km/h\n",
            "風向: 東\u001b[0m\u001b[32;1m\u001b[1;3m台北現在的天氣狀況如下：\n",
            "\n",
            "- 溫度：31.2°C\n",
            "- 體感溫度：32.7°C\n",
            "- 天氣狀況：晴朗\n",
            "- 濕度：54%\n",
            "- 風速：18.8 km/h\n",
            "- 風向：東\n",
            "\n",
            "希望這些資訊對你有幫助！\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "============================================================\n",
            "✨ 最終結果:\n",
            "台北現在的天氣狀況如下：\n",
            "\n",
            "- 溫度：31.2°C\n",
            "- 體感溫度：32.7°C\n",
            "- 天氣狀況：晴朗\n",
            "- 濕度：54%\n",
            "- 風速：18.8 km/h\n",
            "- 風向：東\n",
            "\n",
            "希望這些資訊對你有幫助！\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langchain_core.tools import tool\n",
        "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "import requests\n",
        "from langchain.globals import set_verbose, set_debug\n",
        "\n",
        "# 開啟全域 verbose 和 debug 模式\n",
        "set_verbose(True)\n",
        "set_debug(False)\n",
        "\n",
        "# 初始化 LLM\n",
        "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
        "\n",
        "\n",
        "@tool\n",
        "def convert_location_name(location: str) -> str:\n",
        "    \"\"\"\n",
        "    Convert Chinese location names to English standard names for weather API.\n",
        "\n",
        "    Args:\n",
        "        location: 中文地名，例如：台北、高雄、台中\n",
        "    \"\"\"\n",
        "    # 台灣地名對照表\n",
        "    taiwan_locations = {\n",
        "        # 直轄市\n",
        "        \"台北\": \"Taipei\",\n",
        "        \"臺北\": \"Taipei\",\n",
        "        \"台北市\": \"Taipei\",\n",
        "        \"新北\": \"New Taipei City\",\n",
        "        \"新北市\": \"New Taipei City\",\n",
        "        \"桃園\": \"Taoyuan\",\n",
        "        \"桃園市\": \"Taoyuan\",\n",
        "        \"台中\": \"Taichung\",\n",
        "        \"臺中\": \"Taichung\",\n",
        "        \"台中市\": \"Taichung\",\n",
        "        \"台南\": \"Tainan\",\n",
        "        \"臺南\": \"Tainan\",\n",
        "        \"台南市\": \"Tainan\",\n",
        "        \"高雄\": \"Kaohsiung\",\n",
        "        \"高雄市\": \"Kaohsiung\",\n",
        "\n",
        "        # 縣市\n",
        "        \"基隆\": \"Keelung\",\n",
        "        \"基隆市\": \"Keelung\",\n",
        "        \"新竹\": \"Hsinchu\",\n",
        "        \"新竹市\": \"Hsinchu\",\n",
        "        \"新竹縣\": \"Hsinchu County\",\n",
        "        \"苗栗\": \"Miaoli\",\n",
        "        \"苗栗縣\": \"Miaoli\",\n",
        "        \"彰化\": \"Changhua\",\n",
        "        \"彰化縣\": \"Changhua\",\n",
        "        \"南投\": \"Nantou\",\n",
        "        \"南投縣\": \"Nantou\",\n",
        "        \"雲林\": \"Yunlin\",\n",
        "        \"雲林縣\": \"Yunlin\",\n",
        "        \"嘉義\": \"Chiayi\",\n",
        "        \"嘉義市\": \"Chiayi City\",\n",
        "        \"嘉義縣\": \"Chiayi County\",\n",
        "        \"屏東\": \"Pingtung\",\n",
        "        \"屏東縣\": \"Pingtung\",\n",
        "        \"宜蘭\": \"Yilan\",\n",
        "        \"宜蘭縣\": \"Yilan\",\n",
        "        \"花蓮\": \"Hualien\",\n",
        "        \"花蓮縣\": \"Hualien\",\n",
        "        \"台東\": \"Taitung\",\n",
        "        \"臺東\": \"Taitung\",\n",
        "        \"台東縣\": \"Taitung\",\n",
        "        \"澎湖\": \"Penghu\",\n",
        "        \"澎湖縣\": \"Penghu\",\n",
        "        \"金門\": \"Kinmen\",\n",
        "        \"金門縣\": \"Kinmen\",\n",
        "        \"連江\": \"Lienchiang\",\n",
        "        \"連江縣\": \"Lienchiang\",\n",
        "        \"馬祖\": \"Matsu\",\n",
        "    }\n",
        "\n",
        "    # 移除空白並查找對應\n",
        "    location_clean = location.strip()\n",
        "\n",
        "    if location_clean in taiwan_locations:\n",
        "        english_name = taiwan_locations[location_clean]\n",
        "        result = f\"中文地名「{location}」對應的英文名稱是「{english_name}」\"\n",
        "        print(f\"🔄 地名轉換: {location} -> {english_name}\")\n",
        "        return result\n",
        "    else:\n",
        "        result = f\"無法找到「{location}」的標準英文名稱，建議使用：{location}\"\n",
        "        print(f\"⚠️  未找到對應: {location}\")\n",
        "        return result\n",
        "\n",
        "\n",
        "def _get_coordinates(location: str) -> dict:\n",
        "    \"\"\"使用 Open-Meteo 的 Geocoding API 獲取城市的經緯度\"\"\"\n",
        "    geocoding_url = \"https://geocoding-api.open-meteo.com/v1/search\"\n",
        "\n",
        "    params = {\n",
        "        \"name\": location,\n",
        "        \"count\": 1,\n",
        "        \"language\": \"en\",\n",
        "        \"format\": \"json\"\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.get(geocoding_url, params=params)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "\n",
        "        if \"results\" in data and len(data[\"results\"]) > 0:\n",
        "            result = data[\"results\"][0]\n",
        "            print(f\"✅ 找到位置: {result['name']}, {result.get('country', '')}\")\n",
        "            return {\n",
        "                \"latitude\": result[\"latitude\"],\n",
        "                \"longitude\": result[\"longitude\"],\n",
        "                \"name\": result[\"name\"],\n",
        "                \"country\": result.get(\"country\", \"\"),\n",
        "                \"admin1\": result.get(\"admin1\", \"\")\n",
        "            }\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"地理編碼錯誤: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "@tool\n",
        "def get_weather(location: str) -> str:\n",
        "    \"\"\"\n",
        "    Get the current weather in a given location using Open-Meteo API.\n",
        "\n",
        "    Args:\n",
        "        location: English location name, e.g. Taipei, Kaohsiung\n",
        "    \"\"\"\n",
        "    # 獲取城市的經緯度\n",
        "    coords = _get_coordinates(location)\n",
        "\n",
        "    if not coords:\n",
        "        return f\"找不到 '{location}' 的位置資訊\"\n",
        "\n",
        "    # 使用經緯度獲取天氣\n",
        "    weather_url = \"https://api.open-meteo.com/v1/forecast\"\n",
        "\n",
        "    params = {\n",
        "        \"latitude\": coords[\"latitude\"],\n",
        "        \"longitude\": coords[\"longitude\"],\n",
        "        \"current\": [\n",
        "            \"temperature_2m\",\n",
        "            \"relative_humidity_2m\",\n",
        "            \"apparent_temperature\",\n",
        "            \"weather_code\",\n",
        "            \"wind_speed_10m\",\n",
        "            \"wind_direction_10m\"\n",
        "        ],\n",
        "        \"timezone\": \"auto\"\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.get(weather_url, params=params)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "\n",
        "        current = data[\"current\"]\n",
        "\n",
        "        # 天氣代碼對應描述\n",
        "        weather_codes = {\n",
        "            0: \"晴朗\", 1: \"大致晴朗\", 2: \"局部多雲\", 3: \"多雲\",\n",
        "            45: \"有霧\", 48: \"霧淞\", 51: \"小雨\", 53: \"中雨\", 55: \"大雨\",\n",
        "            61: \"小雨\", 63: \"中雨\", 65: \"大雨\", 71: \"小雪\", 73: \"中雪\",\n",
        "            75: \"大雪\", 80: \"陣雨\", 81: \"中度陣雨\", 82: \"強烈陣雨\",\n",
        "            95: \"雷暴\"\n",
        "        }\n",
        "\n",
        "        weather_description = weather_codes.get(current[\"weather_code\"], \"未知天氣\")\n",
        "\n",
        "        # 風向轉換\n",
        "        directions = [\"北\", \"東北\", \"東\", \"東南\", \"南\", \"西南\", \"西\", \"西北\"]\n",
        "        direction_index = int((current[\"wind_direction_10m\"] + 22.5) / 45) % 8\n",
        "        wind_dir_text = directions[direction_index]\n",
        "\n",
        "        # 格式化結果\n",
        "        location_name = coords[\"name\"]\n",
        "        if coords[\"country\"]:\n",
        "            location_name += f\", {coords['country']}\"\n",
        "\n",
        "        weather_info = f\"\"\"\n",
        "地點: {location_name}\n",
        "溫度: {current['temperature_2m']}°C\n",
        "體感溫度: {current['apparent_temperature']}°C\n",
        "天氣狀況: {weather_description}\n",
        "濕度: {current['relative_humidity_2m']}%\n",
        "風速: {current['wind_speed_10m']} km/h\n",
        "風向: {wind_dir_text}\n",
        "        \"\"\".strip()\n",
        "\n",
        "        return weather_info\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"獲取天氣資訊時發生錯誤: {str(e)}\"\n",
        "\n",
        "\n",
        "# 定義工具列表\n",
        "tools = [convert_location_name, get_weather]\n",
        "\n",
        "# 創建 prompt\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"你是一個天氣助手。當用戶詢問中文地名的天氣時，請先使用 convert_location_name 工具將地名轉換為英文，然後使用 get_weather 工具查詢天氣。\"),\n",
        "    (\"human\", \"{input}\"),\n",
        "    (\"placeholder\", \"{agent_scratchpad}\"),\n",
        "])\n",
        "\n",
        "# 創建 agent\n",
        "agent = create_tool_calling_agent(llm, tools, prompt)\n",
        "\n",
        "# 創建 agent executor\n",
        "agent_executor = AgentExecutor(\n",
        "    agent=agent,\n",
        "    tools=tools,\n",
        "    verbose=True,\n",
        "    handle_parsing_errors=True\n",
        ")\n",
        "\n",
        "# 執行查詢\n",
        "user_question = \"台北現在天氣如何？\"\n",
        "print(f\"❓ 使用者問題: {user_question}\\n\")\n",
        "\n",
        "result = agent_executor.invoke({\"input\": user_question})\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"✨ 最終結果:\\n{result['output']}\")\n",
        "print('='*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94ae491b",
      "metadata": {
        "height": 30,
        "id": "94ae491b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7c3aec3",
      "metadata": {
        "height": 30,
        "id": "e7c3aec3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ae51a3f",
      "metadata": {
        "height": 30,
        "id": "5ae51a3f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06894001",
      "metadata": {
        "height": 30,
        "id": "06894001"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2fb674c",
      "metadata": {
        "height": 30,
        "id": "e2fb674c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5158f4c8",
      "metadata": {
        "height": 30,
        "id": "5158f4c8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cebe066",
      "metadata": {
        "height": 30,
        "id": "2cebe066"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65caee4d",
      "metadata": {
        "height": 30,
        "id": "65caee4d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04799230",
      "metadata": {
        "height": 30,
        "id": "04799230"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30795c10",
      "metadata": {
        "height": 30,
        "id": "30795c10"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08ed59c4",
      "metadata": {
        "height": 30,
        "id": "08ed59c4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb43eee3",
      "metadata": {
        "height": 30,
        "id": "bb43eee3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}