#!/usr/bin/env python3
"""
Week 2 - Lesson 1: Prompt Engineering åŸºç¤
æŒæ¡ Zero-shot, Few-shot, Chain-of-Thought æŠ€å·§
"""

import ollama
import json
from typing import List, Dict, Any
from dataclasses import dataclass
import time

@dataclass
class PromptResult:
    """Prompt åŸ·è¡Œçµæœ"""
    prompt: str
    response: str
    technique: str
    execution_time: float
    tokens_used: int = 0

class PromptEngineeringBasics:
    """Prompt Engineering åŸºç¤æŠ€å·§ç¤ºç¯„"""
    
    def __init__(self, model: str = "gemma:2b"):
        self.model = model
        self.results = []
    
    def zero_shot_demo(self) -> List[PromptResult]:
        """Zero-shot Prompting ç¤ºç¯„"""
        print("\n" + "=" * 60)
        print("ğŸ¯ Zero-shot Prompting")
        print("=" * 60)
        print("å®šç¾©ï¼šç›´æ¥çµ¦å‡ºä»»å‹™æè¿°ï¼Œä¸æä¾›ç¯„ä¾‹\n")
        
        examples = [
            {
                "task": "æƒ…æ„Ÿåˆ†æ",
                "prompt": """åˆ¤æ–·ä»¥ä¸‹è©•è«–çš„æƒ…æ„Ÿï¼ˆæ­£é¢/è² é¢/ä¸­æ€§ï¼‰ï¼š

è©•è«–ï¼šé€™å®¶é¤å»³çš„æœå‹™å¾ˆå¥½ï¼Œä½†é£Ÿç‰©æ™®é€šï¼Œåƒ¹æ ¼åé«˜ã€‚
æƒ…æ„Ÿï¼š"""
            },
            {
                "task": "æ–‡å­—åˆ†é¡",
                "prompt": """å°‡ä»¥ä¸‹æ–°èæ¨™é¡Œåˆ†é¡ï¼ˆç§‘æŠ€/é«”è‚²/å¨›æ¨‚/æ”¿æ²»ï¼‰ï¼š

æ¨™é¡Œï¼šæ–°æ¬¾ iPhone ç™¼è¡¨ï¼Œæ­è¼‰æ›´å¼·å¤§çš„ AI åŠŸèƒ½
é¡åˆ¥ï¼š"""
            },
            {
                "task": "æ‘˜è¦ç”Ÿæˆ",
                "prompt": """ç”¨ä¸€å¥è©±ç¸½çµä»¥ä¸‹æ®µè½ï¼š

äººå·¥æ™ºæ…§æ­£åœ¨æ”¹è®Šæˆ‘å€‘çš„ç”Ÿæ´»æ–¹å¼ã€‚å¾æ™ºæ…§å‹æ‰‹æ©Ÿçš„èªéŸ³åŠ©ç†ï¼Œ
åˆ°è‡ªå‹•é§•é§›æ±½è»Šï¼Œå†åˆ°é†«ç™‚è¨ºæ–·ç³»çµ±ï¼ŒAI æŠ€è¡“å·²ç¶“æ»²é€åˆ°å„å€‹é ˜åŸŸã€‚
é€™äº›æ‡‰ç”¨ä¸åƒ…æé«˜äº†æ•ˆç‡ï¼Œä¹Ÿç‚ºäººé¡å¸¶ä¾†äº†å‰æ‰€æœªæœ‰çš„ä¾¿åˆ©ã€‚

ç¸½çµï¼š"""
            }
        ]
        
        results = []
        for example in examples:
            print(f"ğŸ“ ä»»å‹™: {example['task']}")
            print(f"Prompt:\n{example['prompt']}")
            
            start = time.time()
            response = ollama.generate(
                model=self.model,
                prompt=example['prompt'],
                options={'temperature': 0.3}  # ä½æº«åº¦forä¸€è‡´æ€§
            )
            elapsed = time.time() - start
            
            result = PromptResult(
                prompt=example['prompt'],
                response=response['response'],
                technique="Zero-shot",
                execution_time=elapsed,
                tokens_used=response.get('eval_count', 0)
            )
            
            print(f"ğŸ’¬ å›æ‡‰: {result.response}")
            print(f"â±ï¸  æ™‚é–“: {elapsed:.2f}ç§’")
            print("-" * 40)
            
            results.append(result)
            self.results.append(result)
        
        return results
    
    def few_shot_demo(self) -> List[PromptResult]:
        """Few-shot Prompting ç¤ºç¯„"""
        print("\n" + "=" * 60)
        print("ğŸ¯ Few-shot Prompting")
        print("=" * 60)
        print("å®šç¾©ï¼šæä¾› 2-5 å€‹ç¯„ä¾‹ï¼Œè®“æ¨¡å‹å­¸ç¿’æ¨¡å¼\n")
        
        examples = [
            {
                "task": "æ ¼å¼è½‰æ›",
                "prompt": """å°‡æ—¥æœŸè½‰æ›ç‚ºæ¨™æº–æ ¼å¼ (YYYY-MM-DD)ï¼š

è¼¸å…¥ï¼š3æœˆ15æ—¥2024å¹´
è¼¸å‡ºï¼š2024-03-15

è¼¸å…¥ï¼š2023å¹´12æœˆ1æ—¥
è¼¸å‡ºï¼š2023-12-01

è¼¸å…¥ï¼š7æœˆ20æ—¥2025å¹´
è¼¸å‡ºï¼š2025-07-20

è¼¸å…¥ï¼š2024å¹´5æœˆ8æ—¥
è¼¸å‡ºï¼š"""
            },
            {
                "task": "æƒ…æ„Ÿåˆ†æ•¸è©•åˆ†",
                "prompt": """æ ¹æ“šè©•è«–çµ¦å‡ºæƒ…æ„Ÿåˆ†æ•¸ï¼ˆ1-5åˆ†ï¼Œ5åˆ†æœ€æ­£é¢ï¼‰ï¼š

è©•è«–ï¼šå¤ªæ£’äº†ï¼å®Œå…¨è¶…å‡ºé æœŸï¼
åˆ†æ•¸ï¼š5

è©•è«–ï¼šé‚„å¯ä»¥ï¼Œæ²’ä»€éº¼ç‰¹åˆ¥çš„
åˆ†æ•¸ï¼š3

è©•è«–ï¼šå®Œå…¨ä¸æ¨è–¦ï¼Œæµªè²»éŒ¢
åˆ†æ•¸ï¼š1

è©•è«–ï¼šç›¸ç•¶ä¸éŒ¯ï¼Œç‰©è¶…æ‰€å€¼
åˆ†æ•¸ï¼š4

è©•è«–ï¼šå“è³ªå¾ˆå¥½ï¼Œä½†åƒ¹æ ¼æœ‰é»é«˜
åˆ†æ•¸ï¼š"""
            },
            {
                "task": "å¯¦é«”è­˜åˆ¥",
                "prompt": """å¾å¥å­ä¸­æå–äººåã€åœ°é»å’Œçµ„ç¹”ï¼š

å¥å­ï¼šå¼µä¸‰åœ¨å¾®è»Ÿå°åŒ—è¾¦å…¬å®¤å·¥ä½œ
çµæœï¼šäººå[å¼µä¸‰], åœ°é»[å°åŒ—], çµ„ç¹”[å¾®è»Ÿ]

å¥å­ï¼šæå››æ˜¨å¤©å»äº†Googleç¸½éƒ¨
çµæœï¼šäººå[æå››], åœ°é»[ç¸½éƒ¨], çµ„ç¹”[Google]

å¥å­ï¼šç‹äº”æ˜å¤©è¦å»è˜‹æœå…¬å¸é¢è©¦
çµæœï¼šäººå[ç‹äº”], åœ°é»[], çµ„ç¹”[è˜‹æœå…¬å¸]

å¥å­ï¼šé™³å…­åœ¨å°ç©é›»æ–°ç«¹å» å€ä¸Šç­
çµæœï¼š"""
            }
        ]
        
        results = []
        for example in examples:
            print(f"ğŸ“ ä»»å‹™: {example['task']}")
            print(f"Prompt:\n{example['prompt'][:200]}...")  # é¡¯ç¤ºéƒ¨åˆ†
            
            start = time.time()
            response = ollama.generate(
                model=self.model,
                prompt=example['prompt'],
                options={'temperature': 0.2}
            )
            elapsed = time.time() - start
            
            result = PromptResult(
                prompt=example['prompt'],
                response=response['response'],
                technique="Few-shot",
                execution_time=elapsed,
                tokens_used=response.get('eval_count', 0)
            )
            
            print(f"ğŸ’¬ å›æ‡‰: {result.response}")
            print(f"â±ï¸  æ™‚é–“: {elapsed:.2f}ç§’")
            print("-" * 40)
            
            results.append(result)
            self.results.append(result)
        
        return results
    
    def chain_of_thought_demo(self) -> List[PromptResult]:
        """Chain-of-Thought (CoT) Prompting ç¤ºç¯„"""
        print("\n" + "=" * 60)
        print("ğŸ¯ Chain-of-Thought (CoT) Prompting")
        print("=" * 60)
        print("å®šç¾©ï¼šå¼•å°æ¨¡å‹é€æ­¥æ€è€ƒï¼Œå±•ç¤ºæ¨ç†éç¨‹\n")
        
        examples = [
            {
                "task": "æ•¸å­¸å•é¡Œ",
                "prompt": """è§£æ±ºä»¥ä¸‹æ•¸å­¸å•é¡Œï¼Œè«‹ä¸€æ­¥æ­¥æ€è€ƒï¼š

å•é¡Œï¼šå°æ˜æœ‰ 45 å…ƒï¼Œè²·äº† 3 å€‹è˜‹æœï¼Œæ¯å€‹è˜‹æœ 8 å…ƒï¼Œåˆè²·äº†ä¸€ç“¶æ°´ 12 å…ƒã€‚
è«‹å•å°æ˜é‚„å‰©å¤šå°‘éŒ¢ï¼Ÿ

è®“æˆ‘å€‘ä¸€æ­¥æ­¥è¨ˆç®—ï¼š
1. é¦–å…ˆè¨ˆç®—è˜‹æœçš„ç¸½åƒ¹ï¼š
2. ç„¶å¾Œè¨ˆç®—ç¸½èŠ±è²»ï¼š
3. æœ€å¾Œè¨ˆç®—å‰©é¤˜çš„éŒ¢ï¼š

ç­”æ¡ˆï¼š"""
            },
            {
                "task": "é‚è¼¯æ¨ç†",
                "prompt": """è«‹ä¸€æ­¥æ­¥åˆ†æé€™å€‹é‚è¼¯å•é¡Œï¼š

å•é¡Œï¼šæ‰€æœ‰çš„è²“éƒ½æœ‰å°¾å·´ã€‚å’ªå’ªæ˜¯ä¸€éš»è²“ã€‚æ¹¯å§†æœ‰å°¾å·´ã€‚
è«‹å•ï¼šæˆ‘å€‘èƒ½ç¢ºå®šæ¹¯å§†æ˜¯è²“å—ï¼Ÿ

è®“æˆ‘å€‘é€æ­¥åˆ†æï¼š
1. å·²çŸ¥æ¢ä»¶æ•´ç†ï¼š
2. é‚è¼¯é—œä¿‚åˆ†æï¼š
3. å¾—å‡ºçµè«–ï¼š

ç­”æ¡ˆï¼š"""
            },
            {
                "task": "æ±ºç­–åˆ†æ",
                "prompt": """å¹«åŠ©åšå‡ºæ±ºç­–ï¼Œè«‹è©³ç´°åˆ†æï¼š

æƒ…æ³ï¼šä¸€å®¶å…¬å¸è¦æ±ºå®šæ˜¯å¦æ¨å‡ºæ–°ç”¢å“ã€‚
- é–‹ç™¼æˆæœ¬ï¼š100è¬
- é è¨ˆç¬¬ä¸€å¹´éŠ·å”®ï¼š50è¬
- é è¨ˆç¬¬äºŒå¹´éŠ·å”®ï¼š80è¬
- å¸‚å ´ç«¶çˆ­æ¿€çƒˆ
- å…¬å¸ç¾é‡‘æµå……è¶³

è«‹ä¸€æ­¥æ­¥åˆ†ææ˜¯å¦æ‡‰è©²æ¨å‡ºï¼š
1. æˆæœ¬æ•ˆç›Šåˆ†æï¼š
2. é¢¨éšªè©•ä¼°ï¼š
3. æ©Ÿæœƒæˆæœ¬ï¼š
4. å»ºè­°ï¼š

æ±ºç­–ï¼š"""
            }
        ]
        
        results = []
        for example in examples:
            print(f"ğŸ“ ä»»å‹™: {example['task']}")
            print(f"Prompt:\n{example['prompt'][:150]}...")
            
            start = time.time()
            response = ollama.generate(
                model=self.model,
                prompt=example['prompt'],
                options={'temperature': 0.3}
            )
            elapsed = time.time() - start
            
            result = PromptResult(
                prompt=example['prompt'],
                response=response['response'],
                technique="Chain-of-Thought",
                execution_time=elapsed,
                tokens_used=response.get('eval_count', 0)
            )
            
            print(f"ğŸ’¬ å›æ‡‰:\n{result.response[:300]}...")
            print(f"â±ï¸  æ™‚é–“: {elapsed:.2f}ç§’")
            print("-" * 40)
            
            results.append(result)
            self.results.append(result)
        
        return results
    
    def zero_shot_cot_demo(self) -> List[PromptResult]:
        """Zero-shot Chain-of-Thought ç¤ºç¯„"""
        print("\n" + "=" * 60)
        print("ğŸ¯ Zero-shot Chain-of-Thought")
        print("=" * 60)
        print("å®šç¾©ï¼šä½¿ç”¨é­”æ³•å¥å­ 'Let's think step by step'\n")
        
        examples = [
            {
                "task": "è¤‡é›œè¨ˆç®—",
                "prompt": """ä¸€å®¶é¤å»³æœ‰ 12 å¼µæ¡Œå­ã€‚æ¯å¼µæ¡Œå­å¯å 4 äººã€‚
ä»Šå¤©æœ‰ 3 å€‹ 15 äººçš„åœ˜é«”é ç´„ã€‚
è«‹å•é¤å»³é‚„èƒ½æ¥å¾…å¤šå°‘æ•£å®¢ï¼Ÿ

Let's think step by step."""
            },
            {
                "task": "é‚è¼¯è¬é¡Œ",
                "prompt": """æœ‰ä¸‰å€‹ç›’å­ï¼Œæ¨™ç±¤åˆ†åˆ¥å¯«è‘—ã€Œè˜‹æœã€ã€ã€Œæ©˜å­ã€ã€ã€Œè˜‹æœå’Œæ©˜å­ã€ã€‚
ä½†æ‰€æœ‰æ¨™ç±¤éƒ½è²¼éŒ¯äº†ã€‚ä½ åªèƒ½å¾ä¸€å€‹ç›’å­æ‹¿å‡ºä¸€å€‹æ°´æœä¾†çœ‹ã€‚
è¦å¦‚ä½•ç¢ºå®šæ¯å€‹ç›’å­çš„çœŸå¯¦å…§å®¹ï¼Ÿ

Let's think step by step."""
            }
        ]
        
        results = []
        for example in examples:
            print(f"ğŸ“ ä»»å‹™: {example['task']}")
            print(f"Prompt:\n{example['prompt']}")
            
            start = time.time()
            response = ollama.generate(
                model=self.model,
                prompt=example['prompt'],
                options={'temperature': 0.3}
            )
            elapsed = time.time() - start
            
            result = PromptResult(
                prompt=example['prompt'],
                response=response['response'],
                technique="Zero-shot-CoT",
                execution_time=elapsed,
                tokens_used=response.get('eval_count', 0)
            )
            
            print(f"ğŸ’¬ å›æ‡‰:\n{result.response[:400]}...")
            print(f"â±ï¸  æ™‚é–“: {elapsed:.2f}ç§’")
            print("-" * 40)
            
            results.append(result)
            self.results.append(result)
        
        return results
    
    def compare_techniques(self, task: str) -> Dict[str, PromptResult]:
        """æ¯”è¼ƒä¸åŒ Prompting æŠ€å·§åœ¨åŒä¸€ä»»å‹™ä¸Šçš„è¡¨ç¾"""
        print("\n" + "=" * 60)
        print("ğŸ”¬ æŠ€å·§æ¯”è¼ƒå¯¦é©—")
        print("=" * 60)
        print(f"ä»»å‹™: {task}\n")
        
        base_task = "åˆ†æé€™æ®µæ–‡å­—çš„ä¸»è¦è§€é»ï¼š\n\n" + \
                   "é ç«¯å·¥ä½œæ­£åœ¨æ”¹è®Šå‚³çµ±çš„è¾¦å…¬æ¨¡å¼ã€‚é›–ç„¶æä¾›äº†æ›´å¤§çš„å½ˆæ€§å’Œå·¥ä½œç”Ÿæ´»å¹³è¡¡ï¼Œ" + \
                   "ä½†ä¹Ÿå¸¶ä¾†äº†æºé€šæŒ‘æˆ°å’Œåœ˜éšŠå‡èšåŠ›çš„å•é¡Œã€‚ä¼æ¥­éœ€è¦æ‰¾åˆ°é©ç•¶çš„å¹³è¡¡é»ã€‚"
        
        techniques = {
            "Zero-shot": base_task + "\n\nä¸»è¦è§€é»ï¼š",
            
            "Few-shot": """åˆ†ææ–‡å­—çš„ä¸»è¦è§€é»ï¼š

æ–‡å­—ï¼šç¤¾äº¤åª’é«”æ”¹è®Šäº†äººå€‘çš„æºé€šæ–¹å¼ï¼Œå¸¶ä¾†ä¾¿åˆ©ä½†ä¹Ÿé€ æˆéš±ç§å•é¡Œã€‚
ä¸»è¦è§€é»ï¼šç¤¾äº¤åª’é«”æœ‰åˆ©æœ‰å¼Šï¼Œä¾¿åˆ©æ€§vséš±ç§æ¬Šçš„æ¬Šè¡¡ã€‚

æ–‡å­—ï¼š""" + base_task.split('ï¼š\n\n')[1] + """
ä¸»è¦è§€é»ï¼š""",
            
            "Chain-of-Thought": base_task + """

è«‹ä¸€æ­¥æ­¥åˆ†æï¼š
1. è­˜åˆ¥é—œéµè©ï¼š
2. æ‰¾å‡ºæ­£é¢è§€é»ï¼š
3. æ‰¾å‡ºè² é¢è§€é»ï¼š
4. ç¸½çµä¸»è¦è«–é»ï¼š

ä¸»è¦è§€é»ï¼š""",
            
            "Zero-shot-CoT": base_task + "\n\nLet's think step by step to identify the main points:"
        }
        
        comparison = {}
        
        for technique, prompt in techniques.items():
            print(f"\nğŸ“Œ {technique}")
            print(f"Prompt: {prompt[:100]}...")
            
            start = time.time()
            response = ollama.generate(
                model=self.model,
                prompt=prompt,
                options={'temperature': 0.3}
            )
            elapsed = time.time() - start
            
            result = PromptResult(
                prompt=prompt,
                response=response['response'],
                technique=technique,
                execution_time=elapsed,
                tokens_used=response.get('eval_count', 0)
            )
            
            comparison[technique] = result
            
            print(f"ğŸ’¬ å›æ‡‰: {result.response[:200]}...")
            print(f"â±ï¸  æ™‚é–“: {elapsed:.2f}ç§’")
            print(f"ğŸ“Š Tokens: {result.tokens_used}")
        
        # åˆ†ææ¯”è¼ƒçµæœ
        print("\n" + "=" * 60)
        print("ğŸ“Š æ•ˆèƒ½æ¯”è¼ƒ")
        print("=" * 60)
        
        for technique, result in comparison.items():
            print(f"{technique:15} | æ™‚é–“: {result.execution_time:.2f}s | Tokens: {result.tokens_used}")
        
        return comparison
    
    def save_results(self, filename: str = "prompt_results.json") -> None:
        """å„²å­˜å¯¦é©—çµæœ"""
        results_dict = []
        for result in self.results:
            results_dict.append({
                'technique': result.technique,
                'prompt': result.prompt[:200],  # å„²å­˜éƒ¨åˆ†prompt
                'response': result.response[:500],  # å„²å­˜éƒ¨åˆ†response
                'execution_time': result.execution_time,
                'tokens_used': result.tokens_used
            })
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(results_dict, f, ensure_ascii=False, indent=2)
        
        print(f"\nâœ… çµæœå·²å„²å­˜åˆ° {filename}")

def main():
    """ä¸»ç¨‹å¼"""
    print("=" * 60)
    print("ğŸ“ Prompt Engineering åŸºç¤æŠ€å·§")
    print("=" * 60)
    
    # æª¢æŸ¥ Ollama
    try:
        models = ollama.list()
        print("âœ… å·²é€£æ¥åˆ° Ollama")
    except Exception as e:
        print(f"âŒ ç„¡æ³•é€£æ¥åˆ° Ollama: {e}")
        return
    
    # é¸æ“‡æ¨¡å‹
    model = input("\né¸æ“‡æ¨¡å‹ [é è¨­: gemma:2b]: ").strip() or "gemma:2b"
    
    # å»ºç«‹ç¤ºç¯„ç‰©ä»¶
    demo = PromptEngineeringBasics(model=model)
    
    while True:
        print("\n" + "=" * 60)
        print("é¸æ“‡ç¤ºç¯„é …ç›®ï¼š")
        print("1. Zero-shot Prompting")
        print("2. Few-shot Prompting")
        print("3. Chain-of-Thought")
        print("4. Zero-shot CoT")
        print("5. æŠ€å·§æ¯”è¼ƒ")
        print("6. åŸ·è¡Œæ‰€æœ‰ç¤ºç¯„")
        print("7. å„²å­˜çµæœ")
        print("0. çµæŸ")
        print("-" * 60)
        
        choice = input("é¸æ“‡ (0-7): ").strip()
        
        if choice == '0':
            break
        elif choice == '1':
            demo.zero_shot_demo()
        elif choice == '2':
            demo.few_shot_demo()
        elif choice == '3':
            demo.chain_of_thought_demo()
        elif choice == '4':
            demo.zero_shot_cot_demo()
        elif choice == '5':
            demo.compare_techniques("æ–‡å­—åˆ†æ")
        elif choice == '6':
            demo.zero_shot_demo()
            demo.few_shot_demo()
            demo.chain_of_thought_demo()
            demo.zero_shot_cot_demo()
            demo.compare_techniques("æ–‡å­—åˆ†æ")
        elif choice == '7':
            demo.save_results()
        else:
            print("âŒ ç„¡æ•ˆé¸æ“‡")
        
        if choice != '0':
            input("\næŒ‰ Enter ç¹¼çºŒ...")
    
    print("\nğŸ‘‹ èª²ç¨‹çµæŸï¼")

if __name__ == "__main__":
    main()