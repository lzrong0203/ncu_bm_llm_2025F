{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XP_vmJySaGc4"
   },
   "source": [
    "# Week 6: Output Parser 進階 RAG 應用\n",
    "\n",
    "## 課程目標\n",
    "- 掌握模型量化技術（4-bit quantization）\n",
    "- 學習 LangChain Output Parser 各種類型\n",
    "- 實作結構化 RAG 輸出系統\n",
    "- 應用於實際商業場景\n",
    "\n",
    "## 教學大綱\n",
    "1. 環境設定與量化技術\n",
    "2. Output Parser 基礎\n",
    "3. RAG + Parser 整合\n",
    "4. 商業應用案例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uT7wokpWaGc6"
   },
   "source": [
    "## Part 1: 環境設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h3eecyUeaGc6",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1759920097535,
     "user_tz": -480,
     "elapsed": 61679,
     "user": {
      "displayName": "Steve Lai",
      "userId": "04934564034426550598"
     }
    },
    "outputId": "278176fb-b404-462c-fa8f-23d2c1614432"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m169.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/449.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m449.6/449.6 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/64.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/50.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.5/323.5 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h✅ 套件安裝完成\n",
      "⚠️  請重啟 Runtime 後再執行後續 cells\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: 安裝必要套件\n",
    "!pip install -q langchain-huggingface langchain-community langchain\n",
    "!pip install -q transformers accelerate bitsandbytes\n",
    "!pip install -q pypdf faiss-cpu==1.10.0\n",
    "!pip install -q pydantic\n",
    "!pip install -q rank-bm25  # BM25 檢索\n",
    "!pip install -q sentence-transformers  # Reranker\n",
    "\n",
    "print(\"✅ 套件安裝完成\")\n",
    "print(\"⚠️  請重啟 Runtime 後再執行後續 cells\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KIaTYvz4aGc8",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1759920143080,
     "user_tz": -480,
     "elapsed": 3961,
     "user": {
      "displayName": "Steve Lai",
      "userId": "04934564034426550598"
     }
    },
    "outputId": "fc8abb80-f167-47ad-bec0-04b3c8414291"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "✅ HuggingFace 認證成功\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: HuggingFace 認證\n",
    "from google.colab import userdata\n",
    "from huggingface_hub import login\n",
    "\n",
    "token = userdata.get('HF_TOKEN')\n",
    "login(token=token)\n",
    "\n",
    "print(\"✅ HuggingFace 認證成功\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IU4E5H_caGc8",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1759920197006,
     "user_tz": -480,
     "elapsed": 51356,
     "user": {
      "displayName": "Steve Lai",
      "userId": "04934564034426550598"
     }
    },
    "outputId": "4f1bb21a-b943-404f-db8d-9d115a9d404f"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n",
      "/content/drive/MyDrive/data_rag\n",
      "✅ Google Drive 掛載成功\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: 掛載 Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# 切換到資料目錄\n",
    "%cd drive/MyDrive/data_rag\n",
    "\n",
    "print(\"✅ Google Drive 掛載成功\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "63WZ6ADpaGc8",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1759921169852,
     "user_tz": -480,
     "elapsed": 6841,
     "user": {
      "displayName": "Steve Lai",
      "userId": "04934564034426550598"
     }
    },
    "outputId": "d34e4952-7f93-48bc-bbf9-0c1f4731d38a"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "✅ 套件導入完成\n",
      "🔧 PyTorch 版本: 2.8.0+cu126\n",
      "🎮 CUDA 可用: True\n",
      "📊 GPU: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: 導入基礎套件\n",
    "import torch\n",
    "from transformers import BitsAndBytesConfig\n",
    "from langchain_huggingface import ChatHuggingFace, HuggingFacePipeline, HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import (\n",
    "    StrOutputParser,\n",
    "    JsonOutputParser,\n",
    "    PydanticOutputParser,\n",
    "    CommaSeparatedListOutputParser\n",
    ")\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional, Dict\n",
    "import json\n",
    "\n",
    "print(\"✅ 套件導入完成\")\n",
    "print(f\"🔧 PyTorch 版本: {torch.__version__}\")\n",
    "print(f\"🎮 CUDA 可用: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"📊 GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T21VATmvaGc8"
   },
   "source": [
    "## Part 2: 量化技術實戰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "koiDjGRIaGc9",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1759920211041,
     "user_tz": -480,
     "elapsed": 9,
     "user": {
      "displayName": "Steve Lai",
      "userId": "04934564034426550598"
     }
    },
    "outputId": "c0d6b776-ae13-4602-b488-dec8d70da53c"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "⚙️  設定 4-bit 量化配置...\n",
      "\n",
      "📘 量化參數說明：\n",
      "- load_in_4bit: 將模型權重量化為 4-bit（原本 16-bit）\n",
      "- bnb_4bit_compute_dtype: 計算時使用的資料型別\n",
      "- bnb_4bit_quant_type: NF4 (NormalFloat) 適合神經網路\n",
      "- bnb_4bit_use_double_quant: 量化常數也進行量化\n",
      "\n",
      "💡 預期效果：\n",
      "- 記憶體使用減少約 75%\n",
      "- 1B 模型從 ~2GB 降至 ~0.5GB\n",
      "- 推理速度略有提升\n",
      "- 精度損失極小（<1%）\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: 設定 4-bit 量化配置\n",
    "print(\"⚙️  設定 4-bit 量化配置...\")\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,                      # 啟用 4-bit 量化\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,  # 使用 bfloat16 計算\n",
    "    bnb_4bit_quant_type=\"nf4\",             # NormalFloat 4-bit 量化類型\n",
    "    bnb_4bit_use_double_quant=True,        # 雙重量化，進一步壓縮\n",
    ")\n",
    "\n",
    "print(\"\"\"\\n📘 量化參數說明：\n",
    "- load_in_4bit: 將模型權重量化為 4-bit（原本 16-bit）\n",
    "- bnb_4bit_compute_dtype: 計算時使用的資料型別\n",
    "- bnb_4bit_quant_type: NF4 (NormalFloat) 適合神經網路\n",
    "- bnb_4bit_use_double_quant: 量化常數也進行量化\n",
    "\n",
    "💡 預期效果：\n",
    "- 記憶體使用減少約 75%\n",
    "- 1B 模型從 ~2GB 降至 ~0.5GB\n",
    "- 推理速度略有提升\n",
    "- 精度損失極小（<1%）\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 277,
     "referenced_widgets": [
      "7afc731f8de1445c83a29b96d7f76aec",
      "1b4d2d96a2d54325b30acaeb6d74f88a",
      "da7df6d2dbf94162bc73e0b1d79546b6",
      "130293906dcf41ccb4edb5669d39cb80",
      "1ea423c9fa0449fbbf82fc932fc1a79e",
      "0f58401920c84aaba561e5c439f4f55e",
      "b66799f33df544b5b120af5a2ac1562a",
      "b4dc2bbfce51494c933bb49157e82e1b",
      "391246fea32d43b2a43422bf4c4e6529",
      "b492eb86bb2b41579f501e76d744180e",
      "5a98d662bbff499ca7fba38999f13e84",
      "3f50fa5c591549d78bde4d6f2a740a54",
      "e574f2b816574312bf77425cb8051a94",
      "d44bb50de7b043a4998779cfa3b0762d",
      "aa3d278bd1134847905b15a383dde452",
      "d7a70e469673481d9ba9f1f84ccae2f3",
      "0de13df92f484983b6914f2bc5864c15",
      "2e745fe308da4ee58f36a8fa68a99ddb",
      "9bb687ed770343a2a51b3d335a6dd501",
      "d319c650e3a14e8b9de53174f2091882",
      "69d1509c8d994ffdad96e75f1c418c4d",
      "5873a2c2aded44148681dbfa2cc04ad6",
      "a8d55e5fdfca461a9fe1141248e57df7",
      "acc4c7b4e1f8468ba51be281942ed03b",
      "268be300de1643179eada4107173c97c",
      "7c713a1fbb8d4203a8d0f046121d67e6",
      "82f378a4739c497287c2045d0074edc2",
      "b16a90ceffe141aa82ad15638422fc1c",
      "ef3d11e51f0b46f19c31f970e0bbdc68",
      "0d00480b3f5f4d16af85ecaea52c075f",
      "d060357e6bf645dc8eb8742ebf7f7248",
      "787724bfb57946a1a7991823b23864eb",
      "32a44cd710034ce79c7dadbf870b5c72",
      "1ff6f60bce2d4b9689d66660301c44a3",
      "11f541cdb1bc4a5aa4302e4bbabfdfa7",
      "7cebbf13dcb44bba82fb434e1a95b84e",
      "1cecdbbffd464707b6e67933a49fb387",
      "c49311904ec448c69af9d6f6aebf6695",
      "623edf6da7ed457199f6510c36332e1b",
      "60c7b151bcbf450889d11f1853691d35",
      "16ab9f23a9fc4bdf9f577f9e331e2879",
      "dfb39489226b4cef8c173bc1e3749670",
      "3125c9628d7343209a95150199ffe4ee",
      "ee9448c047064b5194f1d4353010cf15",
      "3f6948b90f2b404097edc9b99f2770ad",
      "079e16db89564db695d3ff7745cac180",
      "651a448fa9714340ab6d0e632545cc9e",
      "26dfe00b7c0149a8b66c711fe42f8dd8",
      "eb385027e9f14f8f8d853c8fb64de2bb",
      "ad9a16098e524806b51f58ea0fd6d0b5",
      "42a7766230f644c58865d48bff70cf0a",
      "273d1d1d9350420ab87416fd3b4ce984",
      "eb696f793f19490bb86c257ba6a9fd87",
      "7ce9710e673749beb3957466d4167cd4",
      "18cfd58e34fe464e948ffc273feb3386",
      "4553f503860e496ca1403ebddc781775",
      "fbe010e0a6bb4ed5a383e3481e3facff",
      "50eb8c3689b34314ae12fcaca03197cf",
      "69001a7e19044ad3824289d853f02818",
      "5567ee66cf2c4ceb8b8bcbd13781a0de",
      "9d1a7ded354b404e8b608996a5719200",
      "02557ac135a443a1ba704cc10af99109",
      "d93a7e3798e045f39c8ff5f35dc8ca3e",
      "260d1e9b6d694136b272ab13f50eca1b",
      "e4ca40c230f5437a8148bc0e67893565",
      "e1497a6b263b4f589fe455976cd73ed1",
      "c95a45bf6efc40f2956ebf61d0a64a24",
      "d41c0465b9f744bfa15144e49d7eeadb",
      "75235c59bd0e4922885d5b44288a7ab3",
      "73ae67b23f504a6ea67e7a828b46617f",
      "b0904b0f4e0a43f99e2983006eb4ad60",
      "53a5013498694286a29524cc2facbb11",
      "d4397dfba29443c0881b59531f1811f2",
      "d471ea754d594eb2b383d602a069914b",
      "8bc768f5203b412a955cacd5cf56c28c",
      "2c52d10cceca48368f5442a188c0b3d1",
      "2c9db00610b24365898760be0f2eb4b4"
     ]
    },
    "id": "87vjUgFXaGc9",
    "outputId": "61a1a82b-c6d1-434b-ab25-bc08be9d47a8"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "🚀 載入量化模型 gemma-3-1b-it...\n",
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.16M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7afc731f8de1445c83a29b96d7f76aec"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.69M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3f50fa5c591549d78bde4d6f2a740a54"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/33.4M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a8d55e5fdfca461a9fe1141248e57df7"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/35.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1ff6f60bce2d4b9689d66660301c44a3"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3f6948b90f2b404097edc9b99f2770ad"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/899 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4553f503860e496ca1403ebddc781775"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.00G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c95a45bf6efc40f2956ebf61d0a64a24"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "# Cell 6: 載入量化模型\n",
    "print(\"🚀 載入量化模型 gemma-3-1b-it...\\n\")\n",
    "\n",
    "llm = HuggingFacePipeline.from_model_id(\n",
    "    model_id=\"google/gemma-3-1b-it\",\n",
    "    task=\"text-generation\",\n",
    "    model_kwargs={\"quantization_config\": quantization_config},\n",
    "    pipeline_kwargs={\n",
    "        \"max_new_tokens\": 512,\n",
    "        \"temperature\": 0.7,\n",
    "        \"top_p\": 0.9,\n",
    "    }\n",
    ")\n",
    "\n",
    "chat_model = ChatHuggingFace(llm=llm)\n",
    "\n",
    "print(\"\\n✅ 模型載入成功！\")\n",
    "print(\"\\n💾 記憶體使用情況：\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"已分配: {torch.cuda.memory_allocated(0) / 1024**3:.2f} GB\")\n",
    "    print(f\"已保留: {torch.cuda.memory_reserved(0) / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9f3f2c84"
   },
   "source": [
    "# 安裝 OpenAI 套件\n",
    "!pip install -q openai langchain-openai\n",
    "print(\"✅ OpenAI 套件安裝完成\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cdad65df"
   },
   "source": [
    "### 設定 OpenAI API Key\n",
    "請確保您已將 OpenAI API Key 儲存在 Colab 的 Secrets 中，名稱為 `OPENAI_API_KEY`。"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install langchain_openai"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "Jo5HMml3ehzB",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1759921204871,
     "user_tz": -480,
     "elapsed": 15036,
     "user": {
      "displayName": "Steve Lai",
      "userId": "04934564034426550598"
     }
    },
    "outputId": "15f85a57-0d8f-49e6-993f-28c3004e7c46"
   },
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting langchain_openai\n",
      "  Downloading langchain_openai-0.3.35-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.78 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (0.3.78)\n",
      "Requirement already satisfied: openai<3.0.0,>=1.104.2 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (1.109.1)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (0.11.0)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.78->langchain_openai) (0.4.31)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.78->langchain_openai) (8.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.78->langchain_openai) (1.33)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.78->langchain_openai) (6.0.3)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.78->langchain_openai) (4.15.0)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.78->langchain_openai) (25.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.78->langchain_openai) (2.11.9)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain_openai) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain_openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain_openai) (0.11.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain_openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain_openai) (4.67.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain_openai) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain_openai) (2.32.5)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai<3.0.0,>=1.104.2->langchain_openai) (3.10)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.104.2->langchain_openai) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.104.2->langchain_openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<3.0.0,>=1.104.2->langchain_openai) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.78->langchain_openai) (3.0.0)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.78->langchain_openai) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.78->langchain_openai) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.78->langchain_openai) (0.25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.78->langchain_openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.78->langchain_openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.78->langchain_openai) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain_openai) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain_openai) (2.5.0)\n",
      "Downloading langchain_openai-0.3.35-py3-none-any.whl (75 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: langchain_openai\n",
      "Successfully installed langchain_openai-0.3.35\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fc2806d6",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1759921494398,
     "user_tz": -480,
     "elapsed": 1098,
     "user": {
      "displayName": "Steve Lai",
      "userId": "04934564034426550598"
     }
    },
    "outputId": "8d66cb1b-9bf7-4251-9597-5f637b442321"
   },
   "source": [
    "from google.colab import userdata\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "# 讀取 API Key\n",
    "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
    "\n",
    "# 建立 ChatOpenAI 實例\n",
    "# 使用 gpt-4o 模型 (目前 OpenAI 最新的模型)\n",
    "# 您也可以換成其他模型，例如 \"gpt-3.5-turbogpt-5\"\n",
    "chat_model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "print(f\"✅ OpenAI Chat Model ({openai_chat_model.model_name}) 建立成功\")"
   ],
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "✅ OpenAI Chat Model (gpt-4o) 建立成功\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06539d83"
   },
   "source": [
    "現在 Cell 9 將使用 `openai_chat_model` 來代替之前的 `chat_model`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CX7C93wMaGc9",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1759921503495,
     "user_tz": -480,
     "elapsed": 4245,
     "user": {
      "displayName": "Steve Lai",
      "userId": "04934564034426550598"
     }
    },
    "outputId": "911b83f3-a9e1-4342-d36b-d8f2e8c41457"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "🧪 測試量化模型輸出...\n",
      "\n",
      "🤖 模型回答：\n",
      "模型量化是一種技術，用於減少機器學習模型的大小和計算需求，通常透過將浮點數權重轉換為較低精度的整數表示。這不僅能降低存儲和計算成本，還能加速推理過程，特別是在資源受限的設備上。\n",
      "\n",
      "✅ 量化模型測試成功！\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: 測試量化模型\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "import os\n",
    "\n",
    "# 設定 CUDA_LAUNCH_BLOCKING=1 以幫助除錯\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "\n",
    "print(\"🧪 測試量化模型輸出...\\n\")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"你是一個專業的 AI 助手，請用繁體中文簡潔回答。\"),\n",
    "    HumanMessage(\"什麼是模型量化？請用 2-3 句話說明。\")\n",
    "]\n",
    "\n",
    "response = chat_model.invoke(messages)\n",
    "print(\"🤖 模型回答：\")\n",
    "print(response.content)\n",
    "print(\"\\n✅ 量化模型測試成功！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZ8Y26SYaGc-"
   },
   "source": [
    "## Part 3: Output Parser 基礎教學"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oTGl4M70aGc-",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1759921519170,
     "user_tz": -480,
     "elapsed": 1987,
     "user": {
      "displayName": "Steve Lai",
      "userId": "04934564034426550598"
     }
    },
    "outputId": "62638611-e1a6-4219-8c6d-e0d8150d3d12"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "📝 範例 1: StrOutputParser (字串解析器)\n",
      "\n",
      "輸出類型: <class 'str'>\n",
      "內容: RAG（檢索增強生成）是一種結合信息檢索和生成模型的方法，通過檢索相關資料來輔助生成更準確和上下文相關的文本。\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: StrOutputParser - 基本字串解析\n",
    "print(\"📝 範例 1: StrOutputParser (字串解析器)\\n\")\n",
    "\n",
    "str_parser = StrOutputParser()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"請用一句話解釋：{concept}\",\n",
    "    input_variables=[\"concept\"]\n",
    ")\n",
    "\n",
    "chain = prompt | chat_model | str_parser\n",
    "\n",
    "result = chain.invoke({\"concept\": \"RAG (Retrieval-Augmented Generation)\"})\n",
    "print(f\"輸出類型: {type(result)}\")\n",
    "print(f\"內容: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uMchHpjtaGc-",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1759921560295,
     "user_tz": -480,
     "elapsed": 1999,
     "user": {
      "displayName": "Steve Lai",
      "userId": "04934564034426550598"
     }
    },
    "outputId": "adc837a5-d9c7-4d45-d251-c171ec02a4e2"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "📋 範例 2: CommaSeparatedListOutputParser (列表解析器)\n",
      "\n",
      "輸出類型: <class 'list'>\n",
      "列表項目:\n",
      "  1. 線性迴歸\n",
      "  2. 決策樹\n",
      "  3. 支持向量機\n",
      "  4. K-均值聚類\n",
      "  5. 隨機森林\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: CommaSeparatedListOutputParser - 列表解析\n",
    "print(\"📋 範例 2: CommaSeparatedListOutputParser (列表解析器)\\n\")\n",
    "\n",
    "list_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"列出 5 個{category}，用逗號分隔，只輸出項目名稱：\",\n",
    "    input_variables=[\"category\"]\n",
    ")\n",
    "\n",
    "# 將 chain 中的模型替換為 openai_chat_model\n",
    "chain = prompt | chat_model | list_parser\n",
    "\n",
    "result = chain.invoke({\"category\": \"機器學習演算法\"})\n",
    "print(f\"輸出類型: {type(result)}\")\n",
    "print(f\"列表項目:\")\n",
    "for i, item in enumerate(result, 1):\n",
    "    print(f\"  {i}. {item.strip()}\")"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "chain = prompt | chat_model | str_parser\n",
    "result = chain.invoke({\"category\": \"機器學習演算法\"})\n",
    "result"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "gEZsBESff_Bn",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1759921671140,
     "user_tz": -480,
     "elapsed": 1552,
     "user": {
      "displayName": "Steve Lai",
      "userId": "04934564034426550598"
     }
    },
    "outputId": "507e9594-78dd-409c-a19b-7dacb564501c"
   },
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'線性回歸, 決策樹, 支持向量機, K-均值聚類, 隨機森林'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 13
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "type(result)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4cDrT1pPgbYG",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1759921688334,
     "user_tz": -480,
     "elapsed": 33,
     "user": {
      "displayName": "Steve Lai",
      "userId": "04934564034426550598"
     }
    },
    "outputId": "5b8bc64d-2e8c-4dcc-9a7c-94f120cbb280"
   },
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4YdhR92yaGc-",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1759922689849,
     "user_tz": -480,
     "elapsed": 1338,
     "user": {
      "displayName": "Steve Lai",
      "userId": "04934564034426550598"
     }
    },
    "outputId": "aae581a3-0257-4581-92ba-4b6720adec5a"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "🔧 範例 3: JsonOutputParser (JSON 解析器)\n",
      "\n",
      "📝 產品描述: MacBook Pro 是 Apple 的專業筆記型電腦，售價 68900 元，目前有現貨\n",
      "\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"description\": \"MacBook Pro 是 Apple 的專業筆記型電腦，售價 68900 元，目前有現貨\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"description\": \"MacBook Pro 是 Apple 的專業筆記型電腦，售價 68900 元，目前有現貨\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:PromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: 從產品描述中提取資訊並輸出 JSON 格式。\\n\\n範例：\\n產品描述: iPhone 17 是 Apple 的智慧手機，售價 52900 元，目前缺貨\\nJSON: {\\\"name\\\": \\\"iPhone 17\\\", \\\"category\\\": \\\"智慧手機\\\", \\\"price\\\": 52900, \\\"in_stock\\\": false}\\n\\n現在請處理：\\n產品描述: MacBook Pro 是 Apple 的專業筆記型電腦，售價 68900 元，目前有現貨\\nJSON:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] [1.31s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"```json\\n{\\n  \\\"name\\\": \\\"MacBook Pro\\\",\\n  \\\"category\\\": \\\"專業筆記型電腦\\\",\\n  \\\"price\\\": 68900,\\n  \\\"in_stock\\\": true\\n}\\n```\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"```json\\n{\\n  \\\"name\\\": \\\"MacBook Pro\\\",\\n  \\\"category\\\": \\\"專業筆記型電腦\\\",\\n  \\\"price\\\": 68900,\\n  \\\"in_stock\\\": true\\n}\\n```\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 44,\n",
      "                \"prompt_tokens\": 115,\n",
      "                \"total_tokens\": 159,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-4o-2024-08-06\",\n",
      "              \"system_fingerprint\": \"fp_cbf1785567\",\n",
      "              \"id\": \"chatcmpl-COMZmvNYNkwa4rREsJsXBy7smJdHt\",\n",
      "              \"service_tier\": \"default\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run--23405fdd-c7e2-410b-9228-5a9498ea626d-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 115,\n",
      "              \"output_tokens\": 44,\n",
      "              \"total_tokens\": 159,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 44,\n",
      "      \"prompt_tokens\": 115,\n",
      "      \"total_tokens\": 159,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-4o-2024-08-06\",\n",
      "    \"system_fingerprint\": \"fp_cbf1785567\",\n",
      "    \"id\": \"chatcmpl-COMZmvNYNkwa4rREsJsXBy7smJdHt\",\n",
      "    \"service_tier\": \"default\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:JsonOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"name\": \"MacBook Pro\",\n",
      "  \"category\": \"專業筆記型電腦\",\n",
      "  \"price\": 68900,\n",
      "  \"in_stock\": true\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [1.32s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"name\": \"MacBook Pro\",\n",
      "  \"category\": \"專業筆記型電腦\",\n",
      "  \"price\": 68900,\n",
      "  \"in_stock\": true\n",
      "}\n",
      "✅ 解析成功！\n",
      "輸出類型: <class 'dict'>\n",
      "\n",
      "JSON 內容:\n",
      "{\n",
      "  \"name\": \"MacBook Pro\",\n",
      "  \"category\": \"專業筆記型電腦\",\n",
      "  \"price\": 68900,\n",
      "  \"in_stock\": true\n",
      "}\n",
      "\n",
      "📦 資料驗證:\n",
      "  ✅ 所有必要欄位都存在\n",
      "\n",
      "📋 產品資訊:\n",
      "  名稱: MacBook Pro\n",
      "  類別: 專業筆記型電腦\n",
      "  價格: NT$ 68,900\n",
      "  庫存: 有貨 ✅\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: JsonOutputParser - JSON 格式解析（改進版）\n",
    "print(\"🔧 範例 3: JsonOutputParser (JSON 解析器)\\n\")\n",
    "import langchain\n",
    "langchain.debug = True\n",
    "# 定義簡單的 JSON schema\n",
    "class Product(BaseModel):\n",
    "    name: str = Field(description=\"產品名稱\")\n",
    "    category: str = Field(description=\"產品類別\")\n",
    "    price: int = Field(description=\"價格（新台幣）\")\n",
    "    in_stock: bool = Field(description=\"是否有庫存\")\n",
    "\n",
    "json_parser = JsonOutputParser(pydantic_object=Product)\n",
    "\n",
    "# 改進的 Prompt - 使用 Few-Shot 範例\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"從產品描述中提取資訊並輸出 JSON 格式。\n",
    "\n",
    "範例：\n",
    "產品描述: iPhone 17 是 Apple 的智慧手機，售價 52900 元，目前缺貨\n",
    "JSON: {{\"name\": \"iPhone 17\", \"category\": \"智慧手機\", \"price\": 52900, \"in_stock\": false}}\n",
    "\n",
    "現在請處理：\n",
    "產品描述: {description}\n",
    "JSON:\"\"\",\n",
    "    input_variables=[\"description\"]\n",
    ")\n",
    "\n",
    "# # 建立 LLM（直接用參數，不使用 GenerationConfig 物件）\n",
    "# json_llm = HuggingFacePipeline.from_model_id(\n",
    "#     model_id=\"google/gemma-3-1b-it\",\n",
    "#     task=\"text-generation\",\n",
    "#     model_kwargs={\n",
    "#         \"quantization_config\": quantization_config,\n",
    "#         \"device_map\": \"auto\"\n",
    "#     },\n",
    "#     pipeline_kwargs={\n",
    "#         \"max_new_tokens\": 128,\n",
    "#         \"do_sample\": False,        # 不使用採樣（確定性輸出）\n",
    "#         \"pad_token_id\": 0,         # 設定 padding token\n",
    "#         \"eos_token_id\": 1          # 設定 end-of-sequence token\n",
    "#     }\n",
    "# )\n",
    "# json_chat = ChatHuggingFace(llm=json_llm)\n",
    "\n",
    "\n",
    "chain = prompt | chat_model | json_parser\n",
    "\n",
    "description = \"MacBook Pro 是 Apple 的專業筆記型電腦，售價 68900 元，目前有現貨\"\n",
    "\n",
    "print(f\"📝 產品描述: {description}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    result = chain.invoke({\"description\": description})\n",
    "\n",
    "    print(f\"✅ 解析成功！\")\n",
    "    print(f\"輸出類型: {type(result)}\\n\")\n",
    "    print(f\"JSON 內容:\")\n",
    "    print(json.dumps(result, indent=2, ensure_ascii=False))\n",
    "\n",
    "    # 驗證資料完整性\n",
    "    print(f\"\\n📦 資料驗證:\")\n",
    "    required_fields = [\"name\", \"category\", \"price\", \"in_stock\"]\n",
    "    missing_fields = [f for f in required_fields if f not in result]\n",
    "\n",
    "    if missing_fields:\n",
    "        print(f\"  ⚠️  缺少欄位: {', '.join(missing_fields)}\")\n",
    "    else:\n",
    "        print(f\"  ✅ 所有必要欄位都存在\")\n",
    "        print(f\"\\n📋 產品資訊:\")\n",
    "        print(f\"  名稱: {result['name']}\")\n",
    "        print(f\"  類別: {result['category']}\")\n",
    "        print(f\"  價格: NT$ {result['price']:,}\")\n",
    "        print(f\"  庫存: {'有貨 ✅' if result['in_stock'] else '缺貨 ❌'}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ 解析錯誤: {e}\")\n",
    "\n",
    "    # 除錯：顯示原始 LLM 輸出\n",
    "    print(f\"\\n🔍 除錯資訊 - LLM 原始輸出:\")\n",
    "    try:\n",
    "        debug_chain = prompt | json_chat\n",
    "        debug_result = debug_chain.invoke({\"description\": description})\n",
    "        print(debug_result.content[:500])  # 只顯示前 500 字元\n",
    "\n",
    "        # 嘗試手動解析\n",
    "        print(f\"\\n💡 嘗試手動解析 JSON...\")\n",
    "        import re\n",
    "        json_match = re.search(r'\\{[^{}]+\\}', debug_result.content)\n",
    "        if json_match:\n",
    "            manual_json = json.loads(json_match.group())\n",
    "            print(f\"✅ 手動解析成功:\")\n",
    "            print(json.dumps(manual_json, indent=2, ensure_ascii=False))\n",
    "        else:\n",
    "            print(\"❌ 找不到 JSON 格式\")\n",
    "\n",
    "    except Exception as debug_e:\n",
    "        print(f\"除錯失敗: {debug_e}\")\n",
    "\n",
    "    print(\"\\n💡 調整建議：\")\n",
    "    print(\"- 已使用直接參數設定確定性輸出\")\n",
    "    print(\"- 如果持續失敗，建議改用 PydanticOutputParser (見 Cell 11)\")\n",
    "    print(\"- 或使用更簡化的 prompt 和更小的模型輸出\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4VlMRrEKaGc_",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1759923215897,
     "user_tz": -480,
     "elapsed": 2739,
     "user": {
      "displayName": "Steve Lai",
      "userId": "04934564034426550598"
     }
    },
    "outputId": "f4f01526-3d0c-4318-96c8-5fd2f4108e44"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "🎯 範例 4: PydanticOutputParser (Pydantic 解析器)\n",
      "\n",
      "📝 文章內容:\n",
      "RAG (Retrieval-Augmented Generation) 是一種結合檢索與生成的 AI 技術。\n",
      "它先從知識庫中檢索相關資訊，再將檢索結果與用戶問題一起傳給大型語言模型生成答案。\n",
      "這種方法可以有效減少 AI 幻覺問題，提供更準確且有依據的回答。\n",
      "\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"article\": \"RAG (Retrieval-Augmented Generation) 是一種結合檢索與生成的 AI 技術。\\n它先從知識庫中檢索相關資訊，再將檢索結果與用戶問題一起傳給大型語言模型生成答案。\\n這種方法可以有效減少 AI 幻覺問題，提供更準確且有依據的回答。\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"article\": \"RAG (Retrieval-Augmented Generation) 是一種結合檢索與生成的 AI 技術。\\n它先從知識庫中檢索相關資訊，再將檢索結果與用戶問題一起傳給大型語言模型生成答案。\\n這種方法可以有效減少 AI 幻覺問題，提供更準確且有依據的回答。\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:PromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: 分析技術文章並提取結構化資訊，以 JSON 格式輸出。\\n\\n範例：\\n文章：Docker 是一個容器化平台，可以打包應用程式及其依賴。它簡化了部署流程，適合微服務架構。開發者可以確保環境一致性。\\nJSON: {\\n  \\\"title\\\": \\\"Docker 容器化技術介紹\\\",\\n  \\\"main_topic\\\": \\\"容器化與部署\\\",\\n  \\\"key_points\\\": [\\\"打包應用程式及依賴\\\", \\\"簡化部署流程\\\", \\\"確保環境一致性\\\"],\\n  \\\"difficulty\\\": \\\"中級\\\"\\n}\\n\\n現在請分析：\\n文章：RAG (Retrieval-Augmented Generation) 是一種結合檢索與生成的 AI 技術。\\n它先從知識庫中檢索相關資訊，再將檢索結果與用戶問題一起傳給大型語言模型生成答案。\\n這種方法可以有效減少 AI 幻覺問題，提供更準確且有依據的回答。\\nJSON:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] [2.65s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"```json\\n{\\n  \\\"title\\\": \\\"RAG 技術介紹\\\",\\n  \\\"main_topic\\\": \\\"檢索增強生成技術\\\",\\n  \\\"key_points\\\": [\\n    \\\"結合檢索與生成\\\",\\n    \\\"從知識庫中檢索相關資訊\\\",\\n    \\\"減少 AI 幻覺問題\\\",\\n    \\\"提供更準確且有依據的回答\\\"\\n  ],\\n  \\\"difficulty\\\": \\\"高級\\\"\\n}\\n```\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"```json\\n{\\n  \\\"title\\\": \\\"RAG 技術介紹\\\",\\n  \\\"main_topic\\\": \\\"檢索增強生成技術\\\",\\n  \\\"key_points\\\": [\\n    \\\"結合檢索與生成\\\",\\n    \\\"從知識庫中檢索相關資訊\\\",\\n    \\\"減少 AI 幻覺問題\\\",\\n    \\\"提供更準確且有依據的回答\\\"\\n  ],\\n  \\\"difficulty\\\": \\\"高級\\\"\\n}\\n```\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 95,\n",
      "                \"prompt_tokens\": 235,\n",
      "                \"total_tokens\": 330,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-4o-2024-08-06\",\n",
      "              \"system_fingerprint\": \"fp_f33640a400\",\n",
      "              \"id\": \"chatcmpl-COMiFebUYONZdetRqNtMTCA9ppohV\",\n",
      "              \"service_tier\": \"default\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run--6bf0beeb-e18c-44e1-a38a-bc4831d3f6b2-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 235,\n",
      "              \"output_tokens\": 95,\n",
      "              \"total_tokens\": 330,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 95,\n",
      "      \"prompt_tokens\": 235,\n",
      "      \"total_tokens\": 330,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-4o-2024-08-06\",\n",
      "    \"system_fingerprint\": \"fp_f33640a400\",\n",
      "    \"id\": \"chatcmpl-COMiFebUYONZdetRqNtMTCA9ppohV\",\n",
      "    \"service_tier\": \"default\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:PydanticOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:PydanticOutputParser] [21ms] Exiting Parser run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [2.67s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "✅ 解析成功！類型: <class '__main__.TechArticleSummary'>\n",
      "\n",
      "📌 標題: RAG 技術介紹\n",
      "🎯 主題: 檢索增強生成技術\n",
      "📊 難度: 高級\n",
      "\n",
      "💡 關鍵重點:\n",
      "  1. 結合檢索與生成\n",
      "  2. 從知識庫中檢索相關資訊\n",
      "  3. 減少 AI 幻覺問題\n",
      "  4. 提供更準確且有依據的回答\n"
     ]
    }
   ],
   "source": [
    "# Cell 11: PydanticOutputParser - 型別安全的結構化輸出\n",
    "print(\"🎯 範例 4: PydanticOutputParser (Pydantic 解析器)\\n\")\n",
    "\n",
    "# 定義簡化的資料模型（減少欄位以提高成功率）\n",
    "class TechArticleSummary(BaseModel):\n",
    "    title: str = Field(description=\"文章標題\")\n",
    "    main_topic: str = Field(description=\"主要主題\")\n",
    "    key_points: List[str] = Field(description=\"關鍵重點，2-3 點\")\n",
    "    difficulty: str = Field(description=\"難度：初級/中級/進階\")\n",
    "\n",
    "pydantic_parser = PydanticOutputParser(pydantic_object=TechArticleSummary)\n",
    "\n",
    "# 改進 Prompt - 使用 Few-Shot 範例，不使用 format_instructions\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"分析技術文章並提取結構化資訊，以 JSON 格式輸出。\n",
    "\n",
    "範例：\n",
    "文章：Docker 是一個容器化平台，可以打包應用程式及其依賴。它簡化了部署流程，適合微服務架構。開發者可以確保環境一致性。\n",
    "JSON: {{\n",
    "  \"title\": \"Docker 容器化技術介紹\",\n",
    "  \"main_topic\": \"容器化與部署\",\n",
    "  \"key_points\": [\"打包應用程式及依賴\", \"簡化部署流程\", \"確保環境一致性\"],\n",
    "  \"difficulty\": \"中級\"\n",
    "}}\n",
    "\n",
    "現在請分析：\n",
    "文章：{article}\n",
    "JSON:\"\"\",\n",
    "    input_variables=[\"article\"]\n",
    ")\n",
    "\n",
    "# # 建立穩定的 LLM（不使用 GenerationConfig 物件，直接用參數）\n",
    "# stable_llm = HuggingFacePipeline.from_model_id(\n",
    "#     model_id=\"google/gemma-3-1b-it\",\n",
    "#     task=\"text-generation\",\n",
    "#     model_kwargs={\n",
    "#         \"quantization_config\": quantization_config,\n",
    "#         \"device_map\": \"auto\"\n",
    "#     },\n",
    "#     pipeline_kwargs={\n",
    "#         \"max_new_tokens\": 256,\n",
    "#         \"do_sample\": False,        # 確定性輸出\n",
    "#         \"pad_token_id\": 0,\n",
    "#         \"eos_token_id\": 1\n",
    "#     }\n",
    "# )\n",
    "# stable_chat = ChatHuggingFace(llm=stable_llm)\n",
    "\n",
    "chain = prompt | chat_model | pydantic_parser\n",
    "\n",
    "article = \"\"\"RAG (Retrieval-Augmented Generation) 是一種結合檢索與生成的 AI 技術。\n",
    "它先從知識庫中檢索相關資訊，再將檢索結果與用戶問題一起傳給大型語言模型生成答案。\n",
    "這種方法可以有效減少 AI 幻覺問題，提供更準確且有依據的回答。\"\"\"\n",
    "\n",
    "print(f\"📝 文章內容:\\n{article}\\n\")\n",
    "\n",
    "try:\n",
    "    result = chain.invoke({\"article\": article})\n",
    "    print(f\"✅ 解析成功！類型: {type(result)}\\n\")\n",
    "    print(f\"📌 標題: {result.title}\")\n",
    "    print(f\"🎯 主題: {result.main_topic}\")\n",
    "    print(f\"📊 難度: {result.difficulty}\")\n",
    "    print(f\"\\n💡 關鍵重點:\")\n",
    "    for i, point in enumerate(result.key_points, 1):\n",
    "        print(f\"  {i}. {point}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ 解析錯誤: {str(e)[:200]}...\\n\")\n",
    "\n",
    "    # 除錯：顯示原始輸出\n",
    "    print(\"🔍 除錯資訊 - LLM 原始輸出:\")\n",
    "    try:\n",
    "        debug_chain = prompt | stable_chat\n",
    "        debug_result = debug_chain.invoke({\"article\": article})\n",
    "        print(debug_result.content[:500])\n",
    "\n",
    "        # 嘗試手動解析\n",
    "        print(\"\\n💡 嘗試手動解析...\")\n",
    "        import re\n",
    "        json_match = re.search(r'\\{[^{}]*\\[[^\\]]*\\][^{}]*\\}|\\{[^{}]+\\}', debug_result.content, re.DOTALL)\n",
    "        if json_match:\n",
    "            try:\n",
    "                manual_json = json.loads(json_match.group())\n",
    "                print(\"✅ 找到 JSON 結構:\")\n",
    "                print(json.dumps(manual_json, indent=2, ensure_ascii=False))\n",
    "\n",
    "                # 嘗試用找到的 JSON 建立物件\n",
    "                manual_result = TechArticleSummary(**manual_json)\n",
    "                print(\"\\n✅ 手動建立 Pydantic 物件成功！\")\n",
    "                print(f\"標題: {manual_result.title}\")\n",
    "                print(f\"主題: {manual_result.main_topic}\")\n",
    "                print(f\"難度: {manual_result.difficulty}\")\n",
    "                print(f\"重點數量: {len(manual_result.key_points)}\")\n",
    "\n",
    "            except Exception as parse_e:\n",
    "                print(f\"❌ 手動解析也失敗: {parse_e}\")\n",
    "        else:\n",
    "            print(\"❌ 找不到完整的 JSON 結構\")\n",
    "\n",
    "    except Exception as debug_e:\n",
    "        print(f\"除錯失敗: {debug_e}\")\n",
    "\n",
    "    print(\"\\n💡 調整建議：\")\n",
    "    print(\"- 已簡化模型欄位（移除 target_audience）\")\n",
    "    print(\"- 已使用 Few-Shot 範例引導\")\n",
    "    print(\"- 已設定 do_sample=False 確保穩定性\")\n",
    "    print(\"- 可以嘗試使用更大的模型（gemma-3-4b-it）\")\n",
    "    print(\"- 或改用更簡單的 JsonOutputParser（見 Cell 10）\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VF6pSGD4aGc_"
   },
   "outputs": [],
   "source": [
    "# Cell 12: Output Parser 比較總結\n",
    "print(\"\"\"📊 Output Parser 類型比較\n",
    "\n",
    "┌─────────────────────────┬──────────────────┬─────────────────────┬─────────────┐\n",
    "│ Parser 類型             │ 輸出類型         │ 適用場景            │ 難度        │\n",
    "├─────────────────────────┼──────────────────┼─────────────────────┼─────────────┤\n",
    "│ StrOutputParser         │ str              │ 簡單文字回答        │ ⭐          │\n",
    "│ CommaSeparatedList      │ List[str]        │ 列表項目            │ ⭐⭐        │\n",
    "│ JsonOutputParser        │ Dict             │ 結構化資料          │ ⭐⭐⭐      │\n",
    "│ PydanticOutputParser    │ Pydantic Model   │ 型別安全資料        │ ⭐⭐⭐⭐    │\n",
    "└─────────────────────────┴──────────────────┴─────────────────────┴─────────────┘\n",
    "\n",
    "💡 選擇建議：\n",
    "1. 簡單回答 → StrOutputParser\n",
    "2. 需要列表 → CommaSeparatedListOutputParser\n",
    "3. 需要驗證 → PydanticOutputParser (推薦！)\n",
    "4. 彈性資料 → JsonOutputParser\n",
    "\n",
    "⚠️  注意事項：\n",
    "- 結構化輸出建議使用 temperature=0 或極低值\n",
    "- Pydantic 提供自動型別檢查和驗證\n",
    "- 複雜結構可能需要多次重試\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PtOnxrJgaGc_"
   },
   "source": [
    "## Part 4: RAG 系統建立"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "InSf4N41aGdA"
   },
   "outputs": [],
   "source": [
    "# Cell 13: 載入論文資料\n",
    "print(\"📚 載入學術論文...\\n\")\n",
    "\n",
    "# 使用 Multi-Agent Debate 論文\n",
    "pdf_path = \"2509.05396v1.pdf\"\n",
    "\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "documents = loader.load()\n",
    "\n",
    "print(f\"✅ 成功載入論文\")\n",
    "print(f\"📄 總頁數: {len(documents)}\")\n",
    "print(f\"📝 第一頁前 200 字元:\\n{documents[0].page_content[:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jlLK1Wl_aGdA"
   },
   "outputs": [],
   "source": [
    "# Cell 14: 文件分割與向量化\n",
    "print(\"✂️  文件分割與向量化...\\n\")\n",
    "\n",
    "# 文件分割\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "texts = text_splitter.split_documents(documents)\n",
    "print(f\"📦 分割成 {len(texts)} 個文字區塊\")\n",
    "\n",
    "# 建立 Embeddings\n",
    "print(\"\\n🔄 建立向量嵌入...\")\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
    ")\n",
    "\n",
    "# 建立向量資料庫\n",
    "print(\"🗄️  建立 FAISS 向量資料庫...\")\n",
    "vectorstore = FAISS.from_documents(texts, embeddings)\n",
    "\n",
    "print(\"\\n✅ RAG 資料準備完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gXiZ7ShOaGdA"
   },
   "outputs": [],
   "source": [
    "# Cell 15: 建立基礎 RAG Chain (無 Parser)\n",
    "print(\"🔗 建立基礎 RAG Chain\\n\")\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "rag_prompt = PromptTemplate(\n",
    "    template=\"\"\"根據以下資訊回答問題。如果資訊中沒有相關內容，請說你不知道。\n",
    "\n",
    "相關資訊:\n",
    "{context}\n",
    "\n",
    "問題: {question}\n",
    "\n",
    "回答:\"\"\",\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=chat_model,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\"prompt\": rag_prompt},\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "# 測試基礎 RAG\n",
    "query = \"請問 multi-agent debate 的主要發現是什麼？\"\n",
    "result = qa_chain.invoke({\"query\": query})\n",
    "\n",
    "print(f\"❓ 問題: {query}\\n\")\n",
    "print(f\"💬 回答: {result['result']}\\n\")\n",
    "print(f\"📌 使用了 {len(result['source_documents'])} 個來源片段\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B-XizGngaGdC"
   },
   "source": [
    "## Part 5: RAG + Output Parser 整合應用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DNsWtekeaGdC",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1759923989760,
     "user_tz": -480,
     "elapsed": 12341,
     "user": {
      "displayName": "Steve Lai",
      "userId": "04934564034426550598"
     }
    },
    "outputId": "44b17d42-e273-4056-8a35-d91459425eae"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "📄 案例 1: 學術論文關鍵資訊提取\n",
      "\n",
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"title\": {\"description\": \"論文標題\", \"title\": \"Title\", \"type\": \"string\"}, \"main_finding\": {\"description\": \"主要研究發現，1-2 句話\", \"title\": \"Main Finding\", \"type\": \"string\"}, \"methodology\": {\"description\": \"研究方法，簡要說明\", \"title\": \"Methodology\", \"type\": \"string\"}, \"key_contributions\": {\"description\": \"主要貢獻，2-3 點\", \"items\": {\"type\": \"string\"}, \"title\": \"Key Contributions\", \"type\": \"array\"}, \"confidence\": {\"description\": \"回答信心度 0-1\", \"maximum\": 1, \"minimum\": 0, \"title\": \"Confidence\", \"type\": \"number\"}}, \"required\": [\"title\", \"main_finding\", \"methodology\", \"key_contributions\", \"confidence\"]}\n",
      "```\n",
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "[Errno 2] No such file or directory: 'drive/MyDrive/data_rag'\n",
      "/content/drive/MyDrive/data_rag\n",
      "✅ Google Drive 掛載成功\n",
      "📚 載入學術論文...\n",
      "\n",
      "✅ 成功載入論文\n",
      "📄 總頁數: 10\n",
      "📝 第一頁前 200 字元:\n",
      "Talk Isn’t Always Cheap: Understanding Failure Modes in Multi-Agent Debate\n",
      "Andrea Wynn* 1 Harsh Satija * 2 Gillian Hadfield 1 3 2\n",
      "Abstract\n",
      "While multi-agent debate has been proposed as\n",
      "a promising str...\n",
      "✂️  文件分割與向量化...\n",
      "\n",
      "📦 分割成 91 個文字區塊\n",
      "\n",
      "🔄 建立向量嵌入...\n",
      "🗄️  建立 FAISS 向量資料庫...\n",
      "\n",
      "✅ RAG 資料準備完成！\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: 根據以下論文片段，提取結構化資訊。\\n\\n論文片段:\\nHopkins University, Baltimore, MD, USA 2Vector Institute\\n3University of Toronto, Toronto, ON, Canada. Correspon-\\ndence to: Andrea Wynn <awynn13@jhu.edu>, Harsh Satija\\n<harsh.satija@vectorinstitute.ai>.\\nProceedings of the 42 nd International Conference on Machine\\nLearning, Vancouver, Canada. PMLR 267, 2025. Copyright 2025\\nby the author(s).\\nmetic and strategic reasoning benchmarks (Du et al., 2023;\\nSubramaniam et al., 2025), produce more truthful answers\\n\\nand evaluations (Chan et al., 2023; Khan et al., 2024), and\\nenhance tasks such as machine translation (Liang et al.,\\n2023) and negotiation (Fu et al., 2023). The core concept\\nof these studies is that by engaging LLM agents through\\nstructured argumentation or discourse, we can facilitate the\\nexchange of reasoning among different agents and guide\\nthem toward more accurate answers. However, most of\\nthese techniques incur significant computational overhead,\\n\\nstanding sycophancy in language models, 2023. URL\\nhttps://arxiv.org/abs/2310.13548.\\nSubramaniam, V ., Du, Y ., Tenenbaum, J. B., Torralba, A.,\\nLi, S., and Mordatch, I. Multiagent finetuning: Self im-\\nprovement with diverse reasoning chains. arXiv preprint\\narXiv:2501.05707, 2025.\\nTalmor, A., Herzig, J., Lourie, N., and Berant, J. Com-\\nmonsenseqa: A question answering challenge target-\\ning commonsense knowledge, 2019. URL https:\\n//arxiv.org/abs/1811.00937.\\n\\n問題: 分析這篇論文的核心內容\\n\\nThe output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\\\"properties\\\": {\\\"foo\\\": {\\\"title\\\": \\\"Foo\\\", \\\"description\\\": \\\"a list of strings\\\", \\\"type\\\": \\\"array\\\", \\\"items\\\": {\\\"type\\\": \\\"string\\\"}}}, \\\"required\\\": [\\\"foo\\\"]}\\nthe object {\\\"foo\\\": [\\\"bar\\\", \\\"baz\\\"]} is a well-formatted instance of the schema. The object {\\\"properties\\\": {\\\"foo\\\": [\\\"bar\\\", \\\"baz\\\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\\\"properties\\\": {\\\"title\\\": {\\\"description\\\": \\\"論文標題\\\", \\\"title\\\": \\\"Title\\\", \\\"type\\\": \\\"string\\\"}, \\\"main_finding\\\": {\\\"description\\\": \\\"主要研究發現，1-2 句話\\\", \\\"title\\\": \\\"Main Finding\\\", \\\"type\\\": \\\"string\\\"}, \\\"methodology\\\": {\\\"description\\\": \\\"研究方法，簡要說明\\\", \\\"title\\\": \\\"Methodology\\\", \\\"type\\\": \\\"string\\\"}, \\\"key_contributions\\\": {\\\"description\\\": \\\"主要貢獻，2-3 點\\\", \\\"items\\\": {\\\"type\\\": \\\"string\\\"}, \\\"title\\\": \\\"Key Contributions\\\", \\\"type\\\": \\\"array\\\"}, \\\"confidence\\\": {\\\"description\\\": \\\"回答信心度 0-1\\\", \\\"maximum\\\": 1, \\\"minimum\\\": 0, \\\"title\\\": \\\"Confidence\\\", \\\"type\\\": \\\"number\\\"}}, \\\"required\\\": [\\\"title\\\", \\\"main_finding\\\", \\\"methodology\\\", \\\"key_contributions\\\", \\\"confidence\\\"]}\\n```\\n\\n分析結果:\"\n",
      "  ]\n",
      "}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/tmp/ipython-input-3444937439.py:81: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  relevant_docs = retriever.get_relevant_documents(query)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[llm:ChatOpenAI] [3.73s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"```json\\n{\\n    \\\"title\\\": \\\"Engaging LLM Agents through Structured Argumentation\\\",\\n    \\\"main_finding\\\": \\\"Engaging LLM agents through structured argumentation or discourse facilitates the exchange of reasoning among different agents and guides them toward more accurate answers.\\\",\\n    \\\"methodology\\\": \\\"The study involves engaging large language model (LLM) agents in structured argumentation or discourse to improve their reasoning and accuracy.\\\",\\n    \\\"key_contributions\\\": [\\n        \\\"Demonstrates that structured argumentation can lead to more truthful answers and evaluations.\\\",\\n        \\\"Highlights the potential of enhancing tasks such as machine translation and negotiation through improved reasoning.\\\",\\n        \\\"Identifies the computational overhead as a significant challenge in implementing these techniques.\\\"\\n    ],\\n    \\\"confidence\\\": 0.9\\n}\\n```\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"```json\\n{\\n    \\\"title\\\": \\\"Engaging LLM Agents through Structured Argumentation\\\",\\n    \\\"main_finding\\\": \\\"Engaging LLM agents through structured argumentation or discourse facilitates the exchange of reasoning among different agents and guides them toward more accurate answers.\\\",\\n    \\\"methodology\\\": \\\"The study involves engaging large language model (LLM) agents in structured argumentation or discourse to improve their reasoning and accuracy.\\\",\\n    \\\"key_contributions\\\": [\\n        \\\"Demonstrates that structured argumentation can lead to more truthful answers and evaluations.\\\",\\n        \\\"Highlights the potential of enhancing tasks such as machine translation and negotiation through improved reasoning.\\\",\\n        \\\"Identifies the computational overhead as a significant challenge in implementing these techniques.\\\"\\n    ],\\n    \\\"confidence\\\": 0.9\\n}\\n```\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 156,\n",
      "                \"prompt_tokens\": 746,\n",
      "                \"total_tokens\": 902,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-4o-2024-08-06\",\n",
      "              \"system_fingerprint\": \"fp_f33640a400\",\n",
      "              \"id\": \"chatcmpl-COMuhNJmMrczFgCAnheQQt3ucpEEY\",\n",
      "              \"service_tier\": \"default\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run--eb2ca537-6282-462c-8298-dd55e0c2ba8a-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 746,\n",
      "              \"output_tokens\": 156,\n",
      "              \"total_tokens\": 902,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 156,\n",
      "      \"prompt_tokens\": 746,\n",
      "      \"total_tokens\": 902,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-4o-2024-08-06\",\n",
      "    \"system_fingerprint\": \"fp_f33640a400\",\n",
      "    \"id\": \"chatcmpl-COMuhNJmMrczFgCAnheQQt3ucpEEY\",\n",
      "    \"service_tier\": \"default\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "✅ 論文分析結果:\n",
      "\n",
      "📌 標題: Engaging LLM Agents through Structured Argumentation\n",
      "\n",
      "🔍 主要發現:\n",
      "Engaging LLM agents through structured argumentation or discourse facilitates the exchange of reasoning among different agents and guides them toward more accurate answers.\n",
      "\n",
      "🛠️  研究方法:\n",
      "The study involves engaging large language model (LLM) agents in structured argumentation or discourse to improve their reasoning and accuracy.\n",
      "\n",
      "💡 主要貢獻:\n",
      "  1. Demonstrates that structured argumentation can lead to more truthful answers and evaluations.\n",
      "  2. Highlights the potential of enhancing tasks such as machine translation and negotiation through improved reasoning.\n",
      "  3. Identifies the computational overhead as a significant challenge in implementing these techniques.\n",
      "\n",
      "📊 信心度: 0.90\n"
     ]
    }
   ],
   "source": [
    "# Cell 16: 案例 1 - 論文關鍵資訊提取\n",
    "print(\"📄 案例 1: 學術論文關鍵資訊提取\\n\")\n",
    "\n",
    "class PaperAnalysis(BaseModel):\n",
    "    title: str = Field(description=\"論文標題\")\n",
    "    main_finding: str = Field(description=\"主要研究發現，1-2 句話\")\n",
    "    methodology: str = Field(description=\"研究方法，簡要說明\")\n",
    "    key_contributions: List[str] = Field(description=\"主要貢獻，2-3 點\")\n",
    "    confidence: float = Field(description=\"回答信心度 0-1\", ge=0, le=1)\n",
    "\n",
    "# 建立 Parser\n",
    "paper_parser = PydanticOutputParser(pydantic_object=PaperAnalysis)\n",
    "print(paper_parser.get_format_instructions())\n",
    "# 建立結構化 RAG Prompt\n",
    "paper_prompt = PromptTemplate(\n",
    "    template=\"\"\"根據以下論文片段，提取結構化資訊。\n",
    "\n",
    "論文片段:\n",
    "{context}\n",
    "\n",
    "問題: {question}\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "分析結果:\"\"\",\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    partial_variables={\"format_instructions\": paper_parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "# Cell 3: 掛載 Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# 切換到資料目錄\n",
    "%cd drive/MyDrive/data_rag\n",
    "\n",
    "print(\"✅ Google Drive 掛載成功\")\n",
    "\n",
    "# Cell 13: 載入論文資料\n",
    "print(\"📚 載入學術論文...\\n\")\n",
    "\n",
    "# 使用 Multi-Agent Debate 論文\n",
    "pdf_path = \"2509.05396v1.pdf\"\n",
    "\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "documents = loader.load()\n",
    "\n",
    "print(f\"✅ 成功載入論文\")\n",
    "print(f\"📄 總頁數: {len(documents)}\")\n",
    "print(f\"📝 第一頁前 200 字元:\\n{documents[0].page_content[:200]}...\")\n",
    "\n",
    "# 手動實作 RAG + Parser 流程\n",
    "query = \"分析這篇論文的核心內容\"\n",
    "# Cell 14: 文件分割與向量化\n",
    "print(\"✂️  文件分割與向量化...\\n\")\n",
    "\n",
    "# 文件分割\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "texts = text_splitter.split_documents(documents)\n",
    "print(f\"📦 分割成 {len(texts)} 個文字區塊\")\n",
    "\n",
    "# 建立 Embeddings\n",
    "print(\"\\n🔄 建立向量嵌入...\")\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
    ")\n",
    "\n",
    "# 建立向量資料庫\n",
    "print(\"🗄️  建立 FAISS 向量資料庫...\")\n",
    "vectorstore = FAISS.from_documents(texts, embeddings)\n",
    "\n",
    "print(\"\\n✅ RAG 資料準備完成！\")\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "# 1. 檢索相關文件\n",
    "relevant_docs = retriever.get_relevant_documents(query)\n",
    "context = \"\\n\\n\".join([doc.page_content for doc in relevant_docs[:3]])\n",
    "\n",
    "# 2. 生成結構化 prompt\n",
    "formatted_prompt = paper_prompt.format(context=context, question=query)\n",
    "\n",
    "# 3. 呼叫 LLM\n",
    "response = chat_model.invoke([HumanMessage(content=formatted_prompt)])\n",
    "\n",
    "# 4. 解析輸出\n",
    "try:\n",
    "    analysis = paper_parser.parse(response.content)\n",
    "\n",
    "    print(\"✅ 論文分析結果:\\n\")\n",
    "    print(f\"📌 標題: {analysis.title}\")\n",
    "    print(f\"\\n🔍 主要發現:\\n{analysis.main_finding}\")\n",
    "    print(f\"\\n🛠️  研究方法:\\n{analysis.methodology}\")\n",
    "    print(f\"\\n💡 主要貢獻:\")\n",
    "    for i, contrib in enumerate(analysis.key_contributions, 1):\n",
    "        print(f\"  {i}. {contrib}\")\n",
    "    print(f\"\\n📊 信心度: {analysis.confidence:.2f}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ 解析失敗: {e}\")\n",
    "    print(f\"\\n原始輸出:\\n{response.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gBlLL79GaGdD"
   },
   "outputs": [],
   "source": [
    "# Cell 17: 案例 2 - 技術問答系統\n",
    "print(\"💻 案例 2: 結構化技術問答\\n\")\n",
    "\n",
    "class TechnicalQA(BaseModel):\n",
    "    question_type: str = Field(description=\"問題類型：概念/方法/比較/實作\")\n",
    "    answer: str = Field(description=\"詳細回答\")\n",
    "    key_terms: List[str] = Field(description=\"關鍵術語，2-4 個\")\n",
    "    difficulty: str = Field(description=\"難度：初級/中級/進階\")\n",
    "    related_topics: List[str] = Field(description=\"相關主題\")\n",
    "    sources_used: int = Field(description=\"使用的來源數量\")\n",
    "\n",
    "tech_parser = PydanticOutputParser(pydantic_object=TechnicalQA)\n",
    "\n",
    "tech_prompt = PromptTemplate(\n",
    "    template=\"\"\"你是一個技術專家。根據以下資訊回答問題。\n",
    "\n",
    "相關資訊:\n",
    "{context}\n",
    "\n",
    "技術問題: {question}\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "結構化回答:\"\"\",\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    partial_variables={\"format_instructions\": tech_parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "query = \"multi-agent debate 和傳統的單一 agent 有什麼差異？\"\n",
    "\n",
    "# RAG + Parser 流程\n",
    "relevant_docs = retriever.get_relevant_documents(query)\n",
    "context = \"\\n\\n\".join([doc.page_content for doc in relevant_docs[:3]])\n",
    "formatted_prompt = tech_prompt.format(context=context, question=query)\n",
    "response = stable_chat.invoke([HumanMessage(content=formatted_prompt)])\n",
    "\n",
    "try:\n",
    "    qa_result = tech_parser.parse(response.content)\n",
    "\n",
    "    print(\"✅ 技術問答結果:\\n\")\n",
    "    print(f\"❓ 問題類型: {qa_result.question_type}\")\n",
    "    print(f\"📊 難度: {qa_result.difficulty}\")\n",
    "    print(f\"\\n💬 回答:\\n{qa_result.answer}\")\n",
    "    print(f\"\\n🔑 關鍵術語: {', '.join(qa_result.key_terms)}\")\n",
    "    print(f\"\\n🔗 相關主題:\")\n",
    "    for topic in qa_result.related_topics:\n",
    "        print(f\"  - {topic}\")\n",
    "    print(f\"\\n📚 使用來源: {qa_result.sources_used} 個片段\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ 解析失敗: {e}\")\n",
    "    print(f\"\\n原始輸出:\\n{response.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NEoUD5Q_aGdD"
   },
   "outputs": [],
   "source": [
    "# Cell 18: 案例 3 - 方法比較分析\n",
    "print(\"⚖️  案例 3: 研究方法比較分析\\n\")\n",
    "\n",
    "class MethodComparison(BaseModel):\n",
    "    method_name: str = Field(description=\"方法名稱\")\n",
    "    advantages: List[str] = Field(description=\"優點，2-3 點\")\n",
    "    disadvantages: List[str] = Field(description=\"缺點，2-3 點\")\n",
    "    use_cases: List[str] = Field(description=\"適用場景\")\n",
    "    performance_note: str = Field(description=\"效能說明\")\n",
    "    recommendation: str = Field(description=\"使用建議\")\n",
    "\n",
    "comparison_parser = PydanticOutputParser(pydantic_object=MethodComparison)\n",
    "\n",
    "comparison_prompt = PromptTemplate(\n",
    "    template=\"\"\"根據以下資訊，分析研究方法的優缺點。\n",
    "\n",
    "研究內容:\n",
    "{context}\n",
    "\n",
    "分析問題: {question}\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "比較分析:\"\"\",\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    partial_variables={\"format_instructions\": comparison_parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "query = \"分析 multi-agent debate 方法的優缺點\"\n",
    "\n",
    "relevant_docs = retriever.get_relevant_documents(query)\n",
    "context = \"\\n\\n\".join([doc.page_content for doc in relevant_docs[:4]])  # 使用更多片段\n",
    "formatted_prompt = comparison_prompt.format(context=context, question=query)\n",
    "response = stable_chat.invoke([HumanMessage(content=formatted_prompt)])\n",
    "\n",
    "try:\n",
    "    comparison = comparison_parser.parse(response.content)\n",
    "\n",
    "    print(\"✅ 方法比較分析:\\n\")\n",
    "    print(f\"📌 方法: {comparison.method_name}\\n\")\n",
    "\n",
    "    print(\"✅ 優點:\")\n",
    "    for i, adv in enumerate(comparison.advantages, 1):\n",
    "        print(f\"  {i}. {adv}\")\n",
    "\n",
    "    print(\"\\n❌ 缺點:\")\n",
    "    for i, dis in enumerate(comparison.disadvantages, 1):\n",
    "        print(f\"  {i}. {dis}\")\n",
    "\n",
    "    print(\"\\n🎯 適用場景:\")\n",
    "    for use_case in comparison.use_cases:\n",
    "        print(f\"  • {use_case}\")\n",
    "\n",
    "    print(f\"\\n📊 效能說明:\\n{comparison.performance_note}\")\n",
    "    print(f\"\\n💡 使用建議:\\n{comparison.recommendation}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ 解析失敗: {e}\")\n",
    "    print(f\"\\n原始輸出:\\n{response.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 6: 進階檢索技術 - BM25、Hybrid Search、Rerank (NEXT WEEK)"
   ],
   "metadata": {
    "id": "Pr2xRWaNaGdA"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Cell 15.5: 檢索方法效果比較\n",
    "print(\"📊 範例 5: 檢索方法全面比較\\n\")\n",
    "\n",
    "import time\n",
    "\n",
    "def compare_retrieval_methods(query: str):\n",
    "    \"\"\"比較不同檢索方法的效果\"\"\"\n",
    "    results = {}\n",
    "\n",
    "    # 1. Vector 檢索\n",
    "    start = time.time()\n",
    "    vector_docs = retriever.invoke(query)[:3]\n",
    "    vector_time = time.time() - start\n",
    "    results['Vector'] = {\n",
    "        'docs': vector_docs,\n",
    "        'time': vector_time,\n",
    "        'method': '語義向量檢索'\n",
    "    }\n",
    "\n",
    "    # 2. BM25 檢索\n",
    "    start = time.time()\n",
    "    bm25_docs = bm25_retriever.invoke(query)[:3]\n",
    "    bm25_time = time.time() - start\n",
    "    results['BM25'] = {\n",
    "        'docs': bm25_docs,\n",
    "        'time': bm25_time,\n",
    "        'method': '關鍵字檢索'\n",
    "    }\n",
    "\n",
    "    # 3. Hybrid 檢索\n",
    "    start = time.time()\n",
    "    hybrid_docs = hybrid_retriever.invoke(query)[:3]\n",
    "    hybrid_time = time.time() - start\n",
    "    results['Hybrid'] = {\n",
    "        'docs': hybrid_docs,\n",
    "        'time': hybrid_time,\n",
    "        'method': '混合檢索'\n",
    "    }\n",
    "\n",
    "    # 4. Hybrid + Rerank\n",
    "    start = time.time()\n",
    "    reranked_docs = hybrid_rerank_retriever(query, k=3, candidate_k=10)\n",
    "    rerank_time = time.time() - start\n",
    "    results['Hybrid+Rerank'] = {\n",
    "        'docs': reranked_docs,\n",
    "        'time': rerank_time,\n",
    "        'method': '混合檢索 + 重排序'\n",
    "    }\n",
    "\n",
    "    return results\n",
    "\n",
    "# 測試不同類型的查詢\n",
    "test_cases = [\n",
    "    {\n",
    "        'query': 'multi-agent debate accuracy performance',\n",
    "        'type': '關鍵字密集型查詢'\n",
    "    },\n",
    "    {\n",
    "        'query': 'How can we improve the reasoning ability of language models?',\n",
    "        'type': '語義理解型查詢'\n",
    "    }\n",
    "]\n",
    "\n",
    "for case in test_cases:\n",
    "    query = case['query']\n",
    "    query_type = case['type']\n",
    "\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"🔬 測試案例: {query_type}\")\n",
    "    print(f\"❓ 查詢: {query}\\n\")\n",
    "\n",
    "    # 執行比較\n",
    "    comparison = compare_retrieval_methods(query)\n",
    "\n",
    "    # 顯示結果\n",
    "    print(\"📊 檢索結果比較：\\n\")\n",
    "\n",
    "    for method_name, data in comparison.items():\n",
    "        print(f\"{'─'*80}\")\n",
    "        print(f\"🔹 方法: {method_name} ({data['method']})\")\n",
    "        print(f\"⏱️  耗時: {data['time']*1000:.2f} ms\")\n",
    "        print(f\"📄 檢索結果:\")\n",
    "\n",
    "        for i, doc in enumerate(data['docs'], 1):\n",
    "            preview = doc.page_content[:100].replace('\\n', ' ')\n",
    "            print(f\"   {i}. {preview}...\")\n",
    "        print()\n",
    "\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "# 總結表格\n",
    "print(\"📈 檢索方法特性總結：\\n\")\n",
    "print(\"┌─────────────────┬──────────────────┬──────────────┬─────────────────┐\")\n",
    "print(\"│ 方法            │ 優點             │ 缺點         │ 適用場景        │\")\n",
    "print(\"├─────────────────┼──────────────────┼──────────────┼─────────────────┤\")\n",
    "print(\"│ Vector          │ 語義理解強       │ 關鍵字弱     │ 語義查詢        │\")\n",
    "print(\"│ BM25            │ 關鍵字精確       │ 無語義理解   │ 精確匹配        │\")\n",
    "print(\"│ Hybrid          │ 兼具兩者優點     │ 參數調整複雜 │ 通用查詢        │\")\n",
    "print(\"│ Hybrid+Rerank   │ 最高準確度       │ 速度較慢     │ 品質要求高      │\")\n",
    "print(\"└─────────────────┴──────────────────┴──────────────┴─────────────────┘\")\n",
    "\n",
    "print(\"\\n💡 選擇建議：\")\n",
    "print(\"• 延遲敏感 → Vector 或 BM25\")\n",
    "print(\"• 品質優先 → Hybrid + Rerank (推薦！)\")\n",
    "print(\"• 平衡方案 → Hybrid\")\n",
    "print(\"• 特定領域 → 根據查詢類型選擇\")\n"
   ],
   "metadata": {
    "id": "-rOWdCYAaGdB"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Cell 15.4: 完整的 Hybrid + Rerank RAG Pipeline\n",
    "print(\"🚀 範例 4: 完整 Hybrid + Rerank RAG 系統\\n\")\n",
    "\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "print(\"📘 完整 Pipeline 流程：\")\n",
    "print(\"1️⃣  Hybrid 檢索：BM25 + Vector 混合檢索\")\n",
    "print(\"2️⃣  Rerank：使用 Cross-Encoder 重新排序\")\n",
    "print(\"3️⃣  Context 組合：將最相關文檔組合為上下文\")\n",
    "print(\"4️⃣  LLM 生成：基於優質上下文生成答案\\n\")\n",
    "\n",
    "def hybrid_rerank_retriever(query: str, k: int = 3, candidate_k: int = 10):\n",
    "    \"\"\"Hybrid + Rerank 檢索器\"\"\"\n",
    "    # Step 1: Hybrid 檢索\n",
    "    candidates = hybrid_retriever.invoke(query)[:candidate_k]\n",
    "\n",
    "    # Step 2: Rerank\n",
    "    reranked = rerank_documents(query, candidates, top_k=k)\n",
    "\n",
    "    # 返回文檔（不含分數）\n",
    "    return [doc for doc, score in reranked]\n",
    "\n",
    "# 建立完整的 RAG Chain\n",
    "advanced_rag_prompt = PromptTemplate(\n",
    "    template=\"\"\"你是一個專業的學術論文分析助手。請根據以下資訊詳細回答問題。\n",
    "\n",
    "相關資訊:\n",
    "{context}\n",
    "\n",
    "問題: {question}\n",
    "\n",
    "請提供：\n",
    "1. 直接回答問題\n",
    "2. 引用相關證據\n",
    "3. 如果資訊不足，請說明\n",
    "\n",
    "回答:\"\"\",\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "# 測試完整系統\n",
    "test_queries = [\n",
    "    \"What is the main contribution of this research?\",\n",
    "    \"How does multi-agent debate improve performance?\",\n",
    "    \"What are the limitations of this approach?\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"❓ 問題: {query}\\n\")\n",
    "\n",
    "    # 使用 Hybrid + Rerank 檢索\n",
    "    print(\"🔍 執行 Hybrid + Rerank 檢索...\")\n",
    "    relevant_docs = hybrid_rerank_retriever(query, k=3, candidate_k=10)\n",
    "\n",
    "    print(f\"✅ 檢索到 {len(relevant_docs)} 個高相關文檔\\n\")\n",
    "\n",
    "    # 組合上下文\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in relevant_docs])\n",
    "\n",
    "    # 生成答案\n",
    "    print(\"🤖 生成答案...\\n\")\n",
    "    formatted_prompt = advanced_rag_prompt.format(context=context, question=query)\n",
    "    response = chat_model.invoke([HumanMessage(content=formatted_prompt)])\n",
    "\n",
    "    print(\"💬 回答:\")\n",
    "    print(response.content)\n",
    "    print(f\"\\n📚 使用來源: {len(relevant_docs)} 個文檔片段\")\n",
    "    print(f\"📄 來源頁碼: {', '.join([str(doc.metadata.get('page', 'N/A')) for doc in relevant_docs])}\")\n",
    "\n",
    "print(f\"\\n{'='*70}\\n\")\n",
    "print(\"✨ 系統優勢總結：\")\n",
    "print(\"✅ Hybrid Search - 結合關鍵字與語義檢索\")\n",
    "print(\"✅ Reranker - 精確排序最相關文檔\")\n",
    "print(\"✅ 高品質上下文 - 提升 LLM 回答準確度\")\n",
    "print(\"✅ 減少幻覺 - 基於真實文檔內容生成\")"
   ],
   "metadata": {
    "id": "ljU6pMM5aGdB"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Cell 15.3: Reranker - 重新排序提升相關性\n",
    "print(\"🎯 範例 3: Reranker (重新排序)\\n\")\n",
    "\n",
    "from sentence_transformers import CrossEncoder\n",
    "import numpy as np\n",
    "\n",
    "print(\"📘 Reranker 原理：\")\n",
    "print(\"- 使用 Cross-Encoder 模型對檢索結果重新評分\")\n",
    "print(\"- Cross-Encoder 同時考慮查詢和文檔，計算相關性分數\")\n",
    "print(\"- 比 Bi-Encoder (向量檢索) 更精確，但速度較慢\")\n",
    "print(\"- 適合對初步檢索結果進行精煉\\n\")\n",
    "\n",
    "# 載入 Reranker 模型（使用輕量級模型以節省資源）\n",
    "print(\"🔄 載入 Reranker 模型...\")\n",
    "reranker = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
    "print(\"✅ Reranker 模型載入完成\\n\")\n",
    "\n",
    "def rerank_documents(query: str, documents: list, top_k: int = 3):\n",
    "    \"\"\"使用 Reranker 對文檔重新排序\"\"\"\n",
    "    # 準備 query-document pairs\n",
    "    pairs = [[query, doc.page_content] for doc in documents]\n",
    "\n",
    "    # 計算相關性分數\n",
    "    scores = reranker.predict(pairs)\n",
    "\n",
    "    # 按分數排序\n",
    "    sorted_indices = np.argsort(scores)[::-1][:top_k]\n",
    "\n",
    "    # 返回排序後的文檔和分數\n",
    "    reranked_docs = [(documents[i], scores[i]) for i in sorted_indices]\n",
    "    return reranked_docs\n",
    "\n",
    "# 測試 Reranker\n",
    "query = \"What are the key findings about multi-agent debate?\"\n",
    "\n",
    "print(f\"❓ 查詢: {query}\\n\")\n",
    "\n",
    "# 先用 Hybrid 檢索獲取候選文檔\n",
    "print(\"🔀 步驟 1: Hybrid 檢索 (獲取 10 個候選)\")\n",
    "candidates = hybrid_retriever.invoke(query)[:10]\n",
    "print(f\"   取得 {len(candidates)} 個候選文檔\\n\")\n",
    "\n",
    "# 使用 Reranker 重新排序\n",
    "print(\"🎯 步驟 2: Reranker 重新排序\")\n",
    "reranked_results = rerank_documents(query, candidates, top_k=3)\n",
    "\n",
    "print(\"\\n📊 Reranked 結果 (按相關性排序):\\n\")\n",
    "for i, (doc, score) in enumerate(reranked_results, 1):\n",
    "    print(f\"排名 {i} (分數: {score:.4f}):\")\n",
    "    print(f\"  內容: {doc.page_content[:120]}...\")\n",
    "    print(f\"  來源: 第 {doc.metadata.get('page', 'N/A')} 頁\")\n",
    "    print()\n",
    "\n",
    "print(\"💡 Reranker 優勢：\")\n",
    "print(\"- 更精確的相關性評估\")\n",
    "print(\"- 減少不相關結果\")\n",
    "print(\"- 提升 RAG 系統整體品質\")"
   ],
   "metadata": {
    "id": "uIpv_QPbaGdC"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Cell 15.2: Hybrid Search - 結合 BM25 與向量檢索\n",
    "print(\"🔀 範例 2: Hybrid Search (混合檢索)\\n\")\n",
    "\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "\n",
    "print(\"📘 Hybrid Search 原理：\")\n",
    "print(\"- 結合 BM25 (關鍵字) 和 Vector (語義) 檢索\")\n",
    "print(\"- 使用加權平均合併兩種檢索結果\")\n",
    "print(\"- 優點：同時獲得精確匹配和語義理解\\n\")\n",
    "\n",
    "# 建立 Ensemble Retriever (混合檢索器)\n",
    "hybrid_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, retriever],  # BM25 + Vector\n",
    "    weights=[0.5, 0.5]  # 各佔 50% 權重\n",
    ")\n",
    "\n",
    "# 比較測試：使用更語義化的查詢\n",
    "test_queries = [\n",
    "    \"What is the main contribution of this paper?\",  # 語義查詢\n",
    "    \"multi-agent debate performance results\",  # 關鍵字查詢\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"❓ 查詢: {query}\\n\")\n",
    "\n",
    "    # Vector 檢索\n",
    "    print(\"🎯 Vector 檢索 (前 2 個):\")\n",
    "    vector_results = retriever.invoke(query)[:2]\n",
    "    for i, doc in enumerate(vector_results, 1):\n",
    "        print(f\"  {i}. {doc.page_content[:80]}... (頁 {doc.metadata.get('page', 'N/A')})\")\n",
    "\n",
    "    # BM25 檢索\n",
    "    print(\"\\n🔍 BM25 檢索 (前 2 個):\")\n",
    "    bm25_results = bm25_retriever.invoke(query)[:2]\n",
    "    for i, doc in enumerate(bm25_results, 1):\n",
    "        print(f\"  {i}. {doc.page_content[:80]}... (頁 {doc.metadata.get('page', 'N/A')})\")\n",
    "\n",
    "    # Hybrid 檢索\n",
    "    print(\"\\n🔀 Hybrid 檢索 (前 3 個):\")\n",
    "    hybrid_results = hybrid_retriever.invoke(query)[:3]\n",
    "    for i, doc in enumerate(hybrid_results, 1):\n",
    "        print(f\"  {i}. {doc.page_content[:80]}... (頁 {doc.metadata.get('page', 'N/A')})\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"\\n💡 觀察重點：\")\n",
    "print(\"- 語義查詢：Vector 表現更好，理解問題意圖\")\n",
    "print(\"- 關鍵字查詢：BM25 表現更好，精確匹配\")\n",
    "print(\"- Hybrid 結合兩者優勢，更穩健\")"
   ],
   "metadata": {
    "id": "tEmb8ZZjaGdC"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Cell 15.1: BM25 Retriever - 關鍵字檢索\n",
    "print(\"🔍 範例 1: BM25 Retriever (關鍵字檢索)\\n\")\n",
    "\n",
    "from langchain.retrievers import BM25Retriever\n",
    "\n",
    "print(\"📘 BM25 演算法說明：\")\n",
    "print(\"- BM25 (Best Matching 25) 是一種基於 TF-IDF 的排序函數\")\n",
    "print(\"- 優點：關鍵字匹配精確、不需要向量化、速度快\")\n",
    "print(\"- 缺點：無法理解語義、對同義詞不敏感\\n\")\n",
    "\n",
    "# 建立 BM25 Retriever\n",
    "bm25_retriever = BM25Retriever.from_documents(texts)\n",
    "bm25_retriever.k = 3  # 返回前 3 個結果\n",
    "\n",
    "# 測試查詢\n",
    "query = \"multi-agent debate methodology\"\n",
    "\n",
    "print(f\"❓ 查詢: {query}\\n\")\n",
    "print(\"🔎 BM25 檢索結果:\\n\")\n",
    "\n",
    "bm25_results = bm25_retriever.invoke(query)\n",
    "\n",
    "for i, doc in enumerate(bm25_results, 1):\n",
    "    print(f\"📄 結果 {i}:\")\n",
    "    print(f\"內容: {doc.page_content[:150]}...\")\n",
    "    print(f\"來源: 第 {doc.metadata.get('page', 'N/A')} 頁\")\n",
    "    print()"
   ],
   "metadata": {
    "id": "6zfu-kVKaGdC"
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "7afc731f8de1445c83a29b96d7f76aec": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1b4d2d96a2d54325b30acaeb6d74f88a",
       "IPY_MODEL_da7df6d2dbf94162bc73e0b1d79546b6",
       "IPY_MODEL_130293906dcf41ccb4edb5669d39cb80"
      ],
      "layout": "IPY_MODEL_1ea423c9fa0449fbbf82fc932fc1a79e"
     }
    },
    "1b4d2d96a2d54325b30acaeb6d74f88a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0f58401920c84aaba561e5c439f4f55e",
      "placeholder": "​",
      "style": "IPY_MODEL_b66799f33df544b5b120af5a2ac1562a",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "da7df6d2dbf94162bc73e0b1d79546b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b4dc2bbfce51494c933bb49157e82e1b",
      "max": 1156999,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_391246fea32d43b2a43422bf4c4e6529",
      "value": 1156999
     }
    },
    "130293906dcf41ccb4edb5669d39cb80": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b492eb86bb2b41579f501e76d744180e",
      "placeholder": "​",
      "style": "IPY_MODEL_5a98d662bbff499ca7fba38999f13e84",
      "value": " 1.16M/1.16M [00:00&lt;00:00, 2.57MB/s]"
     }
    },
    "1ea423c9fa0449fbbf82fc932fc1a79e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0f58401920c84aaba561e5c439f4f55e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b66799f33df544b5b120af5a2ac1562a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b4dc2bbfce51494c933bb49157e82e1b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "391246fea32d43b2a43422bf4c4e6529": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b492eb86bb2b41579f501e76d744180e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5a98d662bbff499ca7fba38999f13e84": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3f50fa5c591549d78bde4d6f2a740a54": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e574f2b816574312bf77425cb8051a94",
       "IPY_MODEL_d44bb50de7b043a4998779cfa3b0762d",
       "IPY_MODEL_aa3d278bd1134847905b15a383dde452"
      ],
      "layout": "IPY_MODEL_d7a70e469673481d9ba9f1f84ccae2f3"
     }
    },
    "e574f2b816574312bf77425cb8051a94": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0de13df92f484983b6914f2bc5864c15",
      "placeholder": "​",
      "style": "IPY_MODEL_2e745fe308da4ee58f36a8fa68a99ddb",
      "value": "tokenizer.model: 100%"
     }
    },
    "d44bb50de7b043a4998779cfa3b0762d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9bb687ed770343a2a51b3d335a6dd501",
      "max": 4689074,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d319c650e3a14e8b9de53174f2091882",
      "value": 4689074
     }
    },
    "aa3d278bd1134847905b15a383dde452": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_69d1509c8d994ffdad96e75f1c418c4d",
      "placeholder": "​",
      "style": "IPY_MODEL_5873a2c2aded44148681dbfa2cc04ad6",
      "value": " 4.69M/4.69M [00:01&lt;00:00, 125kB/s]"
     }
    },
    "d7a70e469673481d9ba9f1f84ccae2f3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0de13df92f484983b6914f2bc5864c15": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2e745fe308da4ee58f36a8fa68a99ddb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9bb687ed770343a2a51b3d335a6dd501": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d319c650e3a14e8b9de53174f2091882": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "69d1509c8d994ffdad96e75f1c418c4d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5873a2c2aded44148681dbfa2cc04ad6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a8d55e5fdfca461a9fe1141248e57df7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_acc4c7b4e1f8468ba51be281942ed03b",
       "IPY_MODEL_268be300de1643179eada4107173c97c",
       "IPY_MODEL_7c713a1fbb8d4203a8d0f046121d67e6"
      ],
      "layout": "IPY_MODEL_82f378a4739c497287c2045d0074edc2"
     }
    },
    "acc4c7b4e1f8468ba51be281942ed03b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b16a90ceffe141aa82ad15638422fc1c",
      "placeholder": "​",
      "style": "IPY_MODEL_ef3d11e51f0b46f19c31f970e0bbdc68",
      "value": "tokenizer.json: 100%"
     }
    },
    "268be300de1643179eada4107173c97c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0d00480b3f5f4d16af85ecaea52c075f",
      "max": 33384568,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d060357e6bf645dc8eb8742ebf7f7248",
      "value": 33384568
     }
    },
    "7c713a1fbb8d4203a8d0f046121d67e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_787724bfb57946a1a7991823b23864eb",
      "placeholder": "​",
      "style": "IPY_MODEL_32a44cd710034ce79c7dadbf870b5c72",
      "value": " 33.4M/33.4M [00:00&lt;00:00, 61.2MB/s]"
     }
    },
    "82f378a4739c497287c2045d0074edc2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b16a90ceffe141aa82ad15638422fc1c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ef3d11e51f0b46f19c31f970e0bbdc68": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0d00480b3f5f4d16af85ecaea52c075f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d060357e6bf645dc8eb8742ebf7f7248": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "787724bfb57946a1a7991823b23864eb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "32a44cd710034ce79c7dadbf870b5c72": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1ff6f60bce2d4b9689d66660301c44a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_11f541cdb1bc4a5aa4302e4bbabfdfa7",
       "IPY_MODEL_7cebbf13dcb44bba82fb434e1a95b84e",
       "IPY_MODEL_1cecdbbffd464707b6e67933a49fb387"
      ],
      "layout": "IPY_MODEL_c49311904ec448c69af9d6f6aebf6695"
     }
    },
    "11f541cdb1bc4a5aa4302e4bbabfdfa7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_623edf6da7ed457199f6510c36332e1b",
      "placeholder": "​",
      "style": "IPY_MODEL_60c7b151bcbf450889d11f1853691d35",
      "value": "added_tokens.json: 100%"
     }
    },
    "7cebbf13dcb44bba82fb434e1a95b84e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_16ab9f23a9fc4bdf9f577f9e331e2879",
      "max": 35,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_dfb39489226b4cef8c173bc1e3749670",
      "value": 35
     }
    },
    "1cecdbbffd464707b6e67933a49fb387": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3125c9628d7343209a95150199ffe4ee",
      "placeholder": "​",
      "style": "IPY_MODEL_ee9448c047064b5194f1d4353010cf15",
      "value": " 35.0/35.0 [00:00&lt;00:00, 4.07kB/s]"
     }
    },
    "c49311904ec448c69af9d6f6aebf6695": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "623edf6da7ed457199f6510c36332e1b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "60c7b151bcbf450889d11f1853691d35": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "16ab9f23a9fc4bdf9f577f9e331e2879": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dfb39489226b4cef8c173bc1e3749670": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3125c9628d7343209a95150199ffe4ee": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ee9448c047064b5194f1d4353010cf15": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3f6948b90f2b404097edc9b99f2770ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_079e16db89564db695d3ff7745cac180",
       "IPY_MODEL_651a448fa9714340ab6d0e632545cc9e",
       "IPY_MODEL_26dfe00b7c0149a8b66c711fe42f8dd8"
      ],
      "layout": "IPY_MODEL_eb385027e9f14f8f8d853c8fb64de2bb"
     }
    },
    "079e16db89564db695d3ff7745cac180": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ad9a16098e524806b51f58ea0fd6d0b5",
      "placeholder": "​",
      "style": "IPY_MODEL_42a7766230f644c58865d48bff70cf0a",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "651a448fa9714340ab6d0e632545cc9e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_273d1d1d9350420ab87416fd3b4ce984",
      "max": 662,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_eb696f793f19490bb86c257ba6a9fd87",
      "value": 662
     }
    },
    "26dfe00b7c0149a8b66c711fe42f8dd8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7ce9710e673749beb3957466d4167cd4",
      "placeholder": "​",
      "style": "IPY_MODEL_18cfd58e34fe464e948ffc273feb3386",
      "value": " 662/662 [00:00&lt;00:00, 77.4kB/s]"
     }
    },
    "eb385027e9f14f8f8d853c8fb64de2bb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ad9a16098e524806b51f58ea0fd6d0b5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "42a7766230f644c58865d48bff70cf0a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "273d1d1d9350420ab87416fd3b4ce984": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eb696f793f19490bb86c257ba6a9fd87": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7ce9710e673749beb3957466d4167cd4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "18cfd58e34fe464e948ffc273feb3386": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4553f503860e496ca1403ebddc781775": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fbe010e0a6bb4ed5a383e3481e3facff",
       "IPY_MODEL_50eb8c3689b34314ae12fcaca03197cf",
       "IPY_MODEL_69001a7e19044ad3824289d853f02818"
      ],
      "layout": "IPY_MODEL_5567ee66cf2c4ceb8b8bcbd13781a0de"
     }
    },
    "fbe010e0a6bb4ed5a383e3481e3facff": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9d1a7ded354b404e8b608996a5719200",
      "placeholder": "​",
      "style": "IPY_MODEL_02557ac135a443a1ba704cc10af99109",
      "value": "config.json: 100%"
     }
    },
    "50eb8c3689b34314ae12fcaca03197cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d93a7e3798e045f39c8ff5f35dc8ca3e",
      "max": 899,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_260d1e9b6d694136b272ab13f50eca1b",
      "value": 899
     }
    },
    "69001a7e19044ad3824289d853f02818": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e4ca40c230f5437a8148bc0e67893565",
      "placeholder": "​",
      "style": "IPY_MODEL_e1497a6b263b4f589fe455976cd73ed1",
      "value": " 899/899 [00:00&lt;00:00, 63.9kB/s]"
     }
    },
    "5567ee66cf2c4ceb8b8bcbd13781a0de": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9d1a7ded354b404e8b608996a5719200": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "02557ac135a443a1ba704cc10af99109": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d93a7e3798e045f39c8ff5f35dc8ca3e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "260d1e9b6d694136b272ab13f50eca1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e4ca40c230f5437a8148bc0e67893565": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e1497a6b263b4f589fe455976cd73ed1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c95a45bf6efc40f2956ebf61d0a64a24": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d41c0465b9f744bfa15144e49d7eeadb",
       "IPY_MODEL_75235c59bd0e4922885d5b44288a7ab3",
       "IPY_MODEL_73ae67b23f504a6ea67e7a828b46617f"
      ],
      "layout": "IPY_MODEL_b0904b0f4e0a43f99e2983006eb4ad60"
     }
    },
    "d41c0465b9f744bfa15144e49d7eeadb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_53a5013498694286a29524cc2facbb11",
      "placeholder": "​",
      "style": "IPY_MODEL_d4397dfba29443c0881b59531f1811f2",
      "value": "model.safetensors:  10%"
     }
    },
    "75235c59bd0e4922885d5b44288a7ab3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d471ea754d594eb2b383d602a069914b",
      "max": 1999811208,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8bc768f5203b412a955cacd5cf56c28c",
      "value": 202076494
     }
    },
    "73ae67b23f504a6ea67e7a828b46617f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2c52d10cceca48368f5442a188c0b3d1",
      "placeholder": "​",
      "style": "IPY_MODEL_2c9db00610b24365898760be0f2eb4b4",
      "value": " 202M/2.00G [00:48&lt;04:13, 7.09MB/s]"
     }
    },
    "b0904b0f4e0a43f99e2983006eb4ad60": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "53a5013498694286a29524cc2facbb11": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d4397dfba29443c0881b59531f1811f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d471ea754d594eb2b383d602a069914b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8bc768f5203b412a955cacd5cf56c28c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2c52d10cceca48368f5442a188c0b3d1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2c9db00610b24365898760be0f2eb4b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}