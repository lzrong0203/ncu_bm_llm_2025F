{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6: Output Parser 進階 RAG 應用\n",
    "\n",
    "## 課程目標\n",
    "- 掌握模型量化技術（4-bit quantization）\n",
    "- 學習 LangChain Output Parser 各種類型\n",
    "- 實作結構化 RAG 輸出系統\n",
    "- 應用於實際商業場景\n",
    "\n",
    "## 教學大綱\n",
    "1. 環境設定與量化技術\n",
    "2. Output Parser 基礎\n",
    "3. RAG + Parser 整合\n",
    "4. 商業應用案例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: 環境設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 1: 安裝必要套件\n!pip install -q langchain-huggingface langchain-community langchain\n!pip install -q transformers accelerate bitsandbytes\n!pip install -q pypdf faiss-cpu==1.10.0\n!pip install -q pydantic\n!pip install -q rank-bm25  # BM25 檢索\n!pip install -q sentence-transformers  # Reranker\n\nprint(\"✅ 套件安裝完成\")\nprint(\"⚠️  請重啟 Runtime 後再執行後續 cells\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: HuggingFace 認證\n",
    "from google.colab import userdata\n",
    "from huggingface_hub import login\n",
    "\n",
    "token = userdata.get('HF_TOKEN')\n",
    "login(token=token)\n",
    "\n",
    "print(\"✅ HuggingFace 認證成功\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: 掛載 Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# 切換到資料目錄\n",
    "%cd drive/MyDrive/data_rag\n",
    "\n",
    "print(\"✅ Google Drive 掛載成功\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: 導入基礎套件\n",
    "import torch\n",
    "from transformers import BitsAndBytesConfig\n",
    "from langchain_huggingface import ChatHuggingFace, HuggingFacePipeline, HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import (\n",
    "    StrOutputParser,\n",
    "    JsonOutputParser,\n",
    "    PydanticOutputParser,\n",
    "    CommaSeparatedListOutputParser\n",
    ")\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional, Dict\n",
    "import json\n",
    "\n",
    "print(\"✅ 套件導入完成\")\n",
    "print(f\"🔧 PyTorch 版本: {torch.__version__}\")\n",
    "print(f\"🎮 CUDA 可用: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"📊 GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: 量化技術實戰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: 設定 4-bit 量化配置\n",
    "print(\"⚙️  設定 4-bit 量化配置...\")\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,                      # 啟用 4-bit 量化\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,  # 使用 bfloat16 計算\n",
    "    bnb_4bit_quant_type=\"nf4\",             # NormalFloat 4-bit 量化類型\n",
    "    bnb_4bit_use_double_quant=True,        # 雙重量化，進一步壓縮\n",
    ")\n",
    "\n",
    "print(\"\"\"\\n📘 量化參數說明：\n",
    "- load_in_4bit: 將模型權重量化為 4-bit（原本 16-bit）\n",
    "- bnb_4bit_compute_dtype: 計算時使用的資料型別\n",
    "- bnb_4bit_quant_type: NF4 (NormalFloat) 適合神經網路\n",
    "- bnb_4bit_use_double_quant: 量化常數也進行量化\n",
    "\n",
    "💡 預期效果：\n",
    "- 記憶體使用減少約 75%\n",
    "- 1B 模型從 ~2GB 降至 ~0.5GB\n",
    "- 推理速度略有提升\n",
    "- 精度損失極小（<1%）\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: 載入量化模型\n",
    "print(\"🚀 載入量化模型 gemma-3-1b-it...\\n\")\n",
    "\n",
    "llm = HuggingFacePipeline.from_model_id(\n",
    "    model_id=\"google/gemma-3-1b-it\",\n",
    "    task=\"text-generation\",\n",
    "    model_kwargs={\"quantization_config\": quantization_config},\n",
    "    pipeline_kwargs={\n",
    "        \"max_new_tokens\": 512,\n",
    "        \"temperature\": 0.7,\n",
    "        \"top_p\": 0.9,\n",
    "    }\n",
    ")\n",
    "\n",
    "chat_model = ChatHuggingFace(llm=llm)\n",
    "\n",
    "print(\"\\n✅ 模型載入成功！\")\n",
    "print(\"\\n💾 記憶體使用情況：\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"已分配: {torch.cuda.memory_allocated(0) / 1024**3:.2f} GB\")\n",
    "    print(f\"已保留: {torch.cuda.memory_reserved(0) / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: 測試量化模型\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "print(\"🧪 測試量化模型輸出...\\n\")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"你是一個專業的 AI 助手，請用繁體中文簡潔回答。\"),\n",
    "    HumanMessage(\"什麼是模型量化？請用 2-3 句話說明。\")\n",
    "]\n",
    "\n",
    "response = chat_model.invoke(messages)\n",
    "print(\"🤖 模型回答：\")\n",
    "print(response.content)\n",
    "print(\"\\n✅ 量化模型測試成功！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Output Parser 基礎教學"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: StrOutputParser - 基本字串解析\n",
    "print(\"📝 範例 1: StrOutputParser (字串解析器)\\n\")\n",
    "\n",
    "str_parser = StrOutputParser()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"請用一句話解釋：{concept}\",\n",
    "    input_variables=[\"concept\"]\n",
    ")\n",
    "\n",
    "chain = prompt | chat_model | str_parser\n",
    "\n",
    "result = chain.invoke({\"concept\": \"RAG (Retrieval-Augmented Generation)\"})\n",
    "print(f\"輸出類型: {type(result)}\")\n",
    "print(f\"內容: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: CommaSeparatedListOutputParser - 列表解析\n",
    "print(\"📋 範例 2: CommaSeparatedListOutputParser (列表解析器)\\n\")\n",
    "\n",
    "list_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"列出 5 個{category}，用逗號分隔，只輸出項目名稱：\",\n",
    "    input_variables=[\"category\"]\n",
    ")\n",
    "\n",
    "chain = prompt | chat_model | list_parser\n",
    "\n",
    "result = chain.invoke({\"category\": \"機器學習演算法\"})\n",
    "print(f\"輸出類型: {type(result)}\")\n",
    "print(f\"列表項目:\")\n",
    "for i, item in enumerate(result, 1):\n",
    "    print(f\"  {i}. {item.strip()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 10: JsonOutputParser - JSON 格式解析（改進版）\nprint(\"🔧 範例 3: JsonOutputParser (JSON 解析器)\\n\")\n\n# 定義簡單的 JSON schema\nclass Product(BaseModel):\n    name: str = Field(description=\"產品名稱\")\n    category: str = Field(description=\"產品類別\")\n    price: int = Field(description=\"價格（新台幣）\")\n    in_stock: bool = Field(description=\"是否有庫存\")\n\njson_parser = JsonOutputParser(pydantic_object=Product)\n\n# 改進的 Prompt - 使用 Few-Shot 範例\nprompt = PromptTemplate(\n    template=\"\"\"從產品描述中提取資訊並輸出 JSON 格式。\n\n範例：\n產品描述: iPhone 15 是 Apple 的智慧手機，售價 32900 元，目前缺貨\nJSON: {{\"name\": \"iPhone 15\", \"category\": \"智慧手機\", \"price\": 32900, \"in_stock\": false}}\n\n現在請處理：\n產品描述: {description}\nJSON:\"\"\",\n    input_variables=[\"description\"]\n)\n\n# 建立 LLM（直接用參數，不使用 GenerationConfig 物件）\njson_llm = HuggingFacePipeline.from_model_id(\n    model_id=\"google/gemma-3-1b-it\",\n    task=\"text-generation\",\n    model_kwargs={\n        \"quantization_config\": quantization_config,\n        \"device_map\": \"auto\"\n    },\n    pipeline_kwargs={\n        \"max_new_tokens\": 128,\n        \"do_sample\": False,        # 不使用採樣（確定性輸出）\n        \"pad_token_id\": 0,         # 設定 padding token\n        \"eos_token_id\": 1          # 設定 end-of-sequence token\n    }\n)\njson_chat = ChatHuggingFace(llm=json_llm)\n\nchain = prompt | json_chat | json_parser\n\ndescription = \"MacBook Pro 是 Apple 的專業筆記型電腦，售價 68900 元，目前有現貨\"\n\nprint(f\"📝 產品描述: {description}\\n\")\n\ntry:\n    result = chain.invoke({\"description\": description})\n    \n    print(f\"✅ 解析成功！\")\n    print(f\"輸出類型: {type(result)}\\n\")\n    print(f\"JSON 內容:\")\n    print(json.dumps(result, indent=2, ensure_ascii=False))\n    \n    # 驗證資料完整性\n    print(f\"\\n📦 資料驗證:\")\n    required_fields = [\"name\", \"category\", \"price\", \"in_stock\"]\n    missing_fields = [f for f in required_fields if f not in result]\n    \n    if missing_fields:\n        print(f\"  ⚠️  缺少欄位: {', '.join(missing_fields)}\")\n    else:\n        print(f\"  ✅ 所有必要欄位都存在\")\n        print(f\"\\n📋 產品資訊:\")\n        print(f\"  名稱: {result['name']}\")\n        print(f\"  類別: {result['category']}\")\n        print(f\"  價格: NT$ {result['price']:,}\")\n        print(f\"  庫存: {'有貨 ✅' if result['in_stock'] else '缺貨 ❌'}\")\n    \nexcept Exception as e:\n    print(f\"❌ 解析錯誤: {e}\")\n    \n    # 除錯：顯示原始 LLM 輸出\n    print(f\"\\n🔍 除錯資訊 - LLM 原始輸出:\")\n    try:\n        debug_chain = prompt | json_chat\n        debug_result = debug_chain.invoke({\"description\": description})\n        print(debug_result.content[:500])  # 只顯示前 500 字元\n        \n        # 嘗試手動解析\n        print(f\"\\n💡 嘗試手動解析 JSON...\")\n        import re\n        json_match = re.search(r'\\{[^{}]+\\}', debug_result.content)\n        if json_match:\n            manual_json = json.loads(json_match.group())\n            print(f\"✅ 手動解析成功:\")\n            print(json.dumps(manual_json, indent=2, ensure_ascii=False))\n        else:\n            print(\"❌ 找不到 JSON 格式\")\n        \n    except Exception as debug_e:\n        print(f\"除錯失敗: {debug_e}\")\n    \n    print(\"\\n💡 調整建議：\")\n    print(\"- 已使用直接參數設定確定性輸出\")\n    print(\"- 如果持續失敗，建議改用 PydanticOutputParser (見 Cell 11)\")\n    print(\"- 或使用更簡化的 prompt 和更小的模型輸出\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 11: PydanticOutputParser - 型別安全的結構化輸出\nprint(\"🎯 範例 4: PydanticOutputParser (Pydantic 解析器)\\n\")\n\n# 定義簡化的資料模型（減少欄位以提高成功率）\nclass TechArticleSummary(BaseModel):\n    title: str = Field(description=\"文章標題\")\n    main_topic: str = Field(description=\"主要主題\")\n    key_points: List[str] = Field(description=\"關鍵重點，2-3 點\")\n    difficulty: str = Field(description=\"難度：初級/中級/進階\")\n\npydantic_parser = PydanticOutputParser(pydantic_object=TechArticleSummary)\n\n# 改進 Prompt - 使用 Few-Shot 範例，不使用 format_instructions\nprompt = PromptTemplate(\n    template=\"\"\"分析技術文章並提取結構化資訊，以 JSON 格式輸出。\n\n範例：\n文章：Docker 是一個容器化平台，可以打包應用程式及其依賴。它簡化了部署流程，適合微服務架構。開發者可以確保環境一致性。\nJSON: {{\n  \"title\": \"Docker 容器化技術介紹\",\n  \"main_topic\": \"容器化與部署\",\n  \"key_points\": [\"打包應用程式及依賴\", \"簡化部署流程\", \"確保環境一致性\"],\n  \"difficulty\": \"中級\"\n}}\n\n現在請分析：\n文章：{article}\nJSON:\"\"\",\n    input_variables=[\"article\"]\n)\n\n# 建立穩定的 LLM（不使用 GenerationConfig 物件，直接用參數）\nstable_llm = HuggingFacePipeline.from_model_id(\n    model_id=\"google/gemma-3-1b-it\",\n    task=\"text-generation\",\n    model_kwargs={\n        \"quantization_config\": quantization_config,\n        \"device_map\": \"auto\"\n    },\n    pipeline_kwargs={\n        \"max_new_tokens\": 256,\n        \"do_sample\": False,        # 確定性輸出\n        \"pad_token_id\": 0,\n        \"eos_token_id\": 1\n    }\n)\nstable_chat = ChatHuggingFace(llm=stable_llm)\n\nchain = prompt | stable_chat | pydantic_parser\n\narticle = \"\"\"RAG (Retrieval-Augmented Generation) 是一種結合檢索與生成的 AI 技術。\n它先從知識庫中檢索相關資訊，再將檢索結果與用戶問題一起傳給大型語言模型生成答案。\n這種方法可以有效減少 AI 幻覺問題，提供更準確且有依據的回答。\"\"\"\n\nprint(f\"📝 文章內容:\\n{article}\\n\")\n\ntry:\n    result = chain.invoke({\"article\": article})\n    print(f\"✅ 解析成功！類型: {type(result)}\\n\")\n    print(f\"📌 標題: {result.title}\")\n    print(f\"🎯 主題: {result.main_topic}\")\n    print(f\"📊 難度: {result.difficulty}\")\n    print(f\"\\n💡 關鍵重點:\")\n    for i, point in enumerate(result.key_points, 1):\n        print(f\"  {i}. {point}\")\n        \nexcept Exception as e:\n    print(f\"❌ 解析錯誤: {str(e)[:200]}...\\n\")\n    \n    # 除錯：顯示原始輸出\n    print(\"🔍 除錯資訊 - LLM 原始輸出:\")\n    try:\n        debug_chain = prompt | stable_chat\n        debug_result = debug_chain.invoke({\"article\": article})\n        print(debug_result.content[:500])\n        \n        # 嘗試手動解析\n        print(\"\\n💡 嘗試手動解析...\")\n        import re\n        json_match = re.search(r'\\{[^{}]*\\[[^\\]]*\\][^{}]*\\}|\\{[^{}]+\\}', debug_result.content, re.DOTALL)\n        if json_match:\n            try:\n                manual_json = json.loads(json_match.group())\n                print(\"✅ 找到 JSON 結構:\")\n                print(json.dumps(manual_json, indent=2, ensure_ascii=False))\n                \n                # 嘗試用找到的 JSON 建立物件\n                manual_result = TechArticleSummary(**manual_json)\n                print(\"\\n✅ 手動建立 Pydantic 物件成功！\")\n                print(f\"標題: {manual_result.title}\")\n                print(f\"主題: {manual_result.main_topic}\")\n                print(f\"難度: {manual_result.difficulty}\")\n                print(f\"重點數量: {len(manual_result.key_points)}\")\n                \n            except Exception as parse_e:\n                print(f\"❌ 手動解析也失敗: {parse_e}\")\n        else:\n            print(\"❌ 找不到完整的 JSON 結構\")\n            \n    except Exception as debug_e:\n        print(f\"除錯失敗: {debug_e}\")\n    \n    print(\"\\n💡 調整建議：\")\n    print(\"- 已簡化模型欄位（移除 target_audience）\")\n    print(\"- 已使用 Few-Shot 範例引導\")\n    print(\"- 已設定 do_sample=False 確保穩定性\")\n    print(\"- 可以嘗試使用更大的模型（gemma-3-4b-it）\")\n    print(\"- 或改用更簡單的 JsonOutputParser（見 Cell 10）\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Output Parser 比較總結\n",
    "print(\"\"\"📊 Output Parser 類型比較\n",
    "\n",
    "┌─────────────────────────┬──────────────────┬─────────────────────┬─────────────┐\n",
    "│ Parser 類型             │ 輸出類型         │ 適用場景            │ 難度        │\n",
    "├─────────────────────────┼──────────────────┼─────────────────────┼─────────────┤\n",
    "│ StrOutputParser         │ str              │ 簡單文字回答        │ ⭐          │\n",
    "│ CommaSeparatedList      │ List[str]        │ 列表項目            │ ⭐⭐        │\n",
    "│ JsonOutputParser        │ Dict             │ 結構化資料          │ ⭐⭐⭐      │\n",
    "│ PydanticOutputParser    │ Pydantic Model   │ 型別安全資料        │ ⭐⭐⭐⭐    │\n",
    "└─────────────────────────┴──────────────────┴─────────────────────┴─────────────┘\n",
    "\n",
    "💡 選擇建議：\n",
    "1. 簡單回答 → StrOutputParser\n",
    "2. 需要列表 → CommaSeparatedListOutputParser\n",
    "3. 需要驗證 → PydanticOutputParser (推薦！)\n",
    "4. 彈性資料 → JsonOutputParser\n",
    "\n",
    "⚠️  注意事項：\n",
    "- 結構化輸出建議使用 temperature=0 或極低值\n",
    "- Pydantic 提供自動型別檢查和驗證\n",
    "- 複雜結構可能需要多次重試\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: RAG 系統建立"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: 載入論文資料\n",
    "print(\"📚 載入學術論文...\\n\")\n",
    "\n",
    "# 使用 Multi-Agent Debate 論文\n",
    "pdf_path = \"2509.05396v1.pdf\"\n",
    "\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "documents = loader.load()\n",
    "\n",
    "print(f\"✅ 成功載入論文\")\n",
    "print(f\"📄 總頁數: {len(documents)}\")\n",
    "print(f\"📝 第一頁前 200 字元:\\n{documents[0].page_content[:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14: 文件分割與向量化\n",
    "print(\"✂️  文件分割與向量化...\\n\")\n",
    "\n",
    "# 文件分割\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "texts = text_splitter.split_documents(documents)\n",
    "print(f\"📦 分割成 {len(texts)} 個文字區塊\")\n",
    "\n",
    "# 建立 Embeddings\n",
    "print(\"\\n🔄 建立向量嵌入...\")\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
    ")\n",
    "\n",
    "# 建立向量資料庫\n",
    "print(\"🗄️  建立 FAISS 向量資料庫...\")\n",
    "vectorstore = FAISS.from_documents(texts, embeddings)\n",
    "\n",
    "print(\"\\n✅ RAG 資料準備完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 15: 建立基礎 RAG Chain (無 Parser)\n",
    "print(\"🔗 建立基礎 RAG Chain\\n\")\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "rag_prompt = PromptTemplate(\n",
    "    template=\"\"\"根據以下資訊回答問題。如果資訊中沒有相關內容，請說你不知道。\n",
    "\n",
    "相關資訊:\n",
    "{context}\n",
    "\n",
    "問題: {question}\n",
    "\n",
    "回答:\"\"\",\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=chat_model,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\"prompt\": rag_prompt},\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "# 測試基礎 RAG\n",
    "query = \"請問 multi-agent debate 的主要發現是什麼？\"\n",
    "result = qa_chain.invoke({\"query\": query})\n",
    "\n",
    "print(f\"❓ 問題: {query}\\n\")\n",
    "print(f\"💬 回答: {result['result']}\\n\")\n",
    "print(f\"📌 使用了 {len(result['source_documents'])} 個來源片段\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Part 4.5: 進階檢索技術 - BM25、Hybrid Search、Rerank",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Cell 15.5: 檢索方法效果比較\nprint(\"📊 範例 5: 檢索方法全面比較\\n\")\n\nimport time\n\ndef compare_retrieval_methods(query: str):\n    \"\"\"比較不同檢索方法的效果\"\"\"\n    results = {}\n    \n    # 1. Vector 檢索\n    start = time.time()\n    vector_docs = retriever.invoke(query)[:3]\n    vector_time = time.time() - start\n    results['Vector'] = {\n        'docs': vector_docs,\n        'time': vector_time,\n        'method': '語義向量檢索'\n    }\n    \n    # 2. BM25 檢索\n    start = time.time()\n    bm25_docs = bm25_retriever.invoke(query)[:3]\n    bm25_time = time.time() - start\n    results['BM25'] = {\n        'docs': bm25_docs,\n        'time': bm25_time,\n        'method': '關鍵字檢索'\n    }\n    \n    # 3. Hybrid 檢索\n    start = time.time()\n    hybrid_docs = hybrid_retriever.invoke(query)[:3]\n    hybrid_time = time.time() - start\n    results['Hybrid'] = {\n        'docs': hybrid_docs,\n        'time': hybrid_time,\n        'method': '混合檢索'\n    }\n    \n    # 4. Hybrid + Rerank\n    start = time.time()\n    reranked_docs = hybrid_rerank_retriever(query, k=3, candidate_k=10)\n    rerank_time = time.time() - start\n    results['Hybrid+Rerank'] = {\n        'docs': reranked_docs,\n        'time': rerank_time,\n        'method': '混合檢索 + 重排序'\n    }\n    \n    return results\n\n# 測試不同類型的查詢\ntest_cases = [\n    {\n        'query': 'multi-agent debate accuracy performance',\n        'type': '關鍵字密集型查詢'\n    },\n    {\n        'query': 'How can we improve the reasoning ability of language models?',\n        'type': '語義理解型查詢'\n    }\n]\n\nfor case in test_cases:\n    query = case['query']\n    query_type = case['type']\n    \n    print(f\"\\n{'='*80}\")\n    print(f\"🔬 測試案例: {query_type}\")\n    print(f\"❓ 查詢: {query}\\n\")\n    \n    # 執行比較\n    comparison = compare_retrieval_methods(query)\n    \n    # 顯示結果\n    print(\"📊 檢索結果比較：\\n\")\n    \n    for method_name, data in comparison.items():\n        print(f\"{'─'*80}\")\n        print(f\"🔹 方法: {method_name} ({data['method']})\")\n        print(f\"⏱️  耗時: {data['time']*1000:.2f} ms\")\n        print(f\"📄 檢索結果:\")\n        \n        for i, doc in enumerate(data['docs'], 1):\n            preview = doc.page_content[:100].replace('\\n', ' ')\n            print(f\"   {i}. {preview}...\")\n        print()\n\nprint(f\"{'='*80}\\n\")\n\n# 總結表格\nprint(\"📈 檢索方法特性總結：\\n\")\nprint(\"┌─────────────────┬──────────────────┬──────────────┬─────────────────┐\")\nprint(\"│ 方法            │ 優點             │ 缺點         │ 適用場景        │\")\nprint(\"├─────────────────┼──────────────────┼──────────────┼─────────────────┤\")\nprint(\"│ Vector          │ 語義理解強       │ 關鍵字弱     │ 語義查詢        │\")\nprint(\"│ BM25            │ 關鍵字精確       │ 無語義理解   │ 精確匹配        │\")\nprint(\"│ Hybrid          │ 兼具兩者優點     │ 參數調整複雜 │ 通用查詢        │\")\nprint(\"│ Hybrid+Rerank   │ 最高準確度       │ 速度較慢     │ 品質要求高      │\")\nprint(\"└─────────────────┴──────────────────┴──────────────┴─────────────────┘\")\n\nprint(\"\\n💡 選擇建議：\")\nprint(\"• 延遲敏感 → Vector 或 BM25\")\nprint(\"• 品質優先 → Hybrid + Rerank (推薦！)\")\nprint(\"• 平衡方案 → Hybrid\")\nprint(\"• 特定領域 → 根據查詢類型選擇\")\n",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Cell 15.4: 完整的 Hybrid + Rerank RAG Pipeline\nprint(\"🚀 範例 4: 完整 Hybrid + Rerank RAG 系統\\n\")\n\nfrom langchain_core.runnables import RunnableLambda\n\nprint(\"📘 完整 Pipeline 流程：\")\nprint(\"1️⃣  Hybrid 檢索：BM25 + Vector 混合檢索\")\nprint(\"2️⃣  Rerank：使用 Cross-Encoder 重新排序\")\nprint(\"3️⃣  Context 組合：將最相關文檔組合為上下文\")\nprint(\"4️⃣  LLM 生成：基於優質上下文生成答案\\n\")\n\ndef hybrid_rerank_retriever(query: str, k: int = 3, candidate_k: int = 10):\n    \"\"\"Hybrid + Rerank 檢索器\"\"\"\n    # Step 1: Hybrid 檢索\n    candidates = hybrid_retriever.invoke(query)[:candidate_k]\n    \n    # Step 2: Rerank\n    reranked = rerank_documents(query, candidates, top_k=k)\n    \n    # 返回文檔（不含分數）\n    return [doc for doc, score in reranked]\n\n# 建立完整的 RAG Chain\nadvanced_rag_prompt = PromptTemplate(\n    template=\"\"\"你是一個專業的學術論文分析助手。請根據以下資訊詳細回答問題。\n\n相關資訊:\n{context}\n\n問題: {question}\n\n請提供：\n1. 直接回答問題\n2. 引用相關證據\n3. 如果資訊不足，請說明\n\n回答:\"\"\",\n    input_variables=[\"context\", \"question\"]\n)\n\n# 測試完整系統\ntest_queries = [\n    \"What is the main contribution of this research?\",\n    \"How does multi-agent debate improve performance?\",\n    \"What are the limitations of this approach?\"\n]\n\nfor query in test_queries:\n    print(f\"\\n{'='*70}\")\n    print(f\"❓ 問題: {query}\\n\")\n    \n    # 使用 Hybrid + Rerank 檢索\n    print(\"🔍 執行 Hybrid + Rerank 檢索...\")\n    relevant_docs = hybrid_rerank_retriever(query, k=3, candidate_k=10)\n    \n    print(f\"✅ 檢索到 {len(relevant_docs)} 個高相關文檔\\n\")\n    \n    # 組合上下文\n    context = \"\\n\\n\".join([doc.page_content for doc in relevant_docs])\n    \n    # 生成答案\n    print(\"🤖 生成答案...\\n\")\n    formatted_prompt = advanced_rag_prompt.format(context=context, question=query)\n    response = chat_model.invoke([HumanMessage(content=formatted_prompt)])\n    \n    print(\"💬 回答:\")\n    print(response.content)\n    print(f\"\\n📚 使用來源: {len(relevant_docs)} 個文檔片段\")\n    print(f\"📄 來源頁碼: {', '.join([str(doc.metadata.get('page', 'N/A')) for doc in relevant_docs])}\")\n\nprint(f\"\\n{'='*70}\\n\")\nprint(\"✨ 系統優勢總結：\")\nprint(\"✅ Hybrid Search - 結合關鍵字與語義檢索\")\nprint(\"✅ Reranker - 精確排序最相關文檔\")\nprint(\"✅ 高品質上下文 - 提升 LLM 回答準確度\")\nprint(\"✅ 減少幻覺 - 基於真實文檔內容生成\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Cell 15.3: Reranker - 重新排序提升相關性\nprint(\"🎯 範例 3: Reranker (重新排序)\\n\")\n\nfrom sentence_transformers import CrossEncoder\nimport numpy as np\n\nprint(\"📘 Reranker 原理：\")\nprint(\"- 使用 Cross-Encoder 模型對檢索結果重新評分\")\nprint(\"- Cross-Encoder 同時考慮查詢和文檔，計算相關性分數\")\nprint(\"- 比 Bi-Encoder (向量檢索) 更精確，但速度較慢\")\nprint(\"- 適合對初步檢索結果進行精煉\\n\")\n\n# 載入 Reranker 模型（使用輕量級模型以節省資源）\nprint(\"🔄 載入 Reranker 模型...\")\nreranker = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\nprint(\"✅ Reranker 模型載入完成\\n\")\n\ndef rerank_documents(query: str, documents: list, top_k: int = 3):\n    \"\"\"使用 Reranker 對文檔重新排序\"\"\"\n    # 準備 query-document pairs\n    pairs = [[query, doc.page_content] for doc in documents]\n    \n    # 計算相關性分數\n    scores = reranker.predict(pairs)\n    \n    # 按分數排序\n    sorted_indices = np.argsort(scores)[::-1][:top_k]\n    \n    # 返回排序後的文檔和分數\n    reranked_docs = [(documents[i], scores[i]) for i in sorted_indices]\n    return reranked_docs\n\n# 測試 Reranker\nquery = \"What are the key findings about multi-agent debate?\"\n\nprint(f\"❓ 查詢: {query}\\n\")\n\n# 先用 Hybrid 檢索獲取候選文檔\nprint(\"🔀 步驟 1: Hybrid 檢索 (獲取 10 個候選)\")\ncandidates = hybrid_retriever.invoke(query)[:10]\nprint(f\"   取得 {len(candidates)} 個候選文檔\\n\")\n\n# 使用 Reranker 重新排序\nprint(\"🎯 步驟 2: Reranker 重新排序\")\nreranked_results = rerank_documents(query, candidates, top_k=3)\n\nprint(\"\\n📊 Reranked 結果 (按相關性排序):\\n\")\nfor i, (doc, score) in enumerate(reranked_results, 1):\n    print(f\"排名 {i} (分數: {score:.4f}):\")\n    print(f\"  內容: {doc.page_content[:120]}...\")\n    print(f\"  來源: 第 {doc.metadata.get('page', 'N/A')} 頁\")\n    print()\n\nprint(\"💡 Reranker 優勢：\")\nprint(\"- 更精確的相關性評估\")\nprint(\"- 減少不相關結果\")\nprint(\"- 提升 RAG 系統整體品質\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Cell 15.2: Hybrid Search - 結合 BM25 與向量檢索\nprint(\"🔀 範例 2: Hybrid Search (混合檢索)\\n\")\n\nfrom langchain.retrievers import EnsembleRetriever\n\nprint(\"📘 Hybrid Search 原理：\")\nprint(\"- 結合 BM25 (關鍵字) 和 Vector (語義) 檢索\")\nprint(\"- 使用加權平均合併兩種檢索結果\")\nprint(\"- 優點：同時獲得精確匹配和語義理解\\n\")\n\n# 建立 Ensemble Retriever (混合檢索器)\nhybrid_retriever = EnsembleRetriever(\n    retrievers=[bm25_retriever, retriever],  # BM25 + Vector\n    weights=[0.5, 0.5]  # 各佔 50% 權重\n)\n\n# 比較測試：使用更語義化的查詢\ntest_queries = [\n    \"What is the main contribution of this paper?\",  # 語義查詢\n    \"multi-agent debate performance results\",  # 關鍵字查詢\n]\n\nfor query in test_queries:\n    print(f\"\\n{'='*60}\")\n    print(f\"❓ 查詢: {query}\\n\")\n    \n    # Vector 檢索\n    print(\"🎯 Vector 檢索 (前 2 個):\")\n    vector_results = retriever.invoke(query)[:2]\n    for i, doc in enumerate(vector_results, 1):\n        print(f\"  {i}. {doc.page_content[:80]}... (頁 {doc.metadata.get('page', 'N/A')})\")\n    \n    # BM25 檢索\n    print(\"\\n🔍 BM25 檢索 (前 2 個):\")\n    bm25_results = bm25_retriever.invoke(query)[:2]\n    for i, doc in enumerate(bm25_results, 1):\n        print(f\"  {i}. {doc.page_content[:80]}... (頁 {doc.metadata.get('page', 'N/A')})\")\n    \n    # Hybrid 檢索\n    print(\"\\n🔀 Hybrid 檢索 (前 3 個):\")\n    hybrid_results = hybrid_retriever.invoke(query)[:3]\n    for i, doc in enumerate(hybrid_results, 1):\n        print(f\"  {i}. {doc.page_content[:80]}... (頁 {doc.metadata.get('page', 'N/A')})\")\n\nprint(f\"\\n{'='*60}\")\nprint(\"\\n💡 觀察重點：\")\nprint(\"- 語義查詢：Vector 表現更好，理解問題意圖\")\nprint(\"- 關鍵字查詢：BM25 表現更好，精確匹配\")\nprint(\"- Hybrid 結合兩者優勢，更穩健\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Cell 15.1: BM25 Retriever - 關鍵字檢索\nprint(\"🔍 範例 1: BM25 Retriever (關鍵字檢索)\\n\")\n\nfrom langchain.retrievers import BM25Retriever\n\nprint(\"📘 BM25 演算法說明：\")\nprint(\"- BM25 (Best Matching 25) 是一種基於 TF-IDF 的排序函數\")\nprint(\"- 優點：關鍵字匹配精確、不需要向量化、速度快\")\nprint(\"- 缺點：無法理解語義、對同義詞不敏感\\n\")\n\n# 建立 BM25 Retriever\nbm25_retriever = BM25Retriever.from_documents(texts)\nbm25_retriever.k = 3  # 返回前 3 個結果\n\n# 測試查詢\nquery = \"multi-agent debate methodology\"\n\nprint(f\"❓ 查詢: {query}\\n\")\nprint(\"🔎 BM25 檢索結果:\\n\")\n\nbm25_results = bm25_retriever.invoke(query)\n\nfor i, doc in enumerate(bm25_results, 1):\n    print(f\"📄 結果 {i}:\")\n    print(f\"內容: {doc.page_content[:150]}...\")\n    print(f\"來源: 第 {doc.metadata.get('page', 'N/A')} 頁\")\n    print()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: RAG + Output Parser 整合應用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 16: 案例 1 - 論文關鍵資訊提取\n",
    "print(\"📄 案例 1: 學術論文關鍵資訊提取\\n\")\n",
    "\n",
    "class PaperAnalysis(BaseModel):\n",
    "    title: str = Field(description=\"論文標題\")\n",
    "    main_finding: str = Field(description=\"主要研究發現，1-2 句話\")\n",
    "    methodology: str = Field(description=\"研究方法，簡要說明\")\n",
    "    key_contributions: List[str] = Field(description=\"主要貢獻，2-3 點\")\n",
    "    confidence: float = Field(description=\"回答信心度 0-1\", ge=0, le=1)\n",
    "\n",
    "# 建立 Parser\n",
    "paper_parser = PydanticOutputParser(pydantic_object=PaperAnalysis)\n",
    "\n",
    "# 建立結構化 RAG Prompt\n",
    "paper_prompt = PromptTemplate(\n",
    "    template=\"\"\"根據以下論文片段，提取結構化資訊。\n",
    "\n",
    "論文片段:\n",
    "{context}\n",
    "\n",
    "問題: {question}\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "分析結果:\"\"\",\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    partial_variables={\"format_instructions\": paper_parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "# 手動實作 RAG + Parser 流程\n",
    "query = \"分析這篇論文的核心內容\"\n",
    "\n",
    "# 1. 檢索相關文件\n",
    "relevant_docs = retriever.get_relevant_documents(query)\n",
    "context = \"\\n\\n\".join([doc.page_content for doc in relevant_docs[:3]])\n",
    "\n",
    "# 2. 生成結構化 prompt\n",
    "formatted_prompt = paper_prompt.format(context=context, question=query)\n",
    "\n",
    "# 3. 呼叫 LLM\n",
    "response = stable_chat.invoke([HumanMessage(content=formatted_prompt)])\n",
    "\n",
    "# 4. 解析輸出\n",
    "try:\n",
    "    analysis = paper_parser.parse(response.content)\n",
    "    \n",
    "    print(\"✅ 論文分析結果:\\n\")\n",
    "    print(f\"📌 標題: {analysis.title}\")\n",
    "    print(f\"\\n🔍 主要發現:\\n{analysis.main_finding}\")\n",
    "    print(f\"\\n🛠️  研究方法:\\n{analysis.methodology}\")\n",
    "    print(f\"\\n💡 主要貢獻:\")\n",
    "    for i, contrib in enumerate(analysis.key_contributions, 1):\n",
    "        print(f\"  {i}. {contrib}\")\n",
    "    print(f\"\\n📊 信心度: {analysis.confidence:.2f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ 解析失敗: {e}\")\n",
    "    print(f\"\\n原始輸出:\\n{response.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 17: 案例 2 - 技術問答系統\n",
    "print(\"💻 案例 2: 結構化技術問答\\n\")\n",
    "\n",
    "class TechnicalQA(BaseModel):\n",
    "    question_type: str = Field(description=\"問題類型：概念/方法/比較/實作\")\n",
    "    answer: str = Field(description=\"詳細回答\")\n",
    "    key_terms: List[str] = Field(description=\"關鍵術語，2-4 個\")\n",
    "    difficulty: str = Field(description=\"難度：初級/中級/進階\")\n",
    "    related_topics: List[str] = Field(description=\"相關主題\")\n",
    "    sources_used: int = Field(description=\"使用的來源數量\")\n",
    "\n",
    "tech_parser = PydanticOutputParser(pydantic_object=TechnicalQA)\n",
    "\n",
    "tech_prompt = PromptTemplate(\n",
    "    template=\"\"\"你是一個技術專家。根據以下資訊回答問題。\n",
    "\n",
    "相關資訊:\n",
    "{context}\n",
    "\n",
    "技術問題: {question}\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "結構化回答:\"\"\",\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    partial_variables={\"format_instructions\": tech_parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "query = \"multi-agent debate 和傳統的單一 agent 有什麼差異？\"\n",
    "\n",
    "# RAG + Parser 流程\n",
    "relevant_docs = retriever.get_relevant_documents(query)\n",
    "context = \"\\n\\n\".join([doc.page_content for doc in relevant_docs[:3]])\n",
    "formatted_prompt = tech_prompt.format(context=context, question=query)\n",
    "response = stable_chat.invoke([HumanMessage(content=formatted_prompt)])\n",
    "\n",
    "try:\n",
    "    qa_result = tech_parser.parse(response.content)\n",
    "    \n",
    "    print(\"✅ 技術問答結果:\\n\")\n",
    "    print(f\"❓ 問題類型: {qa_result.question_type}\")\n",
    "    print(f\"📊 難度: {qa_result.difficulty}\")\n",
    "    print(f\"\\n💬 回答:\\n{qa_result.answer}\")\n",
    "    print(f\"\\n🔑 關鍵術語: {', '.join(qa_result.key_terms)}\")\n",
    "    print(f\"\\n🔗 相關主題:\")\n",
    "    for topic in qa_result.related_topics:\n",
    "        print(f\"  - {topic}\")\n",
    "    print(f\"\\n📚 使用來源: {qa_result.sources_used} 個片段\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ 解析失敗: {e}\")\n",
    "    print(f\"\\n原始輸出:\\n{response.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 18: 案例 3 - 方法比較分析\n",
    "print(\"⚖️  案例 3: 研究方法比較分析\\n\")\n",
    "\n",
    "class MethodComparison(BaseModel):\n",
    "    method_name: str = Field(description=\"方法名稱\")\n",
    "    advantages: List[str] = Field(description=\"優點，2-3 點\")\n",
    "    disadvantages: List[str] = Field(description=\"缺點，2-3 點\")\n",
    "    use_cases: List[str] = Field(description=\"適用場景\")\n",
    "    performance_note: str = Field(description=\"效能說明\")\n",
    "    recommendation: str = Field(description=\"使用建議\")\n",
    "\n",
    "comparison_parser = PydanticOutputParser(pydantic_object=MethodComparison)\n",
    "\n",
    "comparison_prompt = PromptTemplate(\n",
    "    template=\"\"\"根據以下資訊，分析研究方法的優缺點。\n",
    "\n",
    "研究內容:\n",
    "{context}\n",
    "\n",
    "分析問題: {question}\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "比較分析:\"\"\",\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    partial_variables={\"format_instructions\": comparison_parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "query = \"分析 multi-agent debate 方法的優缺點\"\n",
    "\n",
    "relevant_docs = retriever.get_relevant_documents(query)\n",
    "context = \"\\n\\n\".join([doc.page_content for doc in relevant_docs[:4]])  # 使用更多片段\n",
    "formatted_prompt = comparison_prompt.format(context=context, question=query)\n",
    "response = stable_chat.invoke([HumanMessage(content=formatted_prompt)])\n",
    "\n",
    "try:\n",
    "    comparison = comparison_parser.parse(response.content)\n",
    "    \n",
    "    print(\"✅ 方法比較分析:\\n\")\n",
    "    print(f\"📌 方法: {comparison.method_name}\\n\")\n",
    "    \n",
    "    print(\"✅ 優點:\")\n",
    "    for i, adv in enumerate(comparison.advantages, 1):\n",
    "        print(f\"  {i}. {adv}\")\n",
    "    \n",
    "    print(\"\\n❌ 缺點:\")\n",
    "    for i, dis in enumerate(comparison.disadvantages, 1):\n",
    "        print(f\"  {i}. {dis}\")\n",
    "    \n",
    "    print(\"\\n🎯 適用場景:\")\n",
    "    for use_case in comparison.use_cases:\n",
    "        print(f\"  • {use_case}\")\n",
    "    \n",
    "    print(f\"\\n📊 效能說明:\\n{comparison.performance_note}\")\n",
    "    print(f\"\\n💡 使用建議:\\n{comparison.recommendation}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ 解析失敗: {e}\")\n",
    "    print(f\"\\n原始輸出:\\n{response.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: 商業應用實戰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 19: 商業應用 - 智慧客服系統\n",
    "print(\"🤝 商業應用: 智慧客服系統\\n\")\n",
    "\n",
    "class CustomerServiceResponse(BaseModel):\n",
    "    intent: str = Field(description=\"客戶意圖：技術查詢/產品比較/故障排除/其他\")\n",
    "    answer: str = Field(description=\"客服回答，友善且專業\")\n",
    "    sentiment: str = Field(description=\"問題情緒：正面/中性/急迫\")\n",
    "    confidence: float = Field(description=\"回答信心度 0-1\", ge=0, le=1)\n",
    "    suggested_action: str = Field(description=\"建議後續動作\")\n",
    "    escalate: bool = Field(description=\"是否需要轉人工\")\n",
    "    related_docs: List[str] = Field(description=\"相關文件或資源\")\n",
    "\n",
    "service_parser = PydanticOutputParser(pydantic_object=CustomerServiceResponse)\n",
    "\n",
    "service_prompt = PromptTemplate(\n",
    "    template=\"\"\"你是一個專業的 AI 客服助手。根據知識庫回答客戶問題。\n",
    "\n",
    "知識庫內容:\n",
    "{context}\n",
    "\n",
    "客戶問題: {question}\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "客服回應:\"\"\",\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    partial_variables={\"format_instructions\": service_parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "# 模擬客戶問題\n",
    "customer_query = \"我想了解 multi-agent debate 是否適合用在我們的問答系統？有什麼限制嗎？\"\n",
    "\n",
    "relevant_docs = retriever.get_relevant_documents(customer_query)\n",
    "context = \"\\n\\n\".join([doc.page_content for doc in relevant_docs[:3]])\n",
    "formatted_prompt = service_prompt.format(context=context, question=customer_query)\n",
    "response = stable_chat.invoke([HumanMessage(content=formatted_prompt)])\n",
    "\n",
    "try:\n",
    "    service_response = service_parser.parse(response.content)\n",
    "    \n",
    "    print(\"💼 客服系統回應:\\n\")\n",
    "    print(f\"❓ 客戶問題: {customer_query}\\n\")\n",
    "    print(f\"🎯 意圖識別: {service_response.intent}\")\n",
    "    print(f\"😊 情緒分析: {service_response.sentiment}\")\n",
    "    print(f\"📊 信心度: {service_response.confidence:.0%}\\n\")\n",
    "    print(f\"💬 客服回答:\\n{service_response.answer}\\n\")\n",
    "    print(f\"👉 建議動作: {service_response.suggested_action}\")\n",
    "    print(f\"🚨 轉人工: {'是' if service_response.escalate else '否'}\\n\")\n",
    "    print(f\"📚 相關資源:\")\n",
    "    for doc in service_response.related_docs:\n",
    "        print(f\"  • {doc}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ 解析失敗: {e}\")\n",
    "    print(f\"\\n原始輸出:\\n{response.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 20: 錯誤處理與重試機制\n",
    "print(\"🔄 實作錯誤處理與重試機制\\n\")\n",
    "\n",
    "def safe_rag_with_parser(query: str, parser, prompt_template, max_retries=2):\n",
    "    \"\"\"安全的 RAG + Parser 執行，包含重試機制\"\"\"\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            # 1. 檢索\n",
    "            relevant_docs = retriever.get_relevant_documents(query)\n",
    "            context = \"\\n\\n\".join([doc.page_content for doc in relevant_docs[:3]])\n",
    "            \n",
    "            # 2. 生成 prompt\n",
    "            formatted_prompt = prompt_template.format(context=context, question=query)\n",
    "            \n",
    "            # 3. 呼叫 LLM\n",
    "            response = stable_chat.invoke([HumanMessage(content=formatted_prompt)])\n",
    "            \n",
    "            # 4. 解析\n",
    "            parsed_result = parser.parse(response.content)\n",
    "            \n",
    "            print(f\"✅ 第 {attempt + 1} 次嘗試成功\")\n",
    "            return {\n",
    "                \"success\": True,\n",
    "                \"result\": parsed_result,\n",
    "                \"raw_response\": response.content,\n",
    "                \"attempts\": attempt + 1\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"⚠️  第 {attempt + 1} 次嘗試失敗: {str(e)[:100]}\")\n",
    "            \n",
    "            if attempt == max_retries - 1:\n",
    "                # 最後一次嘗試失敗，返回原始輸出\n",
    "                return {\n",
    "                    \"success\": False,\n",
    "                    \"error\": str(e),\n",
    "                    \"raw_response\": response.content if 'response' in locals() else None,\n",
    "                    \"attempts\": attempt + 1\n",
    "                }\n",
    "\n",
    "# 測試\n",
    "test_query = \"multi-agent debate 的核心概念是什麼？\"\n",
    "result = safe_rag_with_parser(\n",
    "    query=test_query,\n",
    "    parser=paper_parser,\n",
    "    prompt_template=paper_prompt\n",
    ")\n",
    "\n",
    "if result[\"success\"]:\n",
    "    print(f\"\\n🎉 解析成功（共 {result['attempts']} 次嘗試）\")\n",
    "    print(f\"結果類型: {type(result['result'])}\")\n",
    "else:\n",
    "    print(f\"\\n❌ 解析失敗（共 {result['attempts']} 次嘗試）\")\n",
    "    print(f\"錯誤: {result['error']}\")\n",
    "    if result['raw_response']:\n",
    "        print(f\"\\n原始輸出:\\n{result['raw_response'][:300]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: 進階技巧與優化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 21: 自定義 Output Parser\n",
    "print(\"🛠️  建立自定義 Output Parser\\n\")\n",
    "\n",
    "from langchain_core.output_parsers import BaseOutputParser\n",
    "from typing import Any\n",
    "\n",
    "class KeyValueParser(BaseOutputParser[Dict[str, str]]):\n",
    "    \"\"\"解析 Key: Value 格式的輸出\"\"\"\n",
    "    \n",
    "    def parse(self, text: str) -> Dict[str, str]:\n",
    "        \"\"\"解析 Key: Value 格式文字\"\"\"\n",
    "        result = {}\n",
    "        lines = text.strip().split('\\n')\n",
    "        \n",
    "        for line in lines:\n",
    "            if ':' in line:\n",
    "                parts = line.split(':', 1)\n",
    "                if len(parts) == 2:\n",
    "                    key = parts[0].strip()\n",
    "                    value = parts[1].strip()\n",
    "                    result[key] = value\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def get_format_instructions(self) -> str:\n",
    "        return \"\"\"請使用以下格式輸出：\n",
    "Key1: Value1\n",
    "Key2: Value2\n",
    "Key3: Value3\"\"\"\n",
    "\n",
    "# 測試自定義 Parser\n",
    "kv_parser = KeyValueParser()\n",
    "\n",
    "kv_prompt = PromptTemplate(\n",
    "    template=\"\"\"提取論文的基本資訊。\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "論文內容:\n",
    "{context}\n",
    "\n",
    "基本資訊:\"\"\",\n",
    "    input_variables=[\"context\"],\n",
    "    partial_variables={\"format_instructions\": kv_parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "relevant_docs = retriever.get_relevant_documents(\"論文資訊\")\n",
    "context = relevant_docs[0].page_content[:500]\n",
    "\n",
    "formatted_prompt = kv_prompt.format(context=context)\n",
    "response = stable_chat.invoke([HumanMessage(content=formatted_prompt)])\n",
    "\n",
    "try:\n",
    "    parsed = kv_parser.parse(response.content)\n",
    "    print(\"✅ 自定義 Parser 解析成功:\\n\")\n",
    "    for key, value in parsed.items():\n",
    "        print(f\"{key}: {value}\")\nexcept Exception as e:\n",
    "    print(f\"❌ 解析失敗: {e}\")\n",
    "    print(f\"\\n原始輸出:\\n{response.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 22: 效能優化建議\n",
    "print(\"\"\"🚀 效能優化建議\n",
    "\n",
    "## 1. 模型量化優化\n",
    "✅ 已使用 4-bit 量化\n",
    "📉 記憶體減少 ~75%\n",
    "🔧 可嘗試:\n",
    "   - 8-bit 量化（更穩定但較大）\n",
    "   - 調整 compute_dtype (bfloat16 vs float16)\n",
    "\n",
    "## 2. Output Parser 優化\n",
    "🎯 Temperature 設定:\n",
    "   - 結構化輸出: 0.0 - 0.2\n",
    "   - 創意回答: 0.7 - 0.9\n",
    "   \n",
    "🔄 重試策略:\n",
    "   - 實作 max_retries (2-3 次)\n",
    "   - 使用 try-except 捕捉錯誤\n",
    "   - 提供降級方案\n",
    "\n",
    "## 3. RAG 系統優化\n",
    "📊 檢索參數:\n",
    "   - chunk_size: 300-1000 (依文件類型)\n",
    "   - chunk_overlap: 50-200\n",
    "   - k值: 3-10 (平衡品質與速度)\n",
    "\n",
    "🔍 檢索策略:\n",
    "   - 混合搜尋 (關鍵字 + 語義)\n",
    "   - Re-ranking (重新排序)\n",
    "   - Query expansion (查詢擴展)\n",
    "\n",
    "## 4. Prompt Engineering\n",
    "📝 Prompt 設計:\n",
    "   - 明確的格式指示\n",
    "   - 提供範例（Few-shot）\n",
    "   - 強調輸出格式要求\n",
    "   \n",
    "## 5. 快取機制\n",
    "💾 建議實作:\n",
    "   - Embedding 快取\n",
    "   - 常見問題快取\n",
    "   - 向量資料庫持久化\n",
    "\n",
    "## 6. 錯誤處理\n",
    "🛡️  防禦策略:\n",
    "   - 驗證 Pydantic 欄位\n",
    "   - 設定預設值\n",
    "   - 記錄失敗案例\n",
    "   - 監控成功率\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 總結與作業"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 23: 課程總結\n",
    "print(\"\"\"📚 Week 6 課程總結\n",
    "\n",
    "## 🎯 本週學習重點\n",
    "\n",
    "### 1. 量化技術\n",
    "✅ 理解模型量化原理\n",
    "✅ 實作 4-bit BitsAndBytes 量化\n",
    "✅ 記憶體優化 ~75%\n",
    "\n",
    "### 2. Output Parser\n",
    "✅ StrOutputParser - 基本字串\n",
    "✅ CommaSeparatedListOutputParser - 列表\n",
    "✅ JsonOutputParser - JSON 格式\n",
    "✅ PydanticOutputParser - 型別安全（推薦！）\n",
    "✅ 自定義 Parser\n",
    "\n",
    "### 3. RAG + Parser 整合\n",
    "✅ 論文資訊提取\n",
    "✅ 技術問答系統\n",
    "✅ 方法比較分析\n",
    "\n",
    "### 4. 商業應用\n",
    "✅ 智慧客服系統\n",
    "✅ 錯誤處理與重試\n",
    "✅ 效能優化策略\n",
    "\n",
    "## 💼 實務技能\n",
    "- 設計結構化資料模型\n",
    "- 整合多個 LangChain 組件\n",
    "- 處理 LLM 輸出不確定性\n",
    "- 建立可靠的生產系統\n",
    "\n",
    "## 🎓 下一步學習\n",
    "- Agent 系統設計\n",
    "- 多模態 RAG\n",
    "- 系統評估與監控\n",
    "- 實際專案部署\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 24: 作業說明\n",
    "print(\"\"\"📝 Week 6 作業\n",
    "\n",
    "## 初級作業（必做）\n",
    "\n",
    "### 作業 1: Pydantic 模型設計\n",
    "設計一個 `ProductReview` Pydantic 模型，包含至少 5 個欄位：\n",
    "- 產品名稱\n",
    "- 評分 (1-5)\n",
    "- 評論內容摘要\n",
    "- 優點列表\n",
    "- 缺點列表\n",
    "\n",
    "### 作業 2: 量化效能比較\n",
    "比較量化前後的：\n",
    "- GPU 記憶體使用\n",
    "- 推理速度\n",
    "- 輸出品質\n",
    "\n",
    "### 作業 3: 基礎 RAG + Parser\n",
    "使用 JsonOutputParser 從論文中提取：\n",
    "- 標題\n",
    "- 作者\n",
    "- 主要貢獻\n",
    "\n",
    "## 中級作業（選做）\n",
    "\n",
    "### 作業 4: 產品推薦系統\n",
    "建立結構化產品推薦系統，包含：\n",
    "- 產品資訊\n",
    "- 推薦理由\n",
    "- 適用場景\n",
    "- 信心度評分\n",
    "\n",
    "### 作業 5: 技術文件問答\n",
    "整合 RAG + 多欄位輸出：\n",
    "- 問題分類\n",
    "- 詳細回答\n",
    "- 程式碼範例（如適用）\n",
    "- 相關資源連結\n",
    "\n",
    "### 作業 6: 錯誤處理機制\n",
    "實作完整的錯誤處理：\n",
    "- 重試機制（最多 3 次）\n",
    "- 降級方案\n",
    "- 錯誤日誌記錄\n",
    "\n",
    "## 進階作業（挑戰）\n",
    "\n",
    "### 作業 7: 多文件檢索系統\n",
    "使用 week04_rag/data/ 中的所有論文：\n",
    "- 建立跨文件檢索\n",
    "- 實作文件來源標註\n",
    "- 比較不同論文的觀點\n",
    "\n",
    "### 作業 8: RAG 品質評估\n",
    "建立自動評估機制：\n",
    "- 答案相關性評分\n",
    "- 來源可信度評估\n",
    "- 輸出格式完整性檢查\n",
    "\n",
    "### 作業 9: 完整客服系統\n",
    "建立生產級客服知識庫：\n",
    "- 意圖分類\n",
    "- 情感分析\n",
    "- 自動回覆\n",
    "- 人工轉接判斷\n",
    "- 滿意度追蹤\n",
    "\n",
    "### 作業 10: 大模型量化實驗\n",
    "嘗試使用 gemma-3-4b-it：\n",
    "- 優化量化配置\n",
    "- 比較 1B vs 4B 效果\n",
    "- 分析記憶體與品質權衡\n",
    "\n",
    "## 📤 繳交方式\n",
    "1. 完成的 Notebook (.ipynb)\n",
    "2. 實驗結果截圖\n",
    "3. 心得報告（500 字內）\n",
    "\n",
    "## ⏰ 截止時間\n",
    "下週上課前\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}